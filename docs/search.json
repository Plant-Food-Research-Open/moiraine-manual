[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The moiraine R package user manual",
    "section": "",
    "text": "Preface\nQuick blurb around multi-omics integration. There are many tools available to perform multi-omics integration, and a lot are implemented as R packages. These tools differ conceptually (in terms of required data input, assumptions, questions they answer) but also at a practical level in terms of input data format, parameters, etc and output format. That makes it time-consuming to apply different tools to a same multi-omics dataset, and to compare the results."
  },
  {
    "objectID": "index.html#the-moiraine-package",
    "href": "index.html#the-moiraine-package",
    "title": "The moiraine R package user manual",
    "section": "The moiraine package",
    "text": "The moiraine package\nThe moiraine package aims at alleviating this by providing a framework to easily and consistently apply different integration tools to a same dataset. It also facilitates the comparison of results with consistent formatting of integration output and visualisations.\nIn addition, in an effort to make these computations reproducible, moiraine heavily relies on targets for the creating of reproducible pipelines."
  },
  {
    "objectID": "index.html#about-this-manual",
    "href": "index.html#about-this-manual",
    "title": "The moiraine R package user manual",
    "section": "About this manual",
    "text": "About this manual\nIn this manual, we are showcasing the functionalities of the moiraine package by presenting an in-depth walk-through example of multi-omics integration analysis. This will not only talk about the how in terms of R functions etc, but also talk about the integration methods and how to use them.\nHere, say that we heavily recommend to be familiar with targets (teaching targets it out of the scope of this manual, and we refer to the excellent targets manual).\n\nlibrary(targets)\n\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n#> [1] 2\n\nA targets chunck:\n\ntar_target(a, 2+2)\n\n\n\n\"something\""
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "\n1  Introduction\n",
    "section": "",
    "text": "omics dataset + what are samples and features metadata\nwhat is multi-omics integration\nsupervised vs unsupervised\nthe analysis workflow from moiraine (use the graph I use in presentations)\n\n\n1.0.1 Other things to add in intro\nNote: Throughout the package and vignettes, we refer to the different biological entities measured in a given dataset (e.g. genes, transcripts, metabolic compounds, etc) as features.\nTo improve upon the default ggplot2 colours, each vignette is run with the following options:\n\noptions(\n  ggplot2.continuous.colour = \"viridis\",\n  ggplot2.continuous.fill = \"viridis\",\n  ggplot2.discrete.colour = function() {\n    ggplot2::scale_colour_brewer(\n      palette = \"Paired\", \n      na.value = \"grey\"\n    )\n  } ,\n  ggplot2.discrete.fill = function() {\n    ggplot2::scale_fill_brewer(\n      palette = \"Paired\",\n      na.value = \"grey\"\n    )\n  } \n)"
  },
  {
    "objectID": "example_dataset.html",
    "href": "example_dataset.html",
    "title": "2  The example dataset",
    "section": "",
    "text": "The dataset that is used as example in this manual comes from Li et al. (2022). In this paper, the authors investigate the molecular mechanisms of bovine respiratory disease (BRD) in beef cattle, using multi-omics data. They collected genomics, transcriptomics and metabolomics measurements on blood samples obtained from both healthy and infected animals. They performed a genome-wide association study (GWAS) to identify genomic variants associated with BRD incidence, as well as a differential expression (DE) analysis on both the transcriptomics and metabolomics datasets to identify genes and metabolites whose expression or abundance differed between the two animal groups. They also performed an expression quantitative trait loci (eQTL) analysis to highlight associations between genomic variants and differentially expressed genes. The datasets analysed in this article are publicly available. In this chapter, we detail the content of each dataset, and how they were obtained and processed to use for this manual.\n\n\n\n\nLi, Jiyuan, Robert Mukiibi, Janelle Jiminez, Zhiquan Wang, Everestus C. Akanno, Edouard Timsit, and Graham S. Plastow. 2022. “Applying Multi-Omics Data to Study the Genetic Background of Bovine Respiratory Disease Infection in Feedlot Crossbred Cattle.” Frontiers in Genetics 13. https://www.frontiersin.org/articles/10.3389/fgene.2022.1046192."
  },
  {
    "objectID": "data_import.html#the-example-dataset-files",
    "href": "data_import.html#the-example-dataset-files",
    "title": "3  Importing data",
    "section": "\n3.1 The example dataset files",
    "text": "3.1 The example dataset files\nThe dataset analysed this manual is presented in Chapter 2. The associated files that we will use here are:\n\n\nGenomics data:\n\ngenomics_dataset.csv: contains the genomic variants’ dosage, with genomic variants as rows and samples as columns.\ngenomics_features_info.csv: contains information about the genomic variants (chromosome, genomic position, etc, as well as the results of a GWAS analysis).\n\n\n\nTranscriptomics data:\n\ntranscriptomics_dataset.csv: contains the raw read counts for the measured genes – rows correspond to transcripts, and columns to samples.\nbos_taurus_gene_model.gff3: the genome annotation file used to map the transcriptomics reads to gene models.\ntranscriptomics_de_results.csv: the results of a differential expression analysis run on the transcriptomics dataset to compare healthy and diseased animals.\ntranscriptomics_go_annotation.csv: contains the correspondence between genes and GO terms in a long format (one row per gene/GO term pair).\n\n\n\nMetabolomics data:\n\nmetabolomics_dataset.csv: contains the area peak values – rows correspond to samples, and columns to compounds.\nmetabolomics_features_info.csv: contains information about the compounds (such as mass, retention time, and formula and name if the compounds has been identified) as well as the results of a differential expression analysis run on the metabolomics dataset to compare healthy and diseased animals.\n\n\nSamples information: stored in the samples_info.csv file, in which each row corresponds to a sample.\n\nEach of these files is available through the moiraine package, and can be retrieved via system.file(\"extdata/genomics_dataset.csv\", package = \"moiraine\")."
  },
  {
    "objectID": "data_import.html#importing-the-datasets",
    "href": "data_import.html#importing-the-datasets",
    "title": "3  Importing data",
    "section": "\n3.2 Importing the datasets",
    "text": "3.2 Importing the datasets\nWe will show how to import the datasets, first manually, and then in an automated way (using a target factory function).\n\n3.2.1 Manually\nWe can start by creating targets that track the different data files. This ensures that when a data file changes, the target is considered outdated and any analysis relying on this data file will be re-run (see here for more information). For example, for the genomics dataset, we write:\n\ntar_target(\n  dataset_file_geno,\n  system.file(\"extdata/genomics_dataset.csv\", package = \"moiraine\"),\n  format = \"file\"\n)\n\nThe created target, called dataset_file_geno, takes as value the path to the file:\n\ntar_read(dataset_file_geno)\n#> [1] \"/powerplant/workspace/hrpoab/RENV_CACHE/v5/R-4.2/x86_64-pc-linux-gnu/moiraine/0.0.0.9000/287c05d8d3c75e0fc72013b86230bba2/moiraine/extdata/genomics_dataset.csv\"\n\nThe next step is to import this dataset in R. We use the import_dataset_csv() function for that, rather than the readr::read_csv() or similar functions, as it ensures that the data is imported with the correct format for further use with the moiraine package. When importing a dataset, we need to specify the path to the file, as well as the name of the column in the csv file that contains the row names (through the col_id argument). In addition, we need to specify whether the features are represented in rows in the csv file, or in columns. This is done through the argument features_as_rows. For example, we can load the genomics dataset through:\n\ntar_target(\n  data_geno,\n  import_dataset_csv(\n    dataset_file_geno, \n    col_id = \"marker\", \n    features_as_rows = TRUE)\n)\n\nThe function returns a matrix in which the rows correspond to the features measured, and the columns correspond to the samples:\n\ntar_read(data_geno) |> dim()\n#> [1] 23036   139\ntar_read(data_geno)[1:5, 1:3]\n#>                             R21 Y3660 Y3243\n#> 1_41768691                    1     0     2\n#> 10-27008241-A-C-rs42918694    2     2     2\n#> 10-37505419-T-C-rs136559242   0     1     0\n#> 10-49904259-G-A-rs471723345   1     2     2\n#> 1-109550832-G-A-rs209732846   2     2     1\n\nNote that import_dataset_csv() uses readr::read_csv() to read in the data. It accepts arguments that will be passed on to read_csv(), which can be useful to control how the data file must be read, e.g. by specifying the columns’ type, or which characters must be considered as missing values.\n\n3.2.2 Using a target factory function\nCreating a target to track the raw file and using the import_dataset_csv() function to read it can be a bit cumbersome if we want to import several datasets. Luckily, this process can be automated with the import_dataset_csv_factory() function. It takes as an input a vector of files path, and for each file creates:\n\na target named dataset_file_XX (XX explained below), which tracks the raw data file;\na target named data_XX, which corresponds to the data matrix that has been imported through the import_dataset_csv function.\n\nFor each file, we need to specify the name of the column giving the row names (argument col_ids), and whether the features are stored as rows or as columns (argument features_as_rowss). Note that these arguments are the same as in the primary function import_dataset_csv(), except that they have an additional ‘s’ at the end of their name. This will be the case for most of the target factory functions from the package.\nIn addition, we have to provide a unique suffix which will be appended to the name of the targets created (i.e. the XX mentioned above) through the target_name_suffixes argument. This allows us to track which target corresponds to which dataset.\nSo the following code (note that it is not within a tar_target() call):\n\nimport_dataset_csv_factory(\n  files = c(\n    system.file(\"extdata/genomics_dataset.csv\", package = \"moiraine\"),\n    system.file(\"extdata/transcriptomics_dataset.csv\", package = \"moiraine\"),\n    system.file(\"extdata/metabolomics_dataset.csv\", package = \"moiraine\")\n  ),\n  col_ids = c(\"marker\", \"gene_id\", \"sample_id\"),\n  features_as_rowss = c(TRUE, TRUE, FALSE),\n  target_name_suffixes = c(\"geno\", \"transcripto\", \"metabo\")\n)\n\nwill create the following targets:\n\ndataset_file_geno, dataset_file_transcripto, dataset_file_metabo\ndata_geno, data_metabo, data_transcripto\n\n\ntar_read(data_geno) |> dim()\n#> [1] 23036   139\ntar_read(data_transcripto) |> dim()\n#> [1] 20335   143\ntar_read(data_metabo) |> dim()\n#> [1]  55 139\n\nWith this factory function, it is not possible to pass arguments to read_csv(). If you want to control how the files are read, please use the import_dataset_csv() function directly instead, as shown in Section 3.2.1."
  },
  {
    "objectID": "data_import.html#importing-the-features-metadata",
    "href": "data_import.html#importing-the-features-metadata",
    "title": "3  Importing data",
    "section": "\n3.3 Importing the features metadata",
    "text": "3.3 Importing the features metadata\nSimilarly to how we imported the datasets, there are two ways of importing features metadata: either manually, or using a target factory function. The two options are illustrated below.\n\n3.3.1 Manually\nAs shown in the previous section, we can start by creating a target that tracks the raw features metadata file, then read the file into R using the import_fmetadata_csv() function. It has the similar arguments as the import_dataset_csv() function, but returns a data-frame (rather than a matrix); and does not have the options to read a csv where the features are columns (they must be in rows):\n\nlist(\n  tar_target(\n    fmetadata_file_geno,\n    system.file(\"extdata/genomics_features_info.csv\", package = \"moiraine\"),\n    format = \"file\"\n  ),\n  \n  tar_target(\n    fmetadata_geno,\n    import_fmetadata_csv(\n      fmetadata_file_geno,\n      col_id = \"marker\",\n      col_types = c(\"chromosome\" = \"c\")\n    )\n  )\n)\n\nNotice that in the import_fmetadata_csv() call, we’ve added an argument (col_types) which will be passed on to read_csv(). This is to ensure that the chromosome column will be read as character (even though the chromosomes are denoted with integers).\n\ntar_read(fmetadata_geno) |> head()\n#>                                                feature_id chromosome  position\n#> 1_41768691                                     1_41768691          1  42139849\n#> 10-27008241-A-C-rs42918694     10-27008241-A-C-rs42918694         10  26971270\n#> 10-37505419-T-C-rs136559242   10-37505419-T-C-rs136559242         10  37388728\n#> 10-49904259-G-A-rs471723345   10-49904259-G-A-rs471723345          0         0\n#> 1-109550832-G-A-rs209732846   1-109550832-G-A-rs209732846          1 108696486\n#> 11-104555023-A-G-rs109353933 11-104555023-A-G-rs109353933         11 104498929\n#>                              gen_train_score ref alt ilmn_strand\n#> 1_41768691                            0.6786   T   G         BOT\n#> 10-27008241-A-C-rs42918694            0.8050   A   C         TOP\n#> 10-37505419-T-C-rs136559242           0.7890   A   G         TOP\n#> 10-49904259-G-A-rs471723345           0.7970   A   G         TOP\n#> 1-109550832-G-A-rs209732846           0.8909   T   C         BOT\n#> 11-104555023-A-G-rs109353933          0.8673   T   C         BOT\n#>                              customer_strand norm_id qtl_type qtl_effect\n#> 1_41768691                               BOT       2     <NA>         NA\n#> 10-27008241-A-C-rs42918694               TOP       1     <NA>         NA\n#> 10-37505419-T-C-rs136559242              BOT       1     <NA>         NA\n#> 10-49904259-G-A-rs471723345              TOP       2     <NA>         NA\n#> 1-109550832-G-A-rs209732846              TOP       3     <NA>         NA\n#> 11-104555023-A-G-rs109353933             TOP       1     <NA>         NA\n#>                              p_value fdr\n#> 1_41768691                        NA  NA\n#> 10-27008241-A-C-rs42918694        NA  NA\n#> 10-37505419-T-C-rs136559242       NA  NA\n#> 10-49904259-G-A-rs471723345       NA  NA\n#> 1-109550832-G-A-rs209732846       NA  NA\n#> 11-104555023-A-G-rs109353933      NA  NA\n\nYou can see that in the data-frame of features metadata, the feature IDs are present both as row names and in the feature_id column. This makes it easier to subset the datasets later on.\n\n3.3.2 Using a target factory function\nAlternatively, we can use a target factory function that automates the process when we have to read in several features metadata files. In our case, we have to do it for the genomics and metabolomics datasets only, as the transcriptomics dataset has a different features metadata format. However because we need to specify the column types for the genomics dataset, we will use the targets factory function to read in the metabolomics features metadata only. The arguments are almost the same as for import_dataset_csv_factory() (except for features_as_rowss):\n\nimport_fmetadata_csv_factory(\n  files = c(\n    system.file(\"extdata/metabolomics_features_info.csv\", package = \"moiraine\")\n  ),\n  col_ids = c(\"feature_id\"),\n  target_name_suffixes = c(\"metabo\")\n)\n\nThe targets created are:\n\nfmetadata_file_metabo\nfmetadata_metabo\n\n\ntar_read(fmetadata_metabo) |> head()\n#>           feature_id     hmdb_id                  name chemical_formula\n#> HMDB00001  HMDB00001 HMDB0000001     1-Methylhistidine        C7H11N3O2\n#> HMDB00008  HMDB00008 HMDB0000008 2-Hydroxybutyric acid           C4H8O3\n#> HMDB00357  HMDB00357 HMDB0000011 3-Hydroxybutyric acid           C4H8O3\n#> HMDB00042  HMDB00042 HMDB0000042           Acetic acid           C2H4O2\n#> HMDB00043  HMDB00043 HMDB0000043               Betaine         C5H12NO2\n#> HMDB00060  HMDB00060 HMDB0000060      Acetoacetic acid           C4H6O3\n#>           monisotopic_molecular_weight cas_registry_number\n#> HMDB00001                    169.08513            332-80-9\n#> HMDB00008                    104.04734           3347-90-8\n#> HMDB00357                    104.04734            625-72-9\n#> HMDB00042                     60.02113             64-19-7\n#> HMDB00043                    118.08680           6915-17-9\n#> HMDB00060                    102.03169            541-50-4\n#>                                smiles                    inchikey kegg_id\n#> HMDB00001 CN1C=NC(C[C@H](N)C(O)=O)=C1 BRMWTNUJHUMWMS-LURJTMIESA-N  C01152\n#> HMDB00008            CC[C@H](O)C(O)=O AFENDNXGAFYKQO-VKHMYHEASA-N  C05984\n#> HMDB00357           C[C@@H](O)CC(O)=O WHBMMWSBFZVSSR-GSVOUGTGSA-N  C01089\n#> HMDB00042                     CC(O)=O QTBSBXVTEAMEQO-UHFFFAOYSA-N  C00033\n#> HMDB00043          C[N+](C)(C)CC(O)=O KWIUHFFTVRNATP-UHFFFAOYSA-O    <NA>\n#> HMDB00060               CC(=O)CC(O)=O WDJHALXBUFZDSR-UHFFFAOYSA-N  C00164\n#>                                    direct_parent                   super_class\n#> HMDB00001              Histidine and derivatives Organic acids and derivatives\n#> HMDB00008    Alpha hydroxy acids and derivatives Organic acids and derivatives\n#> HMDB00357     Beta hydroxy acids and derivatives Organic acids and derivatives\n#> HMDB00042                       Carboxylic acids Organic acids and derivatives\n#> HMDB00043                      Alpha amino acids Organic acids and derivatives\n#> HMDB00060 Short-chain keto acids and derivatives Organic acids and derivatives\n#>               t_value      p_value         padj de_signif     de_status\n#> HMDB00001  -0.5557020 5.797635e-01 6.784466e-01    Not DE        Not DE\n#> HMDB00008   0.2181562 8.276321e-01 8.925444e-01    Not DE        Not DE\n#> HMDB00357  -9.7388879 2.353250e-17 2.157146e-16        DE downregulated\n#> HMDB00042 -12.5323491 1.753101e-24 4.821028e-23        DE downregulated\n#> HMDB00043  -7.9073179 7.827088e-13 3.913544e-12        DE downregulated\n#> HMDB00060  -0.4369834 6.628164e-01 7.439776e-01    Not DE        Not DE\n\nAgain, the targets factory function does not allow to pass arguments to read_csv() (if you need them, please use import_fmetadata_csv() directly as we have done in Section 3.3.1).\n\n3.3.3 Importing features metadata from a GTF/GFF file\nThe moiraine package can also extract features metadata from a genome annotation file (.gtf or .gff). We’ll demonstrate that for the transcriptomics dataset, for which information about the position and name of the transcripts can be found in the genome annotation used to map the reads. The function is called import_fmetadata_gff() (it is also the function you would use to read in information from a .gtf file). The type of information to extract from the annotation file is specified through the feature_type argument, which can be either 'genes' or 'transcripts'. In addition, if the function does not extract certain fields from the annotation file, these can be explicitly called using the add_fields parameter.\nIn this example, we want to extract information about the genes from the gtf file. We also want to make sure that the Name and descriptionfield are imported, as they give the name and description of the genes. To read in this information “manually”, we create the following targets:\n\nlist(\n  tar_target(\n    fmetadata_file_transcripto,\n    system.file(\"extdata/bos_taurus_gene_model.gff3\", package = \"moiraine\"),\n    format = \"file\"\n  ),\n  \n  tar_target(\n    fmetadata_transcripto,\n    import_fmetadata_gff(\n      fmetadata_file_transcripto,\n      feature_type = \"genes\",\n      add_fields = c(\"Name\", \"description\")\n    )\n  )\n)\n\nAs for the other import functions, there exists a more succinct target factory version, called import_fmetadata_gff_factory():\n\nimport_fmetadata_gff_factory(\n  files = system.file(\"extdata/bos_taurus_gene_model.gff3\", package = \"moiraine\"),\n  feature_types = \"genes\",\n  add_fieldss = c(\"Name\", \"description\"),\n  target_name_suffixes = \"transcripto\"\n)\n\nThis will create two targets: fmetadata_file_transcripto and fmetadata_transcripto.\nAs with import_fmetadata, the function returns a data-frame of features information:\n\ntar_read(fmetadata_transcripto) |> head()\n#>                            feature_id chromosome    start      end  width\n#> ENSBTAG00000000005 ENSBTAG00000000005         17 65389743 65505336 115594\n#> ENSBTAG00000000008 ENSBTAG00000000008         29 32214439 32244810  30372\n#> ENSBTAG00000000009 ENSBTAG00000000009         18 12338037 12342272   4236\n#> ENSBTAG00000000010 ENSBTAG00000000010         21 34209956 34223394  13439\n#> ENSBTAG00000000011 ENSBTAG00000000011          8  7950815  7971600  20786\n#> ENSBTAG00000000012 ENSBTAG00000000012         20 33708626 33732944  24319\n#>                    strand  Name\n#> ENSBTAG00000000005      +  GRK3\n#> ENSBTAG00000000008      - KCNJ1\n#> ENSBTAG00000000009      + FOXF1\n#> ENSBTAG00000000010      +  UBL7\n#> ENSBTAG00000000011      -   TDH\n#> ENSBTAG00000000012      + TTC33\n#>                                                                                                       description\n#> ENSBTAG00000000005                        G protein-coupled receptor kinase 3 [Source:VGNC Symbol;Acc:VGNC:53904]\n#> ENSBTAG00000000008 potassium inwardly rectifying channel subfamily J member 1 [Source:VGNC Symbol;Acc:VGNC:30453]\n#> ENSBTAG00000000009                                            forkhead box F1 [Source:VGNC Symbol;Acc:VGNC:29084]\n#> ENSBTAG00000000010                                           ubiquitin like 7 [Source:VGNC Symbol;Acc:VGNC:50128]\n#> ENSBTAG00000000011                                 L-threonine dehydrogenase [Source:VGNC Symbol;Acc:VGNC:108945]\n#> ENSBTAG00000000012                         tetratricopeptide repeat domain 33 [Source:VGNC Symbol;Acc:VGNC:36471]"
  },
  {
    "objectID": "data_import.html#importing-the-samples-metadata",
    "href": "data_import.html#importing-the-samples-metadata",
    "title": "3  Importing data",
    "section": "\n3.4 Importing the samples metadata",
    "text": "3.4 Importing the samples metadata\nAs for importing datasets or features metadata, the import_smetadata_csv() function reads in a csv file that contains information about the samples measured. Similarly to import_fmetadata_csv(), this function assumes that the csv file contains samples as rows. In this example, we have one samples information file for all of our omics datasets, but it is possible to have one separate samples metadata csv file for each omics dataset (if there are some omics-specific information such as batch, technology specifications, etc).\nWe can do this by manually creating the following targets:\n\nlist(\n  tar_target(\n    smetadata_file_all,\n    system.file(\"extdata/samples_info.csv\", package = \"moiraine\"),\n    format = \"file\"\n  ),\n\n  tar_target(\n    smetadata_all,\n    import_smetadata_csv(\n      smetadata_file_all,\n      col_id = \"animal_id\"\n    )\n  )\n)\n\nwhich is equivalent to the (more succinct) command:\n\nimport_smetadata_csv_factory(\n  files = system.file(\"extdata/samples_info.csv\", package = \"moiraine\"),\n  col_ids = \"animal_id\",\n  target_name_suffixes = \"all\"\n)\n\nThe latter command creates the targets smetadata_file_all and smetadata_all. smetadata_all stores the samples metadata imported as a data-frame:\n\ntar_read(smetadata_all) |> head()\n#>          id feedlot gender  status day_on_feed rnaseq_batch geno_comp_1\n#> R21     R21      F1 female Control          31           B2    0.007853\n#> Y3660 Y3660      F1   male Control          19           B2    0.852220\n#> Y3243 Y3243      F1   male Control          16           B2    0.044171\n#> R5764 R5764      F2   male Control          46           B1    0.213094\n#> P4669 P4669      F3   male     BRD          35           B2    0.389393\n#> R5452 R5452      F2   male Control          49           B1    0.265998\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster\n#> R21      0.820691    0.171456                K3\n#> Y3660    0.093585    0.054195                K2\n#> Y3243    0.190262    0.765567                K1\n#> R5764    0.676299    0.110607                K3\n#> P4669    0.503471    0.107136                K3\n#> R5452    0.733992    0.000010                K3\n\nNote that in the samples metadata data-frame, the sample IDs are present both as row names and in the id column. This makes it easier to subset the datasets later on.\nAs for the other import functions, import_smetadata_csv() accepts arguments that will be passed to read_csv() in order to specify how the file should be read. The targets factory version does not have this option."
  },
  {
    "objectID": "data_import.html#creating-the-omics-sets",
    "href": "data_import.html#creating-the-omics-sets",
    "title": "3  Importing data",
    "section": "\n3.5 Creating the omics sets",
    "text": "3.5 Creating the omics sets\nOnce each dataset and associated features and samples metadata have been imported, we need to combine them into omics sets. In practice, this means that for each omics dataset, we will create an R object that stores the actual dataset alongside its relevant metadata. moiraine relies on the Biobase containers derived from Biobase::eSet to store the different omics datasets; for example, Biobase::ExpressionSet objects are used to store transcriptomics measurements. Currently, moiraine support four types of omics containers:\n\ngenomics containers, which are Biobase::SnpSet objects. The particularity of this data type is that the features metadata data-frame must contain a column named chromosome and a column named position, which store the chromosome and genomic position within the chromosome (in base pairs) of a given genomic marker or variant.\ntranscriptomics containers, which are Biobase::ExpressionSet objects. The particularity of this data type is that the features metadata data-frame must contain the following columns: chromosome, start, end, giving the chromosome, start and end positions (in base pairs) of the genes or transcripts. Moreover, the values in start and end must be integers, and for each row the value in end must be higher than the value in start.\nmetabolomics containers, which are MetabolomeSet objects (implemented within moiraine). There are no restrictions on the features metadata table for this type of containers.\nphenotype containers, which are PhenotypeSet objects (implemented within moiraine). There are no restrictions on the features metadata table for this type of containers.\n\nIn practice, the nuances between these different containers are not very important, and the type of container used to store a particular dataset will have no impact on the downstream analysis apart from the name that will be given to the omics dataset. So in order to create a container for a transcriptomics dataset in the absence of features metadata, we have to create a dummy data-frame with the columns chromosome, start and end containing the values ch1, 1, and 10 (for example) and use that as features metadata. Alternately, or for other omics data (e.g. proteomics), it is possible to use a PhenotypeSet object instead.\n\n3.5.1 Creating a single omics set\nThe function create_omics_set() provides a convenient wrapper to create such container objects from the imported datasets and metadata. It has two mandatory arguments: the dataset, which should be in the form of a matrix where the rows correspond to features and the columns to samples; and the type of omics data that the dataset represents ('genomics', 'transcriptomics', 'metabolomics' or 'phenomics'). The latter determines which type of container will be generated. Optionally, a features metadata and/or a samples metadata data-frame can be passed on via the features_metadata and samples_metadata arguments, respectively. For example, let’s create a set for the genomics data:\n\ntar_target(\n  set_geno,\n  create_omics_set(\n    data_geno,\n    omics_type = \"genomics\",\n    features_metadata = fmetadata_geno,\n    samples_metadata = smetadata_all\n  )\n)\n\nIf executed, this command will return the following warning:\n\n#> Warning: 5 samples in samples metadata not in dataset, will be removed from\n#> metadata.\n\nThis is because, when providing features and samples metadata information, the function makes sure that the feature or sample IDs present in the metadata tables match those used in the dataset. In our case, 5 sample IDs from the metadata data-frame are not present in the dataset. We can confirm that by comparing the column names of the genomics dataset to the row names of the samples metadata:\n\nsetdiff(\n  tar_read(smetadata_all) |> rownames(),\n  tar_read(data_geno) |> colnames()\n)\n#> [1] \"P4744\" \"P4772\" \"R8953\" \"U5416\" \"R9909\"\n\nRather than throwing an error, the function will add a row for each missing sample ID to the metadata data-frame, with a NA in every column, and will remove from the metadata data-frame any sample not present in the dataset. The same applies for features metadata.\nThe resulting object is a SnpSet:\n\ntar_read(set_geno)\n#> SnpSet (storageMode: lockedEnvironment)\n#> assayData: 23036 features, 139 samples \n#>   element names: call, callProbability \n#> protocolData: none\n#> phenoData\n#>   rowNames: R21 Y3660 ... O5108 (139 total)\n#>   varLabels: id feedlot ... geno_comp_cluster (10 total)\n#>   varMetadata: labelDescription\n#> featureData\n#>   featureNames: 1_41768691 10-27008241-A-C-rs42918694 ... STAT5_13516_2\n#>     (23036 total)\n#>   fvarLabels: feature_id chromosome ... fdr (13 total)\n#>   fvarMetadata: labelDescription\n#> experimentData: use 'experimentData(object)'\n#> Annotation:\n\nwhich can be queried using specific methods from the Biobase package, e.g.:\n\ntar_load(set_geno)\n\ndim(set_geno)\n#> Features  Samples \n#>    23036      139\n\nfeatureNames(set_geno) |> head()\n#> [1] \"1_41768691\"                   \"10-27008241-A-C-rs42918694\"  \n#> [3] \"10-37505419-T-C-rs136559242\"  \"10-49904259-G-A-rs471723345\" \n#> [5] \"1-109550832-G-A-rs209732846\"  \"11-104555023-A-G-rs109353933\"\n\nsampleNames(set_geno) |> head()\n#> [1] \"R21\"   \"Y3660\" \"Y3243\" \"R5764\" \"P4669\" \"R5452\"\n\nfData(set_geno) |> head() ## extracts features metadata\n#>                                                feature_id chromosome  position\n#> 1_41768691                                     1_41768691          1  42139849\n#> 10-27008241-A-C-rs42918694     10-27008241-A-C-rs42918694         10  26971270\n#> 10-37505419-T-C-rs136559242   10-37505419-T-C-rs136559242         10  37388728\n#> 10-49904259-G-A-rs471723345   10-49904259-G-A-rs471723345          0         0\n#> 1-109550832-G-A-rs209732846   1-109550832-G-A-rs209732846          1 108696486\n#> 11-104555023-A-G-rs109353933 11-104555023-A-G-rs109353933         11 104498929\n#>                              gen_train_score ref alt ilmn_strand\n#> 1_41768691                            0.6786   T   G         BOT\n#> 10-27008241-A-C-rs42918694            0.8050   A   C         TOP\n#> 10-37505419-T-C-rs136559242           0.7890   A   G         TOP\n#> 10-49904259-G-A-rs471723345           0.7970   A   G         TOP\n#> 1-109550832-G-A-rs209732846           0.8909   T   C         BOT\n#> 11-104555023-A-G-rs109353933          0.8673   T   C         BOT\n#>                              customer_strand norm_id qtl_type qtl_effect\n#> 1_41768691                               BOT       2     <NA>         NA\n#> 10-27008241-A-C-rs42918694               TOP       1     <NA>         NA\n#> 10-37505419-T-C-rs136559242              BOT       1     <NA>         NA\n#> 10-49904259-G-A-rs471723345              TOP       2     <NA>         NA\n#> 1-109550832-G-A-rs209732846              TOP       3     <NA>         NA\n#> 11-104555023-A-G-rs109353933             TOP       1     <NA>         NA\n#>                              p_value fdr\n#> 1_41768691                        NA  NA\n#> 10-27008241-A-C-rs42918694        NA  NA\n#> 10-37505419-T-C-rs136559242       NA  NA\n#> 10-49904259-G-A-rs471723345       NA  NA\n#> 1-109550832-G-A-rs209732846       NA  NA\n#> 11-104555023-A-G-rs109353933      NA  NA\n\npData(set_geno) |> head() ## extracts samples metadata\n#>          id feedlot gender  status day_on_feed rnaseq_batch geno_comp_1\n#> R21     R21      F1 female Control          31           B2    0.007853\n#> Y3660 Y3660      F1   male Control          19           B2    0.852220\n#> Y3243 Y3243      F1   male Control          16           B2    0.044171\n#> R5764 R5764      F2   male Control          46           B1    0.213094\n#> P4669 P4669      F3   male     BRD          35           B2    0.389393\n#> R5452 R5452      F2   male Control          49           B1    0.265998\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster\n#> R21      0.820691    0.171456                K3\n#> Y3660    0.093585    0.054195                K2\n#> Y3243    0.190262    0.765567                K1\n#> R5764    0.676299    0.110607                K3\n#> P4669    0.503471    0.107136                K3\n#> R5452    0.733992    0.000010                K3\n\nNote that these methods can also be applied to the other types of containers.\n\n3.5.2 Using a target factory for creating omics sets\nThe function create_omics_set_factory() allows us to create several omics sets at once. It returns a list of targets, each storing one of the created omics set container. It takes as input arguments vectors that give for each omics set the arguments required by create_omics_set().\n\ncreate_omics_set_factory(\n  datasets = c(data_geno, data_transcripto, data_metabo),\n  omics_types = c(\"genomics\", \"transcriptomics\", \"metabolomics\"),\n  features_metadatas = c(fmetadata_geno, fmetadata_transcripto, fmetadata_metabo),\n  samples_metadatas = c(smetadata_all, smetadata_all, smetadata_all)\n)\n\nAgain, the warnings raised by the function originate from discrepancies between the datasets and associated metadata. It is always good practice to double-check manually to make sure that it is not due to a typo in the IDs or similar error.\nIf one of the datasets has no associated features or samples metadata, use NULL in the corresponding input arguments, e.g.:\n\ncreate_omics_set_factory(\n  datasets = c(data_geno, data_transcripto, data_metabo),\n  omics_types = c(\"genomics\", \"transcriptomics\", \"metabolomics\"),\n  features_metadatas = c(NULL, fmetadata_transcripto, fmetadata_metabo),\n  samples_metadatas = c(smetadata_all, NULL, smetadata_all)\n)\n\nThe create_omics_set_factory() function has a target_name_suffixes argument to customise the name of the created targets. However, if this argument is not provided, the function will attempt to read the suffixes to use from the name of the dataset targets. So in this case, it knows that the suffixes to use are 'geno', 'transcripto' and 'metabo'. Consequently, the function creates the following targets: set_geno, set_transcripto, set_metabo.\n\ntar_read(set_geno)\n#> SnpSet (storageMode: lockedEnvironment)\n#> assayData: 23036 features, 139 samples \n#>   element names: call, callProbability \n#> protocolData: none\n#> phenoData\n#>   rowNames: R21 Y3660 ... O5108 (139 total)\n#>   varLabels: id feedlot ... geno_comp_cluster (10 total)\n#>   varMetadata: labelDescription\n#> featureData\n#>   featureNames: 1_41768691 10-27008241-A-C-rs42918694 ... STAT5_13516_2\n#>     (23036 total)\n#>   fvarLabels: feature_id chromosome ... fdr (13 total)\n#>   fvarMetadata: labelDescription\n#> experimentData: use 'experimentData(object)'\n#> Annotation:\n\n\ntar_read(set_transcripto)\n#> ExpressionSet (storageMode: lockedEnvironment)\n#> assayData: 20335 features, 143 samples \n#>   element names: exprs \n#> protocolData: none\n#> phenoData\n#>   rowNames: R9497 R5969 ... Y9816 (143 total)\n#>   varLabels: id feedlot ... geno_comp_cluster (10 total)\n#>   varMetadata: labelDescription\n#> featureData\n#>   featureNames: ENSBTAG00000000005 ENSBTAG00000000008 ...\n#>     ENSBTAG00000055314 (20335 total)\n#>   fvarLabels: feature_id chromosome ... description (8 total)\n#>   fvarMetadata: labelDescription\n#> experimentData: use 'experimentData(object)'\n#> Annotation:\n\n\ntar_read(set_metabo)\n#> MetabolomeSet (storageMode: lockedEnvironment)\n#> assayData: 55 features, 139 samples \n#>   element names: call \n#> protocolData: none\n#> phenoData\n#>   rowNames: R21 Y3660 ... U5416 (139 total)\n#>   varLabels: id feedlot ... geno_comp_cluster (10 total)\n#>   varMetadata: labelDescription\n#> featureData\n#>   featureNames: HMDB00001 HMDB00008 ... HMDB01881 (55 total)\n#>   fvarLabels: feature_id hmdb_id ... de_status (16 total)\n#>   fvarMetadata: labelDescription\n#> experimentData: use 'experimentData(object)'\n#> Annotation:"
  },
  {
    "objectID": "data_import.html#creating-the-multi-omics-set",
    "href": "data_import.html#creating-the-multi-omics-set",
    "title": "3  Importing data",
    "section": "\n3.6 Creating the multi-omics set",
    "text": "3.6 Creating the multi-omics set\nFinally, we can combine the different omics sets into one multi-omics set object. moiraine makes use of the MultiDataSet package for that. MultiDataSet (Hernandez-Ferrer et al. (2017)) implements a multi-omics data container that collects, in one R object, several omics datasets alongside their associated features and samples metadata. One of the main advantages of using a MultiDataSet container is that we can pass all of the information associated with a set of related omics datasets with only one R object. In addition, the MultiDataSet package implements a number of very useful functions. For example, it is possible to assess the samples that are common to several omics sets. This is particularly useful for data integration, as the moiraine package can automatically discard samples missing from one or more datasets prior to the integration step if needed. Note that sample matching between the different omics datasets is based on sample IDs, so they must be consistent between the different datasets.\nWe will create the multi-omics set with the create_multiomics_set() function. It requires a list of the omics sets (that we created via either create_omics_set() or create_omics_set_factory()) to include, and returns a MultiDataSet::MultiDataSet-class object.\n\ntar_target(\n  mo_set,\n  create_multiomics_set(\n    list(set_geno,\n         set_transcripto,\n         set_metabo)\n  )\n)\n\n\ntar_read(mo_set)\n#> Object of class 'MultiDataSet'\n#>  . assayData: 3 elements\n#>     . snps: 23036 features, 139 samples \n#>     . rnaseq: 20335 features, 143 samples \n#>     . metabolome: 55 features, 139 samples \n#>  . featureData:\n#>     . snps: 23036 rows, 13 cols (feature_id, ..., p_value)\n#>     . rnaseq: 20335 rows, 8 cols (feature_id, ..., Name)\n#>     . metabolome: 55 rows, 16 cols (feature_id, ..., de_signif)\n#>  . rowRanges:\n#>     . snps: YES\n#>     . rnaseq: YES\n#>     . metabolome: NO\n#>  . phenoData:\n#>     . snps: 139 samples, 10 cols (id, ..., geno_comp_3)\n#>     . rnaseq: 143 samples, 10 cols (id, ..., geno_comp_3)\n#>     . metabolome: 139 samples, 10 cols (id, ..., geno_comp_3)\n\nWithin the MultiDataSet object, each omics set is assigned a name. The name depends first on the omics container type: a SnpSet set will be named snps, an ExpressionSet set will be named rnaseq, a MetabolomeSet will be named metabolome and a PhenotypeSet will be called phenotypes. If several sets of the same type are provided, they will be assigned unique names, e.g. snps+1 and snps+2 (the + symbol used as separator is set in the MultiDataSet package and cannot be changed). Alternatively, we can provide custom names for the datasets, using the datasets_names argument. These will be added to the type name (e.g. snps+customname). For example:\n\ntar_target(\n  mo_set_with_names,\n  create_multiomics_set(\n    list(set_geno,\n         set_transcripto,\n         set_metabo),\n    datasets_names = c(\"CaptureSeq\", \"RNAseq\", \"LCMS\")\n  )\n)\n\nreturns:\n\ntar_read(mo_set_with_names)\n#> Object of class 'MultiDataSet'\n#>  . assayData: 3 elements\n#>     . snps+CaptureSeq: 23036 features, 139 samples \n#>     . rnaseq+RNAseq: 20335 features, 143 samples \n#>     . metabolome+LCMS: 55 features, 139 samples \n#>  . featureData:\n#>     . snps+CaptureSeq: 23036 rows, 13 cols (feature_id, ..., p_value)\n#>     . rnaseq+RNAseq: 20335 rows, 8 cols (feature_id, ..., Name)\n#>     . metabolome+LCMS: 55 rows, 16 cols (feature_id, ..., de_signif)\n#>  . rowRanges:\n#>     . snps+CaptureSeq: YES\n#>     . rnaseq+RNAseq: YES\n#>     . metabolome+LCMS: NO\n#>  . phenoData:\n#>     . snps+CaptureSeq: 139 samples, 10 cols (id, ..., geno_comp_3)\n#>     . rnaseq+RNAseq: 143 samples, 10 cols (id, ..., geno_comp_3)\n#>     . metabolome+LCMS: 139 samples, 10 cols (id, ..., geno_comp_3)\n\nImportantly, the create_multiomics_set() function makes sure that samples metadata is consistent across the datasets for common samples. That is, if the same column (i.e. with the same name) is present in the samples metadata of several omics datasets, the values in this column must match for each sample present in all datasets. Otherwise, the function returns an error.\nIn the following chapter on Inspecting the MultiDataSet object, we will see how to handle the MultiDataSet object we just created. Alternatively, the MultiDataSet package vignette provides examples of constructing, querying and subsetting MultiDataSet objects."
  },
  {
    "objectID": "data_import.html#recap-targets-list",
    "href": "data_import.html#recap-targets-list",
    "title": "3  Importing data",
    "section": "\n3.7 Recap – targets list",
    "text": "3.7 Recap – targets list\nFor convenience, here is the list of targets that we created in this section:\n\nTargets list for data import\n\nlist(\n  ## Data import using a target factory\n  import_dataset_csv_factory(\n    files = c(\n      system.file(\"extdata/genomics_dataset.csv\", package = \"moiraine\"),\n      system.file(\"extdata/transcriptomics_dataset.csv\", package = \"moiraine\"),\n      system.file(\"extdata/metabolomics_dataset.csv\", package = \"moiraine\")\n    ),\n    col_ids = c(\"marker\", \"gene_id\", \"sample_id\"),\n    features_as_rowss = c(TRUE, TRUE, FALSE),\n    target_name_suffixes = c(\"geno\", \"transcripto\", \"metabo\")\n  ),\n  \n  ## Genomics features metadata file\n  tar_target(\n    fmetadata_file_geno,\n    system.file(\"extdata/genomics_features_info.csv\", package = \"moiraine\"),\n    format = \"file\"\n  ),\n  \n  ## Genomics features metadata import\n  tar_target(\n    fmetadata_geno,\n    import_fmetadata_csv(\n      fmetadata_file_geno,\n      col_id = \"marker\",\n      col_types = c(\"chromosome\" = \"c\")\n    )\n  ),\n  \n  \n  ## Metabolomics features metadata import\n  import_fmetadata_csv_factory(\n    files = c(\n      system.file(\"extdata/metabolomics_features_info.csv\", package = \"moiraine\")\n    ),\n    col_ids = c(\"feature_id\"),\n    target_name_suffixes = c(\"metabo\")\n  ),\n  \n  ## Transcriptomics features metadata import\n  import_fmetadata_gff_factory(\n    files = system.file(\"extdata/bos_taurus_gene_model.gff3\", package = \"moiraine\"),\n    feature_types = \"genes\",\n    add_fieldss = c(\"Name\", \"description\"),\n    target_name_suffixes = \"transcripto\"\n  ),\n  \n  ## Samples metadata import\n  import_smetadata_csv_factory(\n    files = system.file(\"extdata/samples_info.csv\", package = \"moiraine\"),\n    col_ids = \"animal_id\",\n    target_name_suffixes = \"all\"\n  ),\n  \n  ## Creating omics sets for each dataset\n  create_omics_set_factory(\n    datasets = c(data_geno, data_transcripto, data_metabo),\n    omics_types = c(\"genomics\", \"transcriptomics\", \"metabolomics\"),\n    features_metadatas = c(fmetadata_geno, fmetadata_transcripto, fmetadata_metabo),\n    samples_metadatas = c(smetadata_all, smetadata_all, smetadata_all)\n  ),\n  \n  ## Creating the MultiDataSet object\n  tar_target(\n    mo_set,\n    create_multiomics_set(\n      list(set_geno,\n           set_transcripto,\n           set_metabo)\n    )\n  )\n)\n\n\n\n\n\nHernandez-Ferrer, Carles, Carlos Ruiz-Arenas, Alba Beltran-Gomila, and Juan R. González. 2017. “MultiDataSet: An r Package for Encapsulating Multiple Data Sets with Application to Omic Data Integration.” BMC Bioinformatics 18 (1): 36. https://doi.org/10.1186/s12859-016-1455-1."
  },
  {
    "objectID": "inspecting_multidataset.html#querying-datasets-names-and-dimensions",
    "href": "inspecting_multidataset.html#querying-datasets-names-and-dimensions",
    "title": "4  Inspecting the MultiDataSet object",
    "section": "\n4.1 Querying datasets names and dimensions",
    "text": "4.1 Querying datasets names and dimensions\nThe names of the omics datasets stored in a MultiDataSet object can be obtained with:\n\nnames(mo_set)\n#> [1] \"snps\"       \"rnaseq\"     \"metabolome\"\n\nIt is also possible to query the number of features and samples in each dataset via n_features() and n_samples(). Both functions return a named integer vector:\n\nn_features(mo_set)\n#>       snps     rnaseq metabolome \n#>      23036      20335         55\n\n\nn_samples(mo_set)\n#>       snps     rnaseq metabolome \n#>        139        143        139\n\nThe feature and sample IDs for each dataset can be extracted with the get_features() and get_samples() functions. Both functions return a named list of features or samples ID for each omics dataset:\n\nget_features(mo_set) |> str()\n#> List of 3\n#>  $ snps      : chr [1:23036] \"1_41768691\" \"10-27008241-A-C-rs42918694\" \"10-37505419-T-C-rs136559242\" \"10-49904259-G-A-rs471723345\" ...\n#>  $ rnaseq    : chr [1:20335] \"ENSBTAG00000000005\" \"ENSBTAG00000000008\" \"ENSBTAG00000000009\" \"ENSBTAG00000000010\" ...\n#>  $ metabolome: chr [1:55] \"HMDB00001\" \"HMDB00008\" \"HMDB00042\" \"HMDB00043\" ...\n\n\nget_samples(mo_set) |> str()\n#> List of 3\n#>  $ snps      : chr [1:139] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n#>  $ rnaseq    : chr [1:143] \"R9497\" \"R5969\" \"R5327\" \"R5979\" ...\n#>  $ metabolome: chr [1:139] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ..."
  },
  {
    "objectID": "inspecting_multidataset.html#extracting-datasets-and-metadata",
    "href": "inspecting_multidataset.html#extracting-datasets-and-metadata",
    "title": "4  Inspecting the MultiDataSet object",
    "section": "\n4.2 Extracting datasets and metadata",
    "text": "4.2 Extracting datasets and metadata\nWe can extract the dataset matrices from a MultiDataSet object with the get_datasets() function, which returns a named list of matrices, each with features as rows and samples as columns:\n\nget_datasets(mo_set) |> str()\n#> List of 3\n#>  $ snps      : num [1:23036, 1:139] 1 2 0 1 2 0 1 2 1 1 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : chr [1:23036] \"1_41768691\" \"10-27008241-A-C-rs42918694\" \"10-37505419-T-C-rs136559242\" \"10-49904259-G-A-rs471723345\" ...\n#>   .. ..$ : chr [1:139] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n#>  $ rnaseq    : num [1:20335, 1:143] 733 6 0 2693 0 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : chr [1:20335] \"ENSBTAG00000000005\" \"ENSBTAG00000000008\" \"ENSBTAG00000000009\" \"ENSBTAG00000000010\" ...\n#>   .. ..$ : chr [1:143] \"R9497\" \"R5969\" \"R5327\" \"R5979\" ...\n#>  $ metabolome: num [1:55, 1:139] 9.1 58.2 403 172.6 0.7 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : chr [1:55] \"HMDB00001\" \"HMDB00008\" \"HMDB00042\" \"HMDB00043\" ...\n#>   .. ..$ : chr [1:139] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n\n\nget_datasets(mo_set)[[\"snps\"]][1:5, 1:5]\n#>                             R21 Y3660 Y3243 R5764 P4669\n#> 1_41768691                    1     0     2     2     1\n#> 10-27008241-A-C-rs42918694    2     2     2     1     2\n#> 10-37505419-T-C-rs136559242   0     1     0     2     0\n#> 10-49904259-G-A-rs471723345   1     2     2     2     2\n#> 1-109550832-G-A-rs209732846   2     2     1     2     2\n\nTo obtain the matrix for a single dataset from the MultiDataSet object, the get_dataset_matrix() function can be used instead:\n\nget_dataset_matrix(mo_set, \"snps\")[1:5, 1:5]\n#>                             R21 Y3660 Y3243 R5764 P4669\n#> 1_41768691                    1     0     2     2     1\n#> 10-27008241-A-C-rs42918694    2     2     2     1     2\n#> 10-37505419-T-C-rs136559242   0     1     0     2     0\n#> 10-49904259-G-A-rs471723345   1     2     2     2     2\n#> 1-109550832-G-A-rs209732846   2     2     1     2     2\n\nSimilarly, the functions get_features_metadata() and get_samples_metadata() each return a named list of feature or sample metadata data-frames, one per omics dataset:\n\nget_features_metadata(mo_set) |> str()\n#> List of 3\n#>  $ snps      :'data.frame':  23036 obs. of  13 variables:\n#>   ..$ feature_id     : chr [1:23036] \"1_41768691\" \"10-27008241-A-C-rs42918694\" \"10-37505419-T-C-rs136559242\" \"10-49904259-G-A-rs471723345\" ...\n#>   ..$ chromosome     : chr [1:23036] \"1\" \"10\" \"10\" \"0\" ...\n#>   ..$ position       : num [1:23036] 4.21e+07 2.70e+07 3.74e+07 0.00 1.09e+08 ...\n#>   ..$ gen_train_score: num [1:23036] 0.679 0.805 0.789 0.797 0.891 ...\n#>   ..$ ref            : chr [1:23036] \"T\" \"A\" \"A\" \"A\" ...\n#>   ..$ alt            : chr [1:23036] \"G\" \"C\" \"G\" \"G\" ...\n#>   ..$ ilmn_strand    : chr [1:23036] \"BOT\" \"TOP\" \"TOP\" \"TOP\" ...\n#>   ..$ customer_strand: chr [1:23036] \"BOT\" \"TOP\" \"BOT\" \"TOP\" ...\n#>   ..$ norm_id        : num [1:23036] 2 1 1 2 3 1 3 3 0 0 ...\n#>   ..$ qtl_type       : chr [1:23036] NA NA NA NA ...\n#>   ..$ qtl_effect     : num [1:23036] NA NA NA NA NA NA NA NA NA NA ...\n#>   ..$ p_value        : num [1:23036] NA NA NA NA NA NA NA NA NA NA ...\n#>   ..$ fdr            : num [1:23036] NA NA NA NA NA NA NA NA NA NA ...\n#>  $ rnaseq    :'data.frame':  20335 obs. of  8 variables:\n#>   ..$ feature_id : chr [1:20335] \"ENSBTAG00000000005\" \"ENSBTAG00000000008\" \"ENSBTAG00000000009\" \"ENSBTAG00000000010\" ...\n#>   ..$ chromosome : Factor w/ 178 levels \"1\",\"2\",\"3\",\"4\",..: 17 29 18 21 8 20 20 5 5 23 ...\n#>   ..$ start      : int [1:20335] 65389743 32214439 12338037 34209956 7950815 33708626 33674806 74883636 74905031 27720176 ...\n#>   ..$ end        : int [1:20335] 65505336 32244810 12342272 34223394 7971600 33732944 33703223 74893752 74919112 27721739 ...\n#>   ..$ width      : int [1:20335] 115594 30372 4236 13439 20786 24319 28418 10117 14082 1564 ...\n#>   ..$ strand     : Factor w/ 3 levels \"+\",\"-\",\"*\": 1 2 1 1 2 1 1 2 2 2 ...\n#>   ..$ Name       : chr [1:20335] \"GRK3\" \"KCNJ1\" \"FOXF1\" \"UBL7\" ...\n#>   ..$ description: chr [1:20335] \"G protein-coupled receptor kinase 3 [Source:VGNC Symbol;Acc:VGNC:53904]\" \"potassium inwardly rectifying channel subfamily J member 1 [Source:VGNC Symbol;Acc:VGNC:30453]\" \"forkhead box F1 [Source:VGNC Symbol;Acc:VGNC:29084]\" \"ubiquitin like 7 [Source:VGNC Symbol;Acc:VGNC:50128]\" ...\n#>  $ metabolome:'data.frame':  55 obs. of  16 variables:\n#>   ..$ feature_id                  : chr [1:55] \"HMDB00001\" \"HMDB00008\" \"HMDB00042\" \"HMDB00043\" ...\n#>   ..$ hmdb_id                     : chr [1:55] \"HMDB0000001\" \"HMDB0000008\" \"HMDB0000042\" \"HMDB0000043\" ...\n#>   ..$ name                        : chr [1:55] \"1-Methylhistidine\" \"2-Hydroxybutyric acid\" \"Acetic acid\" \"Betaine\" ...\n#>   ..$ chemical_formula            : chr [1:55] \"C7H11N3O2\" \"C4H8O3\" \"C2H4O2\" \"C5H12NO2\" ...\n#>   ..$ monisotopic_molecular_weight: num [1:55] 169 104 60 118 102 ...\n#>   ..$ cas_registry_number         : chr [1:55] \"332-80-9\" \"3347-90-8\" \"64-19-7\" \"6915-17-9\" ...\n#>   ..$ smiles                      : chr [1:55] \"CN1C=NC(C[C@H](N)C(O)=O)=C1\" \"CC[C@H](O)C(O)=O\" \"CC(O)=O\" \"C[N+](C)(C)CC(O)=O\" ...\n#>   ..$ inchikey                    : chr [1:55] \"BRMWTNUJHUMWMS-LURJTMIESA-N\" \"AFENDNXGAFYKQO-VKHMYHEASA-N\" \"QTBSBXVTEAMEQO-UHFFFAOYSA-N\" \"KWIUHFFTVRNATP-UHFFFAOYSA-O\" ...\n#>   ..$ kegg_id                     : chr [1:55] \"C01152\" \"C05984\" \"C00033\" NA ...\n#>   ..$ direct_parent               : chr [1:55] \"Histidine and derivatives\" \"Alpha hydroxy acids and derivatives\" \"Carboxylic acids\" \"Alpha amino acids\" ...\n#>   ..$ super_class                 : chr [1:55] \"Organic acids and derivatives\" \"Organic acids and derivatives\" \"Organic acids and derivatives\" \"Organic acids and derivatives\" ...\n#>   ..$ t_value                     : num [1:55] -0.556 0.218 -12.532 -7.907 -0.437 ...\n#>   ..$ p_value                     : num [1:55] 5.80e-01 8.28e-01 1.75e-24 7.83e-13 6.63e-01 ...\n#>   ..$ padj                        : num [1:55] 6.78e-01 8.93e-01 4.82e-23 3.91e-12 7.44e-01 ...\n#>   ..$ de_signif                   : chr [1:55] \"Not DE\" \"Not DE\" \"DE\" \"DE\" ...\n#>   ..$ de_status                   : chr [1:55] \"Not DE\" \"Not DE\" \"downregulated\" \"downregulated\" ...\n\n\nget_samples_metadata(mo_set) |> str()\n#> List of 3\n#>  $ snps      :'data.frame':  139 obs. of  10 variables:\n#>   ..$ id               : chr [1:139] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n#>   ..$ feedlot          : chr [1:139] \"F1\" \"F1\" \"F1\" \"F2\" ...\n#>   ..$ gender           : chr [1:139] \"female\" \"male\" \"male\" \"male\" ...\n#>   ..$ status           : chr [1:139] \"Control\" \"Control\" \"Control\" \"Control\" ...\n#>   ..$ day_on_feed      : num [1:139] 31 19 16 46 35 49 21 16 37 37 ...\n#>   ..$ rnaseq_batch     : chr [1:139] \"B2\" \"B2\" \"B2\" \"B1\" ...\n#>   ..$ geno_comp_1      : num [1:139] 0.00785 0.85222 0.04417 0.21309 0.38939 ...\n#>   ..$ geno_comp_2      : num [1:139] 0.8207 0.0936 0.1903 0.6763 0.5035 ...\n#>   ..$ geno_comp_3      : num [1:139] 0.1715 0.0542 0.7656 0.1106 0.1071 ...\n#>   ..$ geno_comp_cluster: chr [1:139] \"K3\" \"K2\" \"K1\" \"K3\" ...\n#>  $ rnaseq    :'data.frame':  143 obs. of  10 variables:\n#>   ..$ id               : chr [1:143] \"R9497\" \"R5969\" \"R5327\" \"R5979\" ...\n#>   ..$ feedlot          : chr [1:143] \"F2\" \"F2\" \"F2\" \"F2\" ...\n#>   ..$ gender           : chr [1:143] \"male\" \"male\" \"male\" \"male\" ...\n#>   ..$ status           : chr [1:143] \"BRD\" \"BRD\" \"BRD\" \"BRD\" ...\n#>   ..$ day_on_feed      : num [1:143] 35 24 38 30 31 24 26 18 13 32 ...\n#>   ..$ rnaseq_batch     : chr [1:143] \"B1\" \"B1\" \"B1\" \"B1\" ...\n#>   ..$ geno_comp_1      : num [1:143] 0.15372 0.11066 0.14073 0.28673 0.00001 ...\n#>   ..$ geno_comp_2      : num [1:143] 0.745 0.626 0.809 0.108 0.999 ...\n#>   ..$ geno_comp_3      : num [1:143] 0.10178 0.26351 0.04987 0.60547 0.00108 ...\n#>   ..$ geno_comp_cluster: chr [1:143] \"K3\" \"K3\" \"K3\" \"K1\" ...\n#>  $ metabolome:'data.frame':  139 obs. of  10 variables:\n#>   ..$ id               : chr [1:139] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n#>   ..$ feedlot          : chr [1:139] \"F1\" \"F1\" \"F1\" \"F2\" ...\n#>   ..$ gender           : chr [1:139] \"female\" \"male\" \"male\" \"male\" ...\n#>   ..$ status           : chr [1:139] \"Control\" \"Control\" \"Control\" \"Control\" ...\n#>   ..$ day_on_feed      : num [1:139] 31 19 16 46 35 49 21 16 37 37 ...\n#>   ..$ rnaseq_batch     : chr [1:139] \"B2\" \"B2\" \"B2\" \"B1\" ...\n#>   ..$ geno_comp_1      : num [1:139] 0.00785 0.85222 0.04417 0.21309 0.38939 ...\n#>   ..$ geno_comp_2      : num [1:139] 0.8207 0.0936 0.1903 0.6763 0.5035 ...\n#>   ..$ geno_comp_3      : num [1:139] 0.1715 0.0542 0.7656 0.1106 0.1071 ...\n#>   ..$ geno_comp_cluster: chr [1:139] \"K3\" \"K2\" \"K1\" \"K3\" ...\n\nFor the samples metadata, it is possible to extract a single data-frame that combines the metadata from the different datasets with the function get_samples_metadata_combined(). The only_common_cols argument controls whether only the columns that are common to the samples metadata of the different omics datasets should be returned. For this example, as the samples metadata is identical across the datasets, it makes no difference:\n\nget_samples_metadata_combined(mo_set) |> head()\n#>          id feedlot gender  status day_on_feed rnaseq_batch geno_comp_1\n#> R21     R21      F1 female Control          31           B2    0.007853\n#> Y3660 Y3660      F1   male Control          19           B2    0.852220\n#> Y3243 Y3243      F1   male Control          16           B2    0.044171\n#> R5764 R5764      F2   male Control          46           B1    0.213094\n#> P4669 P4669      F3   male     BRD          35           B2    0.389393\n#> R5452 R5452      F2   male Control          49           B1    0.265998\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster\n#> R21      0.820691    0.171456                K3\n#> Y3660    0.093585    0.054195                K2\n#> Y3243    0.190262    0.765567                K1\n#> R5764    0.676299    0.110607                K3\n#> P4669    0.503471    0.107136                K3\n#> R5452    0.733992    0.000010                K3"
  },
  {
    "objectID": "inspecting_multidataset.html#sec-inspecting-multidataset-summary-plots",
    "href": "inspecting_multidataset.html#sec-inspecting-multidataset-summary-plots",
    "title": "4  Inspecting the MultiDataSet object",
    "section": "\n4.3 Summary plots",
    "text": "4.3 Summary plots\nA number of plotting functions have been implemented to obtain a quick overview of the omics datasets in a MultiDataSet object.\n\n4.3.1 Samples upset plot\nFirst, the plot_samples_upset() function displays the number of common and unique samples across the datasets with an UpSet plot:\n\nplot_samples_upset(mo_set)\n\n\n\n\nAs can be seen in the upset plot above, 135 samples have measurements across all three omics datasets. In addition, 4 samples have both transcriptomics and metabolomics measurements, but no transcriptomics information; 3 samples are present in the genomics and metabolomics datasets but not the transcriptomics dataset, and the genomics and transcriptomics datasets each have a unique sample not present in the other omics datasets.\n\n4.3.2 Datasets density plots\nNext, we can show the density plot of each omics dataset with the plot_density_data() function. By default, all datasets are plotted onto the same axes, which is not very useful if they have very different scales. We can change that by setting the combined argument to FALSE, which splits the plot into one facet per dataset, and by setting scales to 'free' in order to give its own scale to each dataset:\n\nplot_density_data(mo_set, combined = FALSE, scales = \"free\")\n\n\n\n\nBy default, all datasets are represented in the density plot, but it is possible to focus on one or a subset of them via the datasets argument. This is useful here as the plots for the transcriptomics and metabolomics could benefit from a log10 transformation for the x-axis:\n\nplot_density_data(\n  mo_set,\n  datasets = c(\"rnaseq\", \"metabolome\"),\n  combined = FALSE,\n  scales = \"free\"\n) +\n  scale_x_log10()\n#> Warning: Transformation introduced infinite values in continuous x-axis\n#> Warning: Removed 338138 rows containing non-finite values (`stat_density()`).\n\n\n\n\nNote that as the plot_density_data() function returns a ggplot, it can be further customised with other ggplot2 functions as shown above.\n\n4.3.3 Datasets mean-sd plots\nIt is also possible to assess for each dataset whether there exists a relationship between the features mean and standard deviation, with the plot_meansd_data() function. The presence of such relationship indicates that the dataset should be transformed, via a log or variance-stabilising transformation. The function requires the hexbin package to be installed:\n\nplot_meansd_data(mo_set)\n\n\n\n\nIn our case, we can see a very strong relationship between features mean and standard deviation in both the transcriptomics and metabolomics datasets, which suggest that a log or variance-stabilising transformation will be necessary in both cases (datasets transformation are covered in Chapter 6).\nNote that the hexplots are only drawn for datasets with at least 30 features, and the trend curve (in pink) is only drawn for datasets with at least 10 features."
  },
  {
    "objectID": "inspecting_multidataset.html#assessing-missing-values",
    "href": "inspecting_multidataset.html#assessing-missing-values",
    "title": "4  Inspecting the MultiDataSet object",
    "section": "\n4.4 Assessing missing values",
    "text": "4.4 Assessing missing values\nFinally, one very important aspect to check is the presence of missing values in the datasets. The function check_missing_values() provide a summary of the number of missing values in each dataset:\n\ncheck_missing_values(mo_set)\n#> 9615 (0.3%) missing values in snps dataset, across 4093 features and 139 samples.\n#> No missing values in rnaseq dataset.\n#> 588 (7.69%) missing values in metabolome dataset, across 15 features and 45 samples.\n\nThe function returns an invisible character vector containing the messages printed above, which is useful for automatic reporting.\nIn Chapter 6, we will see how to impute missing values."
  },
  {
    "objectID": "inspecting_multidataset.html#visualising-the-datasets",
    "href": "inspecting_multidataset.html#visualising-the-datasets",
    "title": "4  Inspecting the MultiDataSet object",
    "section": "\n4.5 Visualising the datasets",
    "text": "4.5 Visualising the datasets\nOnce the omics datasets are stored in a MultiDataSet object, we can easily visualise the measurements for a set of features of interest. As an example, we will randomly select three features from each of the omics datasets:\n\nset.seed(32)\nrandom_features <- get_features(mo_set) |>\n  map(\\(x) sample(x, size = 3, replace = FALSE)) |>\n  unlist() |>\n  unname()\n\nrandom_features\n#> [1] \"ARS-BFGL-NGS-102169_dup\" \"BovineHD0300020059\"     \n#> [3] \"BTB-01546164\"            \"ENSBTAG00000038316\"     \n#> [5] \"ENSBTAG00000016902\"      \"ENSBTAG00000048333\"     \n#> [7] \"HMDB00214\"               \"HMDB00407\"              \n#> [9] \"HMDB00182\"\n\n\n4.5.1 As a heatmap\nThe function plot_data_heatmap() allows us to view the data for these features as a heatmap. It relies on the ComplexHeatmap::Heatmap() function, and can be customised by passing arguments to this function (for example to remove the column labels):\n\nplot_data_heatmap(\n  mo_set,\n  random_features,\n  center = TRUE,\n  scale = TRUE,\n  show_column_names = FALSE\n)\n#> Warning: Not enough data to calculate distance between samples, disabling\n#> clustering of columns.\n\n\n\n\nNote that we specified that the data should be centred and scaled before plotting, to represent features from different datasets on a similar scale.\nBy default, all samples all represented, including those that are only present in some of the omics datasets (hence the warning about columns clustering). We can instead restrict the plot to only samples that are present across all datasets (only_common_samples argument), or to specific samples by passing a list of samples ID to the samples argument:\n\nplot_data_heatmap(\n  mo_set,\n  random_features,\n  center = TRUE,\n  scale = TRUE,\n  show_column_names = FALSE,\n  samples = c(\"O4713\", \"Y3660\", \"R5979\")\n)\n\n\n\n\nWe can also add samples and/or features information to the sides of the heatmap through the samples_info and features_info arguments. These two arguments take a vector of column names from the samples or features metadata table, respectively. The ComplexHeatmap::Heatmap() picks random colours for these annotations, but we can set specific colour palettes by passing a list of colour palettes through the argument colours_list. For continuous annotations, the colour palette must be generated with circlize::colorRamp2().\n\nplot_data_heatmap(\n  mo_set,\n  random_features,\n  center = TRUE,\n  scale = TRUE,\n  show_column_names = FALSE,\n  only_common_samples = TRUE,\n  samples_info = c(\"status\", \"day_on_feed\"),\n  features_info = c(\"chromosome\"),\n  colours_list = list(\n    \"status\" = c(\"Control\" = \"gold\", \"BRD\" = \"lightblue\"),\n    \"day_on_feed\" = colorRamp2(c(5, 70), c(\"white\", \"pink3\"))\n  )\n)\n\n\n\n\nWe can also use information from the features metadata tables to give a more meaningful label to the features. For example, we can use the column Name from the transcriptomics features metadata and the column name from the metabolomics features metadata to label the features. This is done by passing a named list through the label_cols argument, where each element is the name of the column to use and the name of the element gives the name of the dataset in the MultiDataSet object. If these labels are too long, we can truncate them through the truncate argument (see the function help).\n\nplot_data_heatmap(\n  mo_set,\n  random_features,\n  center = TRUE,\n  scale = TRUE,\n  show_column_names = FALSE,\n  only_common_samples = TRUE,\n  samples_info = c(\"status\", \"day_on_feed\"),\n  features_info = c(\"chromosome\"),\n  colours_list = list(\n    \"status\" = c(\"Control\" = \"gold\", \"BRD\" = \"lightblue\"),\n    \"day_on_feed\" = colorRamp2(c(5, 70), c(\"white\", \"pink3\"))\n  ),\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  truncate = 20\n)\n\n\n\n\nNote that because we didn’t include the snps dataset in the list passed through label_cols, the ID of the features are used as labels.\n\n4.5.2 Against samples covariates\nAlternatively, we can display the features’ measurements against some samples covariate, with the plot_data_covariate() function. As for the plot_data_heatmap() function, the plot shows data from all samples, unless otherwise specified (through either the common_samples_only or samples arguments). The covariate is specified as a column name from the samples metadata (can be from any dataset’s samples metadata). If the covariate is categorical, the function generates violin plots. For example, we can represent the feature’s measurements against the animal disease status:\n\nplot_data_covariate(\n  mo_set,\n  \"status\",\n  random_features,\n  only_common_samples = TRUE\n)\n\n\n\n\nWe can use other columns from the samples metadata to customise the points colour and shape. For the colour, the constructed plot will depend on whether the corresponding in categorical or numeric:\n\nplot_data_covariate(\n  mo_set,\n  \"status\",\n  random_features,\n  only_common_samples = TRUE,\n  colour_by = \"feedlot\",\n  shape_by = \"feedlot\"\n)\n\n\n\n\nplot_data_covariate(\n  mo_set,\n  \"status\",\n  random_features,\n  only_common_samples = TRUE,\n  colour_by = \"day_on_feed\",\n  shape_by = \"feedlot\"\n)\n\n\n\n\nIf instead the covariate is numerical, the function produces scatterplots with a loess curve for each feature:\n\nplot_data_covariate(\n  mo_set,\n  \"day_on_feed\",\n  random_features,\n  only_common_samples = TRUE\n)\n\n\n\n\nAgain, we can use other samples information to specify the colour or shapes of the samples. Note that if the covariate used for points colour is discrete, a loess curve will be fitted for each category. If the covariate is continuous, or if changing the shape of the points, only one loess curve will be fitted for all data points.\n\nplot_data_covariate(\n  mo_set,\n  \"day_on_feed\",\n  random_features,\n  only_common_samples = TRUE,\n  colour_by = \"status\",\n  shape_by = \"status\"\n)\n\n\n\n\nplot_data_covariate(\n  mo_set,\n  \"day_on_feed\",\n  random_features,\n  only_common_samples = TRUE,\n  colour_by = \"day_on_feed\",\n  shape_by = \"feedlot\"\n)\n\n\n\n\nThe features can be renamed using features metadata through the label_cols argument in the same way that with the plot_data_heatmap() function:\n\nplot_data_covariate(\n  mo_set,\n  \"day_on_feed\",\n  random_features,\n  only_common_samples = TRUE,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  )\n)"
  },
  {
    "objectID": "inspecting_multidataset.html#recap-targets-list",
    "href": "inspecting_multidataset.html#recap-targets-list",
    "title": "4  Inspecting the MultiDataSet object",
    "section": "\n4.6 Recap – targets list",
    "text": "4.6 Recap – targets list\nAlthough we didn’t create any new target in this section, we can turn some plots into targets.\n\nTargets list for inspecting a MultiDataSet object\n\nlist(\n  ## Creating a density plot for each dataset\n  tar_target(\n    density_plots,\n    plot_density_data(\n      mo_set,\n      combined = FALSE,\n      scales = \"free\"\n    )\n  ),\n\n  ## Plotting the relationship between features mean and standard deviation\n  ## for each dataset\n  tar_target(\n    mean_sd_plots,\n    plot_meansd_data(mo_set)\n  ),\n  \n  ## Assessing missing values\n  tar_target(\n    n_missing_values,\n    check_missing_values(mo_set)\n  )\n)"
  },
  {
    "objectID": "modifying_multidataset.html#modifying-a-dataset-matrix",
    "href": "modifying_multidataset.html#modifying-a-dataset-matrix",
    "title": "5  Modifying the MultiDataSet object",
    "section": "\n5.1 Modifying a dataset matrix",
    "text": "5.1 Modifying a dataset matrix\nLet us imagine that, prior to performing the data transformation step (which we will see in Chapter 6), we want to replace all zero values in the transcriptomics dataset with a small value, to avoid issues during the log-transformation process (note that this is only to illustrate this functionality, for the actual analysis we will use a different transformation that handles zero values). We will pick this small value as half of the non-null minimum value in the dataset (which will be 0.5, since we are working with count data). We can compute the new matrix of RNAseq counts:\n\nrnaseq_mat <- get_dataset_matrix(mo_set, \"rnaseq\")\nrnaseq_mat[1:5, 1:5]\n#>                    R9497 R5969 R5327 R5979 R9504\n#> ENSBTAG00000000005   733  1407  2919   872   740\n#> ENSBTAG00000000008     6     7     3    10    20\n#> ENSBTAG00000000009     0     1     9     0     0\n#> ENSBTAG00000000010  2693  2212  2937  2000  2345\n#> ENSBTAG00000000011     0     1     1     1     0\n\nsmall_val <- (1/2) * min(rnaseq_mat[rnaseq_mat != 0])\nsmall_val\n#> [1] 0.5\n\nnew_mat <- rnaseq_mat\nnew_mat[new_mat == 0] <- small_val\n\nnew_mat[1:5, 1:5]\n#>                     R9497 R5969 R5327  R5979  R9504\n#> ENSBTAG00000000005  733.0  1407  2919  872.0  740.0\n#> ENSBTAG00000000008    6.0     7     3   10.0   20.0\n#> ENSBTAG00000000009    0.5     1     9    0.5    0.5\n#> ENSBTAG00000000010 2693.0  2212  2937 2000.0 2345.0\n#> ENSBTAG00000000011    0.5     1     1    1.0    0.5\n\nIn order to replace the rnaseq dataset stored in the MultiDataSet object with this new matrix, we pass both the object and the new matrix to the replace_dataset() function, along with the name of the omics dataset whose matrix should be replaced:\n\nmo_set_modif <- replace_dataset(mo_set, \"rnaseq\", new_mat)\n\n## Checking that the replacement has been done\nget_dataset_matrix(mo_set_modif, \"rnaseq\")[1:5, 1:5]\n#>                     R9497 R5969 R5327  R5979  R9504\n#> ENSBTAG00000000005  733.0  1407  2919  872.0  740.0\n#> ENSBTAG00000000008    6.0     7     3   10.0   20.0\n#> ENSBTAG00000000009    0.5     1     9    0.5    0.5\n#> ENSBTAG00000000010 2693.0  2212  2937 2000.0 2345.0\n#> ENSBTAG00000000011    0.5     1     1    1.0    0.5\n\nNote that this only works for modifying the values within an omics dataset, and not for filtering, since both features and samples number and IDs in the new dataset matrix should match the ones in the original matrix:\n\nmo_set_modif <- replace_dataset(mo_set, \"rnaseq\", new_mat[1:10, 1:10])\n#> Error in replace_dataset(mo_set, \"rnaseq\", new_mat[1:10, 1:10]): 'new_data' argument has incorrect dimensions. Should have 20335 rows (features) and 143 columns (samples).\n\n\nClick here to see a targets version of the code.\n\nlist(\n  ## Replacing zero values in RNAseq dataset\n  ## (note that it is more tidy to write a function for that and call it here)\n  tar_target(\n    rnaseq_mat_nozero,\n    {\n      rnaseq_mat <- get_dataset_matrix(mo_set, \"rnaseq\")\n      small_val <- (1/2) * min(rnaseq_mat[rnaseq_mat != 0])\n      new_mat <- rnaseq_mat\n      new_mat[new_mat == 0] <- small_val\n\n      new_mat\n    }\n  ),\n\n  ## Replacing RNAseq dataset in MultiDataSet object\n  tar_target(\n    mo_set_rnaseq_nozero,\n    replace_dataset(mo_set, \"rnaseq\", rnaseq_mat_nozero)\n  )\n)"
  },
  {
    "objectID": "modifying_multidataset.html#adding-information-to-features-metadata",
    "href": "modifying_multidataset.html#adding-information-to-features-metadata",
    "title": "5  Modifying the MultiDataSet object",
    "section": "\n5.2 Adding information to features metadata",
    "text": "5.2 Adding information to features metadata\nIn the case of the transcriptomics dataset, we extracted the features metadata directly from a GFF file, which provides information about the genome annotation used. However, we might want to add information about the genes from a different source. We could add this information to the data-frame generated with import_fmetadata_gff() (see Section 3.3.3) before creating theMultiDataSet object, but we will demonstrate here how to add information once we’ve already created the object. Note that we will use targets for this example, as we will incorporate these changes in our analysis pipeline.\nLet’s start by reading in the differential expression results:\n\nlist(\n  tar_target(\n    rnaseq_de_res_file,\n    system.file(\n      \"extdata/transcriptomics_de_results.csv\",\n      package = \"moiraine\"\n    ),\n    format = \"file\"\n  ),\n\n  tar_target(\n    rnaseq_de_res_df,\n    read_csv(rnaseq_de_res_file) |>\n      rename(feature_id = gene_id) |>\n      mutate(dataset = \"rnaseq\")\n  )\n)\n\nNotice that in the results file, the gene IDs are stored in the gene_id column. Here, we rename this column as feature_id, which is required for adding it to the features metadata. In addition, we create a dataset column which contains the name of the dataset in the MultiDataSet object to which the features belong. This is also necessary.\nThe differential results look like this:\n\ntar_read(rnaseq_de_res_df) |>\n  head()\n#> # A tibble: 6 × 9\n#>   feature_id  log_fc log_cpm     f  p_value      fdr de_signif de_status dataset\n#>   <chr>        <dbl>   <dbl> <dbl>    <dbl>    <dbl> <chr>     <chr>     <chr>  \n#> 1 ENSBTAG000…   4.61    4.19  358. 5.32e-40 5.93e-36 DE        upregula… rnaseq \n#> 2 ENSBTAG000…   3.80    6.83  356. 6.33e-40 5.93e-36 DE        upregula… rnaseq \n#> 3 ENSBTAG000…   5.41    2.24  347. 2.41e-39 1.50e-35 DE        upregula… rnaseq \n#> 4 ENSBTAG000…   4.34    3.52  344. 3.40e-39 1.59e-35 DE        upregula… rnaseq \n#> 5 ENSBTAG000…   2.18    6.74  327. 4.05e-38 1.52e-34 DE        upregula… rnaseq \n#> 6 ENSBTAG000…  -1.31    2.64  316. 2.39e-37 7.48e-34 Not DE    Not DE    rnaseq\n\nWe can now use the add_features_metadata() function to add this table to the features metadata of the transcriptomics dataset. The new MultiDataSet object that includes information about the differential expression results will be saved in the mo_set_de target:\n\ntar_target(\n  mo_set_de,\n  add_features_metadata(mo_set, rnaseq_de_res_df)\n)\n\nThe new information has been added to the features metadata of the transcriptomics dataset.\n\ntar_read(mo_set_de) |>\n  get_features_metadata() |>\n  pluck(\"rnaseq\") |>\n  head()\n#>                            feature_id chromosome    start      end  width\n#> ENSBTAG00000000005 ENSBTAG00000000005         17 65389743 65505336 115594\n#> ENSBTAG00000000008 ENSBTAG00000000008         29 32214439 32244810  30372\n#> ENSBTAG00000000009 ENSBTAG00000000009         18 12338037 12342272   4236\n#> ENSBTAG00000000010 ENSBTAG00000000010         21 34209956 34223394  13439\n#> ENSBTAG00000000011 ENSBTAG00000000011          8  7950815  7971600  20786\n#> ENSBTAG00000000012 ENSBTAG00000000012         20 33708626 33732944  24319\n#>                    strand  Name\n#> ENSBTAG00000000005      +  GRK3\n#> ENSBTAG00000000008      - KCNJ1\n#> ENSBTAG00000000009      + FOXF1\n#> ENSBTAG00000000010      +  UBL7\n#> ENSBTAG00000000011      -   TDH\n#> ENSBTAG00000000012      + TTC33\n#>                                                                                                       description\n#> ENSBTAG00000000005                        G protein-coupled receptor kinase 3 [Source:VGNC Symbol;Acc:VGNC:53904]\n#> ENSBTAG00000000008 potassium inwardly rectifying channel subfamily J member 1 [Source:VGNC Symbol;Acc:VGNC:30453]\n#> ENSBTAG00000000009                                            forkhead box F1 [Source:VGNC Symbol;Acc:VGNC:29084]\n#> ENSBTAG00000000010                                           ubiquitin like 7 [Source:VGNC Symbol;Acc:VGNC:50128]\n#> ENSBTAG00000000011                                 L-threonine dehydrogenase [Source:VGNC Symbol;Acc:VGNC:108945]\n#> ENSBTAG00000000012                         tetratricopeptide repeat domain 33 [Source:VGNC Symbol;Acc:VGNC:36471]\n#>                         log_fc    log_cpm          f      p_value          fdr\n#> ENSBTAG00000000005  0.13603041  5.9051177  4.1626465 4.324808e-02 7.170137e-02\n#> ENSBTAG00000000008 -0.12965356 -0.7437052  1.0676845 3.032916e-01 3.938643e-01\n#> ENSBTAG00000000009  1.27141158 -2.5627934 23.9562951 2.731328e-06 9.665375e-06\n#> ENSBTAG00000000010  0.39567729  6.2563594 60.5303416 1.581955e-12 1.521160e-11\n#> ENSBTAG00000000011  0.07766873 -2.7608361  0.1418457 7.070363e-01 7.773874e-01\n#> ENSBTAG00000000012  0.15756169  3.6628775 11.0448775 1.141125e-03 2.623062e-03\n#>                    de_signif de_status\n#> ENSBTAG00000000005    Not DE    Not DE\n#> ENSBTAG00000000008    Not DE    Not DE\n#> ENSBTAG00000000009    Not DE    Not DE\n#> ENSBTAG00000000010    Not DE    Not DE\n#> ENSBTAG00000000011    Not DE    Not DE\n#> ENSBTAG00000000012    Not DE    Not DE\n\nNote that with this function, we can add information about features from different datasets at once, which is why there needs to be a dataset column in the data-frame to add, indicating the dataset to which each feature belongs. Also, not all features from a given dataset need to be present in this new data-frame; it is possible to add information for only a subset of them. In that case, the function will throw a warning giving the number of features from the corresponding dataset missing from the new data-frame, and the new columns in the corresponding features metadata will be filled with NA for features not present. However, it is only possible to add columns that do not already exist in the corresponding features metadata."
  },
  {
    "objectID": "modifying_multidataset.html#adding-information-to-samples-metadata",
    "href": "modifying_multidataset.html#adding-information-to-samples-metadata",
    "title": "5  Modifying the MultiDataSet object",
    "section": "\n5.3 Adding information to samples metadata",
    "text": "5.3 Adding information to samples metadata\nSimilarly, we can add a data-frame of information to the samples metadata. Here, we will create a table that contains “new” simulated information about the samples that we want to incorporate in our MultiDataSet object.\n\n## Getting the list of samples ID across the datasets\nsamples_list <- get_samples(mo_set) |>\n  unlist() |>\n  unname() |>\n  unique()\n\n## Simulating new information table, with new samples grouping\nnew_samples_df <- tibble(id = samples_list) |>\n  mutate(new_group = sample(letters[1:3], n(), replace = TRUE))\n\nhead(new_samples_df)\n#> # A tibble: 6 × 2\n#>   id    new_group\n#>   <chr> <chr>    \n#> 1 R21   b        \n#> 2 Y3660 a        \n#> 3 Y3243 a        \n#> 4 R5764 c        \n#> 5 P4669 a        \n#> 6 R5452 c\n\nNote that the sample IDs must be stored in a column named id. We will use the add_samples_metadata() function to add this new data-frame to the samples metadata in our MultiDataSet object. There are several options for which samples metadata tables should be modified; this is controlled through the datasets argument of the function. By default, the information is added to the samples metadata table of all omics datasets (case when datasets = NULL):\n\nmo_set_new_samples_info <- add_samples_metadata(mo_set, new_samples_df)\n#> Warning: snps dataset: 5 sample IDs not in 'mo_data', will be removed from\n#> samples metadata.\n#> Warning: rnaseq dataset: 1 sample IDs not in 'mo_data', will be removed from\n#> samples metadata.\n#> Warning: metabolome dataset: 5 sample IDs not in 'mo_data', will be removed\n#> from samples metadata.\n\nmo_set_new_samples_info |>\n  get_samples_metadata() |>\n  map(head)\n#> $snps\n#>          id feedlot gender  status day_on_feed rnaseq_batch geno_comp_1\n#> R21     R21      F1 female Control          31           B2    0.007853\n#> Y3660 Y3660      F1   male Control          19           B2    0.852220\n#> Y3243 Y3243      F1   male Control          16           B2    0.044171\n#> R5764 R5764      F2   male Control          46           B1    0.213094\n#> P4669 P4669      F3   male     BRD          35           B2    0.389393\n#> R5452 R5452      F2   male Control          49           B1    0.265998\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster new_group\n#> R21      0.820691    0.171456                K3         b\n#> Y3660    0.093585    0.054195                K2         a\n#> Y3243    0.190262    0.765567                K1         a\n#> R5764    0.676299    0.110607                K3         c\n#> P4669    0.503471    0.107136                K3         a\n#> R5452    0.733992    0.000010                K3         c\n#> \n#> $rnaseq\n#>          id feedlot gender status day_on_feed rnaseq_batch geno_comp_1\n#> R9497 R9497      F2   male    BRD          35           B1    0.153716\n#> R5969 R5969      F2   male    BRD          24           B1    0.110663\n#> R5327 R5327      F2   male    BRD          38           B1    0.140730\n#> R5979 R5979      F2   male    BRD          30           B1    0.286733\n#> R9504 R9504      F2   male    BRD          31           B1    0.000010\n#> R5994 R5994      F2   male    BRD          24           B1    0.129271\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster new_group\n#> R9497    0.744505    0.101779                K3         c\n#> R5969    0.625823    0.263514                K3         c\n#> R5327    0.809396    0.049874                K3         a\n#> R5979    0.107794    0.605473                K1         c\n#> R9504    0.998913    0.001077                K3         b\n#> R5994    0.034351    0.836377                K1         b\n#> \n#> $metabolome\n#>          id feedlot gender  status day_on_feed rnaseq_batch geno_comp_1\n#> R21     R21      F1 female Control          31           B2    0.007853\n#> Y3660 Y3660      F1   male Control          19           B2    0.852220\n#> Y3243 Y3243      F1   male Control          16           B2    0.044171\n#> R5764 R5764      F2   male Control          46           B1    0.213094\n#> P4669 P4669      F3   male     BRD          35           B2    0.389393\n#> R5452 R5452      F2   male Control          49           B1    0.265998\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster new_group\n#> R21      0.820691    0.171456                K3         b\n#> Y3660    0.093585    0.054195                K2         a\n#> Y3243    0.190262    0.765567                K1         a\n#> R5764    0.676299    0.110607                K3         c\n#> P4669    0.503471    0.107136                K3         a\n#> R5452    0.733992    0.000010                K3         c\n\nHowever, it is also possible to specify for which dataset(s) the changes should be made, by passing their name to the datasets argument.\n\nmo_set_new_samples_info <- add_samples_metadata(\n  mo_set, \n  new_samples_df, \n  datasets = c(\"rnaseq\", \"metabolome\")\n)\n#> Warning: rnaseq dataset: 1 sample IDs not in 'mo_data', will be removed from\n#> samples metadata.\n#> Warning: metabolome dataset: 5 sample IDs not in 'mo_data', will be removed\n#> from samples metadata.\n\nmo_set_new_samples_info |>\n  get_samples_metadata() |>\n  map(head)\n#> $snps\n#>          id feedlot gender  status day_on_feed rnaseq_batch geno_comp_1\n#> R21     R21      F1 female Control          31           B2    0.007853\n#> Y3660 Y3660      F1   male Control          19           B2    0.852220\n#> Y3243 Y3243      F1   male Control          16           B2    0.044171\n#> R5764 R5764      F2   male Control          46           B1    0.213094\n#> P4669 P4669      F3   male     BRD          35           B2    0.389393\n#> R5452 R5452      F2   male Control          49           B1    0.265998\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster\n#> R21      0.820691    0.171456                K3\n#> Y3660    0.093585    0.054195                K2\n#> Y3243    0.190262    0.765567                K1\n#> R5764    0.676299    0.110607                K3\n#> P4669    0.503471    0.107136                K3\n#> R5452    0.733992    0.000010                K3\n#> \n#> $rnaseq\n#>          id feedlot gender status day_on_feed rnaseq_batch geno_comp_1\n#> R9497 R9497      F2   male    BRD          35           B1    0.153716\n#> R5969 R5969      F2   male    BRD          24           B1    0.110663\n#> R5327 R5327      F2   male    BRD          38           B1    0.140730\n#> R5979 R5979      F2   male    BRD          30           B1    0.286733\n#> R9504 R9504      F2   male    BRD          31           B1    0.000010\n#> R5994 R5994      F2   male    BRD          24           B1    0.129271\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster new_group\n#> R9497    0.744505    0.101779                K3         c\n#> R5969    0.625823    0.263514                K3         c\n#> R5327    0.809396    0.049874                K3         a\n#> R5979    0.107794    0.605473                K1         c\n#> R9504    0.998913    0.001077                K3         b\n#> R5994    0.034351    0.836377                K1         b\n#> \n#> $metabolome\n#>          id feedlot gender  status day_on_feed rnaseq_batch geno_comp_1\n#> R21     R21      F1 female Control          31           B2    0.007853\n#> Y3660 Y3660      F1   male Control          19           B2    0.852220\n#> Y3243 Y3243      F1   male Control          16           B2    0.044171\n#> R5764 R5764      F2   male Control          46           B1    0.213094\n#> P4669 P4669      F3   male     BRD          35           B2    0.389393\n#> R5452 R5452      F2   male Control          49           B1    0.265998\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster new_group\n#> R21      0.820691    0.171456                K3         b\n#> Y3660    0.093585    0.054195                K2         a\n#> Y3243    0.190262    0.765567                K1         a\n#> R5764    0.676299    0.110607                K3         c\n#> P4669    0.503471    0.107136                K3         a\n#> R5452    0.733992    0.000010                K3         c\n\nIn both cases, the function throws some warnings to alert about samples missing from this new table, or samples that are not present in the original samples metadata table. These warnings should be checked to avoid issues due to typos, etc.\nAs with the add_features_metadata() function, it is possible to add information about only a subset of the samples; however the columns in the new data-frame must not already be present in the features metadata tables to which it will be added."
  },
  {
    "objectID": "modifying_multidataset.html#recap-targets-list",
    "href": "modifying_multidataset.html#recap-targets-list",
    "title": "5  Modifying the MultiDataSet object",
    "section": "\n5.4 Recap – targets list",
    "text": "5.4 Recap – targets list\nFor convenience, here is the list of targets that we created in this section:\n\nTargets list for modifying a MultiDataSet object\n\nlist(\n  ## RNAseq differential expression results file\n  tar_target(\n    rnaseq_de_res_file,\n    system.file(\n      \"extdata/transcriptomics_de_results.csv\",\n      package = \"moiraine\"\n    ),\n    format = \"file\"\n  ),\n\n  ## Reading the RNAseq differential expression results\n  tar_target(\n    rnaseq_de_res_df,\n    read_csv(rnaseq_de_res_file) |>\n      rename(feature_id = gene_id) |>\n      mutate(dataset = \"rnaseq\")\n  ),\n\n  ## Adding the differential expression results to the MultiDataSet object\n  tar_target(\n    mo_set_de,\n    add_features_metadata(mo_set, rnaseq_de_res_df)\n  )\n)"
  },
  {
    "objectID": "preprocessing.html#datasets-transformations",
    "href": "preprocessing.html#datasets-transformations",
    "title": "6  Data pre-processing",
    "section": "\n6.1 Datasets transformations",
    "text": "6.1 Datasets transformations\nAfter inspection of the density plots for the different datasets (see Section 4.3), it might be necessary to normalise or transform some or all datasets. This is necessary to mitigate the mean-variance trend that occurs in RNAseq data, for example, or simply to bring the different features to a comparable scale. Transformation here refers to applying a function to each feature (i.e. each row) within a dataset that will transform the measurement values for the feature.\nmoiraine implements several options to transform an omics dataset:\n\nVariance Stabilising Normalisation (VSN) through the vsn package – recommended for metabolomics datasets or other continuous datasets with a strong mean-variance trend;\nVariance Stabilising Transformation (VST) through the DESeq2 package – recommended for RNAseq data or any raw read count-type data;\nAutomatic selection of the best normalisation method for each feature through the bestNormalize package – recommended for phenotype data, and when the number of features is small (note that the selection of the normalisation method is done independently for each feature, so the same transformation might not be applied to all features);\nA selection of common normalisation methods through the bestNormalize package, including center/scale, log, exponential, square-root, arcsinh, Box Cox, Yeo-Johnson and ordered quantile transformations (see details in the bestNormalize vignette) – recommended when applying the same transformation to all features, e.g. log2 transformation or centering.\n\n\n6.1.1 Transforming a single dataset\nThe transformation of one dataset is done through the transform_dataset() function, which takes as input a MultiDataSet object, the name of the dataset to transform, and the name of the transformation to be applied, which should be one of vsn, vst-deseq2, best-normalize-auto or best-normalize-manual. For the latter, the name of the normalisation method from the BestNormalize package to use must also be supplied through the method argument.\nThe return_multidataset argument determines whether a MultiDataSet object with the corresponding dataset transformed should be returned. If it is set to FALSE, the function will instead return a list with the transformed dataset as a matrix as well as other useful information returned by the transformation function applied. It is possible to only return the transformed matrix, by setting return_matrix_only to TRUE. This can be useful to quickly assess the effects of the transformation outside of the analysis pipeline.\nFor example, we can apply the Variance Stabilising Transformation to the transcriptomics dataset:\n\ntar_load(mo_set_de)\n\nrnaseq_vst <- transform_dataset(\n  mo_set_de,\n  \"rnaseq\",\n  \"vst-deseq2\",\n  return_multidataset = FALSE\n)\n#> Applying Variance Stabilising Transformation (DESeq2) to rnaseq dataset.\n#> converting counts to integer mode\n\nThe function returns a list, with the transformed dataset as matrix in the transformed_data element. Information generated during the transformation by the DESeq2 package is stored in the info_transformation element. The name of the transformation applied is stored in the transformation element:\n\nnames(rnaseq_vst)\n#> [1] \"transformed_data\"    \"info_transformation\" \"transformation\"\n\nrnaseq_vst$transformed_data[1:5, 1:5]\n#>                        R9497     R5969     R5327     R5979     R9504\n#> ENSBTAG00000000005 10.357314 11.289047 12.070536 10.201227 10.251942\n#> ENSBTAG00000000008  4.836495  4.937948  4.375764  4.986154  5.710581\n#> ENSBTAG00000000009  3.486141  4.054636  4.983434  3.486141  3.486141\n#> ENSBTAG00000000010 12.216690 11.937084 12.079359 11.383360 11.897780\n#> ENSBTAG00000000011  3.486141  4.054636  4.005139  3.979732  3.486141\n\nrnaseq_vst$info_transformation\n#> class: DESeqTransform \n#> dim: 20335 143 \n#> metadata(1): version\n#> assays(1): ''\n#> rownames(20335): ENSBTAG00000000005 ENSBTAG00000000008 ...\n#>   ENSBTAG00000055312 ENSBTAG00000055314\n#> rowData names(6): baseMean baseVar ... dispGeneIter dispFit\n#> colnames(143): R9497 R5969 ... Y9747 Y9816\n#> colData names(1): sizeFactor\n\nrnaseq_vst$transformation\n#> [1] \"vst-deseq2\"\n\nIf we instead want to apply a log2 transformation to the dataset, we will use the best-normalize-manual transformation option instead, and we have to specify the transformation to use through the method argument; in our case, we will use the log_x method.\nThe bestNormalize::log_x() function uses by default a log base 10, but this can be changed by passing the b argument (the log base to use) to 2. We will also set a (the offset to use before log-transformation) to 0.5 – see the bestNormalize::log_x() function help for information about the parameters. By default, all bestNormalize functions standardise the transformed datasets, which we can prevent by setting standardize = FALSE:\n\nrnaseq_log2 <- transform_dataset(\n  mo_set_de,\n  \"rnaseq\",\n  \"best-normalize-manual\",\n  method = \"log_x\",\n  return_multidataset = TRUE, \n  ## Arguments passed to BestNormalize::log_x():\n  a = 0.5,\n  b = 2,\n  standardize = FALSE\n)\n#> Applying log_x transformation (bestNormalize) to rnaseq dataset.\n\nIn that case, we asked the function to return a MultiDataSet object, in which the rnaseq dataset has been transformed:\n\nrnaseq_log2\n#> Object of class 'MultiDataSet'\n#>  . assayData: 3 elements\n#>     . snps: 23036 features, 139 samples \n#>     . rnaseq: 20335 features, 143 samples \n#>     . metabolome: 55 features, 139 samples \n#>  . featureData:\n#>     . snps: 23036 rows, 13 cols (feature_id, ..., p_value)\n#>     . rnaseq: 20335 rows, 15 cols (feature_id, ..., de_signif)\n#>     . metabolome: 55 rows, 16 cols (feature_id, ..., de_signif)\n#>  . rowRanges:\n#>     . snps: YES\n#>     . rnaseq: YES\n#>     . metabolome: NO\n#>  . phenoData:\n#>     . snps: 139 samples, 10 cols (id, ..., geno_comp_3)\n#>     . rnaseq: 143 samples, 10 cols (id, ..., geno_comp_3)\n#>     . metabolome: 139 samples, 10 cols (id, ..., geno_comp_3)\n\nget_dataset_matrix(rnaseq_log2, \"rnaseq\")[1:5, 1:5]\n#>                        R9497      R5969      R5327      R5979     R9504\n#> ENSBTAG00000000005  9.518653 10.4589192 11.5115056  9.7690113  9.532356\n#> ENSBTAG00000000008  2.700440  2.9068906  1.8073549  3.3923174  4.357552\n#> ENSBTAG00000000009 -1.000000  0.5849625  3.2479275 -1.0000000 -1.000000\n#> ENSBTAG00000000010 11.395266 11.1114617 11.5203731 10.9661449 11.195680\n#> ENSBTAG00000000011 -1.000000  0.5849625  0.5849625  0.5849625 -1.000000\n\n\n6.1.2 Transformation target factory\nThe target factory function transformation_datasets_factory() provides a wrapper to apply (potentially different) transformations to several datasets at once. The function takes as input the MultiDataSet object as well as a named character vector, in which each element corresponds to a transformation that should be applied to a specific dataset. If a dataset is not present in the transformation vector, it will not be transformed (but it will still be present in the resulting MultiDataSet object).\nHere, we would like to apply Variance Stabilising Transformation to the transcriptomics dataset, and a log2 transformation to the metabolomics dataset. Note that the VST and VSN transformations are very close to the log2 transformation, especially for features with high means.\n\ntransformation_datasets_factory(\n  mo_set_de,\n  c(\"rnaseq\" = \"vst-deseq2\",\n    \"metabolome\" = \"best-normalize-manual\"),\n  methods = c(\"metabolome\" = \"log_x\"),\n  a = 0.01,\n  b = 2,\n  standardize = FALSE,\n  transformed_data_name = \"mo_set_transformed\"\n)\n\nThe transformation_datasets_factory() function works as follows:\n\nIt creates a grouped tibble listing the transformation to apply to each dataset, stored in the transformations_spec target;\n\n\ntar_read(transformations_spec)\n#> # A tibble: 2 × 4\n#>   dsn        transf                meth  tar_group\n#>   <chr>      <chr>                 <chr>     <int>\n#> 1 rnaseq     vst-deseq2            <NA>          2\n#> 2 metabolome best-normalize-manual log_x         1\n\n\nIt performs the required transformation on each dataset via dynamic branching. This is done through a call to the transform_dataset() function. The transformed datasets are stored in a list, in the transformations_runs_list target. Note that by default the function will store all details of the transformations, which can be useful for later inspection, but can be memory-intensive. It is possible to only store the transformed datasets instead, by setting the return_matrix_only argument to TRUE in the transformation_datasets_factory() call.\n\n\ntar_load(transformations_runs_list)\n\nnames(transformations_runs_list)\n#> [1] \"transformations_runs_list_7a466037\" \"transformations_runs_list_a1c8db41\"\n\nmap_chr(transformations_runs_list, attr, \"dataset_name\")\n#> transformations_runs_list_7a466037 transformations_runs_list_a1c8db41 \n#>                       \"metabolome\"                           \"rnaseq\"\n\ntransformations_runs_list[[\"transformations_runs_list_a1c8db41\"]] |> names()\n#> [1] \"transformed_data\"    \"info_transformation\" \"transformation\"\n\n\nIt creates a new MultiDataSet object, with the transformed version of the datasets. By default, this new MultiDataSet object is stored in a target called transformed_set, but a different name can be specified via the transformed_data_name argument (here we called it mo_set_transformed).\n\n\ntar_load(mo_set_transformed)\n\nmo_set_transformed\n#> Object of class 'MultiDataSet'\n#>  . assayData: 3 elements\n#>     . snps: 23036 features, 139 samples \n#>     . rnaseq: 20335 features, 143 samples \n#>     . metabolome: 55 features, 139 samples \n#>  . featureData:\n#>     . snps: 23036 rows, 13 cols (feature_id, ..., p_value)\n#>     . rnaseq: 20335 rows, 15 cols (feature_id, ..., de_signif)\n#>     . metabolome: 55 rows, 16 cols (feature_id, ..., de_signif)\n#>  . rowRanges:\n#>     . snps: YES\n#>     . rnaseq: YES\n#>     . metabolome: NO\n#>  . phenoData:\n#>     . snps: 139 samples, 10 cols (id, ..., geno_comp_3)\n#>     . rnaseq: 143 samples, 10 cols (id, ..., geno_comp_3)\n#>     . metabolome: 139 samples, 10 cols (id, ..., geno_comp_3)\n\nget_dataset_matrix(mo_set_de, \"metabolome\")[1:5, 1:3]\n#>             R21 Y3660 Y3243\n#> HMDB00001   9.1   9.7   9.3\n#> HMDB00008  58.2  22.8   9.1\n#> HMDB00042 403.0 392.0 606.0\n#> HMDB00043 172.6 163.1 165.2\n#> HMDB00060   0.7   1.5   1.4\n\nget_dataset_matrix(mo_set_de, \"metabolome\")[1:5, 1:3]\n#>             R21 Y3660 Y3243\n#> HMDB00001   9.1   9.7   9.3\n#> HMDB00008  58.2  22.8   9.1\n#> HMDB00042 403.0 392.0 606.0\n#> HMDB00043 172.6 163.1 165.2\n#> HMDB00060   0.7   1.5   1.4\n\nWe can assess the effect of the transformations by generating density and mean-sd plots for the transformed datasets:\n\nplot_density_data(\n  mo_set_transformed,\n  combined = FALSE,\n  scales = \"free\"\n)\n\n\n\n\nNote how the relationship between features mean and standard deviation has been reduced in both transformed datasets:\n\nplot_meansd_data(mo_set_transformed)\n\n\n\n\nFinally, it can be useful to summarise which transformations have been applied to the datasets, for example when creating a report. The function get_table_transformation() is here for that. It takes as an input the transformations_runs_list target generated by transformation_datasets_factory(), and returns a tibble indicating the transformation applied to each dataset:\n\nget_table_transformations(transformations_runs_list)\n#> # A tibble: 2 × 2\n#>   Dataset    Transformation                                                 \n#>   <chr>      <chr>                                                          \n#> 1 metabolome Non-Standardized Log_2(x + 0.01) transformation (bestNormalize)\n#> 2 rnaseq     Variance Stabilising Transformation (DESeq2)"
  },
  {
    "objectID": "preprocessing.html#running-a-pca-on-each-dataset",
    "href": "preprocessing.html#running-a-pca-on-each-dataset",
    "title": "6  Data pre-processing",
    "section": "\n6.2 Running a PCA on each dataset",
    "text": "6.2 Running a PCA on each dataset\nIt is always best practice to run some exploratory analysis on a dataset prior to running analyses. This is largely outside the scope of this package, and we assume that any input dataset has been properly assessed before turning to the integration pipeline. However, running a Principal Component Analysis (PCA) on each of the omics datasets within the integration pipeline serves two purposes:\n\nas a last check to ensure that there are no obvious batch effects or problematic samples that should be addressed,\nas a missing data imputation method.\n\nThe moiraine package relies on the Bioconductor pcaMethods package to perform the PCA. In particular, the pcaMethods package implements a NIPALS (non-linear iterative partial least squares) method for PCA, which allows for missing values in the input dataset, and imputes missing values based on the results of the PCA.\n\n6.2.1 Running the PCAs\nThe pca_complete_data_factory() function uses dynamic branching to perform a PCA on each omics dataset within a MultiDataSet object. It takes as input the MultiDataSet object (in our case, mo_set_transformed), and, optionally, the names of the datasets on which a PCA should be run. This is useful if one dataset is very large and has no missing values, and we want to avoid running a PCA on it. It then proceeds as follows:\n\nIt creates a target called dataset_names_pca, which stores a vector of dataset names on which a PCA should be applied;\nFor each value in dataset_names_pca, it extracts the omics dataset as a matrix with features as rows and samples as columns, using the get_dataset_matrix() function. This is done via dynamic branching, and the results are stored as a list in the pca_mats_list target. Note that the names of this list are not meaningful; to check which element of the list corresponds to which dataset, you can run map_chr(pca_mats_list, attr, \"dataset_name\");\nFor each matrix in pca_mats_list, it applies the run_pca_matrix() function to the corresponding dataset. This is done via dynamic branching; it results in a list where each element is the PCA result (i.e. a pcaMethods::pcaRes object) for a given dataset. This list is stored in the pca_runs_list target. Note that the names of this list are not meaningful; to check which element of the list corresponds to which dataset, you can run map_chr(pca_runs_list, attr, \"dataset_name\");\nIt extracts from the result of each PCA the complete dataset, i.e. with missing values imputed, and uses this information to construct a new MultiDataSet object, in which the datasets are complete (i.e. no missing value). This is done by calling the get_complete_data() function. If no PCA was run on a dataset, the dataset will still be present in the new MultiDataSet object, but its missing values will not be imputed. The resulting complete MultiDataSet object is stored by default in a target called complete_set; this name can be changed via the complete_data_name argument.\n\nLet’s apply this to our multi-omics dataset:\n\npca_complete_data_factory(\n  mo_set_transformed,\n  complete_data_name = \"mo_set_complete\"\n)\n\nWe can have a look at the different targets constructed. By default, a PCA was run on all datasets:\n\ntar_read(dataset_names_pca)\n#> [1] \"snps\"       \"rnaseq\"     \"metabolome\"\n\n\ntar_load(pca_mats_list)\n\nmap_chr(pca_mats_list, attr, \"dataset_name\")\n#> pca_mats_list_302d7473 pca_mats_list_84d36937 pca_mats_list_64d37e6c \n#>                 \"snps\"               \"rnaseq\"           \"metabolome\"\nmap(pca_mats_list, ~.x[1:5, 1:5])\n#> $pca_mats_list_302d7473\n#>                             R21 Y3660 Y3243 R5764 P4669\n#> 1_41768691                    1     0     2     2     1\n#> 10-27008241-A-C-rs42918694    2     2     2     1     2\n#> 10-37505419-T-C-rs136559242   0     1     0     2     0\n#> 10-49904259-G-A-rs471723345   1     2     2     2     2\n#> 1-109550832-G-A-rs209732846   2     2     1     2     2\n#> \n#> $pca_mats_list_84d36937\n#>                        R9497     R5969     R5327     R5979     R9504\n#> ENSBTAG00000000005 10.357314 11.289047 12.070536 10.201227 10.251942\n#> ENSBTAG00000000008  4.836495  4.937948  4.375764  4.986154  5.710581\n#> ENSBTAG00000000009  3.486141  4.054636  4.983434  3.486141  3.486141\n#> ENSBTAG00000000010 12.216690 11.937084 12.079359 11.383360 11.897780\n#> ENSBTAG00000000011  3.486141  4.054636  4.005139  3.979732  3.486141\n#> \n#> $pca_mats_list_64d37e6c\n#>                  R21     Y3660     Y3243    R5764     P4669\n#> HMDB00001  3.1874511 3.2794713 3.2187812       NA 3.6334312\n#> HMDB00008  5.8631951 4.5115945 3.1874511 2.657640 4.1626934\n#> HMDB00042  8.6546718 8.6147466 9.2431978 8.655388 7.9009272\n#> HMDB00043  7.4313722 7.3497014 7.3681572 7.707428 6.4027563\n#> HMDB00060 -0.4941091 0.5945485 0.4956952 2.908813 0.6870607\n\n\ntar_load(pca_runs_list)\n\nnames(pca_runs_list)\n#> [1] \"pca_runs_list_74d71ae8\" \"pca_runs_list_71fd94b4\" \"pca_runs_list_559272f0\"\n\nmap_chr(pca_runs_list, attr, \"dataset_name\")\n#> pca_runs_list_74d71ae8 pca_runs_list_71fd94b4 pca_runs_list_559272f0 \n#>                 \"snps\"               \"rnaseq\"           \"metabolome\"\n\nThe result of the PCA run on the genomics dataset looks like this:\n\ntar_read(pca_runs_list_74d71ae8)\n#> nipals calculated PCA\n#> Importance of component(s):\n#>                   PC1     PC2     PC3     PC4     PC5     PC6      PC7      PC8\n#> R2            0.05578 0.02881 0.01305 0.01196 0.01168 0.01005 0.009848 0.009565\n#> Cumulative R2 0.05578 0.08459 0.09765 0.10960 0.12128 0.13133 0.141175 0.150739\n#>                    PC9     PC10\n#> R2            0.009286 0.008915\n#> Cumulative R2 0.160026 0.168941\n#> 23036    Variables\n#> 139  Samples\n#> 9615     NAs ( 0.3 %)\n#> 10   Calculated component(s)\n#> Data was mean centered before running PCA \n#> Data was NOT scaled before running PCA \n#> Scores structure:\n#> [1] 139  10\n#> Loadings structure:\n#> [1] 23036    10\n\nYou can notice that there is some information about the number of principal components computed, and whether the dataset was centred and scaled before applying the PCA. This is handled by the default arguments of run_pca_matrix(), but can be specified by passing the corresponding arguments to pca_complete_data_factory(). For example, to scale the datasets before performing a PCA, we could use:\n\npca_complete_data_factory(\n  mo_set_transformed,\n  complete_data_name = \"mo_set_complete\",\n  scale = TRUE\n)\n\nFor convenience, the run_pca() function can be used to run a PCA on one of the omics datasets directly from a MultiDataSet object. It is a wrapper around the run_pca_matrix() function, and takes as input a MultiDataSet object as well as the name of the omics dataset on which a PCA should be run, e.g.:\n\nrun_pca(mo_set_de, \"rnaseq\")\n\n\n6.2.2 Visualising the PCA results\nIt is possible to get an overview of the results of each PCA. First, the function plot_screeplot_pca() displays the percentage of variance explained by the principal components computed for each dataset. It takes as input the pca_runs_list target constructed in the previous step. Note that by default, 10 components are computed for each dataset.\n\nplot_screeplot_pca(pca_runs_list)\n\n\n\n\nIn addition, the plot_samples_coordinates_pca allows us to display the samples in the reduced principal components space (the common PCA sample plot). The function returns a list of plots (one plot per dataset). By default, it shows all principal components computed for each dataset, but for clarity we will only look at the first three:\n\nplot_samples_coordinates_pca(\n  pca_runs_list,\n  pcs = 1:3\n)\n#> $snps\n\n\n\n#> \n#> $rnaseq\n\n\n\n#> \n#> $metabolome\n\n\n\n\nNote that it is possible to look at a different set of principal components for each dataset. For that, the index of the principal components should be passed to the pcs argument as a named list (where the name of each element corresponds to a dataset name), e.g.:\n\nplot_samples_coordinates_pca(\n  pca_runs_list,\n  pcs = list(\n    \"snps\" = 1:4,\n    \"rnaseq\" = 1:2,\n    \"metabolome\" = 1:3\n  )\n)\n\nBy default, the points in the sample plots are not coloured. It is however possible to colour the samples according to the information contained in the sample metadata tables available through the MultiDataset object. We can set different colours and shapes for the upper and lower plots in the scatterplot matrix, see the plot_samples_score() function for more information. For example, we can assess whether the first three principal components show any clustering of the samples according to their cluster computed from genomics similarity, disease status or feedlot (we’ll only show the results for the SNPs dataset here):\n\nplot_samples_coordinates_pca(\n  pca_runs_list,\n  datasets = \"snps\",\n  pcs = 1:3,\n  mo_data = mo_set_de,\n  colour_upper = \"geno_comp_cluster\",\n  shape_upper = \"status\",\n  colour_lower = \"feedlot\"\n) +\n  theme(legend.box = \"vertical\")\n\n\n\n\n\n6.2.3 Missing values imputation\nWe can check that the complete multi-omics set constructed has no more missing values:\n\ntar_load(mo_set_complete)\n\nmo_set_complete\n#> Object of class 'MultiDataSet'\n#>  . assayData: 3 elements\n#>     . snps: 23036 features, 139 samples \n#>     . rnaseq: 20335 features, 143 samples \n#>     . metabolome: 55 features, 139 samples \n#>  . featureData:\n#>     . snps: 23036 rows, 13 cols (feature_id, ..., p_value)\n#>     . rnaseq: 20335 rows, 15 cols (feature_id, ..., de_signif)\n#>     . metabolome: 55 rows, 16 cols (feature_id, ..., de_signif)\n#>  . rowRanges:\n#>     . snps: YES\n#>     . rnaseq: YES\n#>     . metabolome: NO\n#>  . phenoData:\n#>     . snps: 139 samples, 10 cols (id, ..., geno_comp_3)\n#>     . rnaseq: 143 samples, 10 cols (id, ..., geno_comp_3)\n#>     . metabolome: 139 samples, 10 cols (id, ..., geno_comp_3)\n\n\ncheck_missing_values(mo_set_complete)\n#> No missing values in snps dataset.\n#> No missing values in rnaseq dataset.\n#> No missing values in metabolome dataset."
  },
  {
    "objectID": "preprocessing.html#recap-targets-list",
    "href": "preprocessing.html#recap-targets-list",
    "title": "6  Data pre-processing",
    "section": "\n6.3 Recap – targets list",
    "text": "6.3 Recap – targets list\nFor convenience, here is the list of targets that we created in this section:\n\nTargets list for datasets preprocessing\n\nlist(\n  ## Applying transformations to the datasets\n  transformation_datasets_factory(\n    mo_set_de,\n    c(\"rnaseq\" = \"vst-deseq2\",\n      \"metabolome\" = \"best-normalize-manual\"),\n    methods = c(\"metabolome\" = \"log_x\"),\n    a = 0.01,\n    b = 2,\n    standardize = FALSE,\n    transformed_data_name = \"mo_set_transformed\"\n  ),\n  \n  ## Density plot for each transformed dataset\n  tar_target(\n    density_plots_transformed,\n    plot_density_data(\n      mo_set_transformed,\n      combined = FALSE,\n      scales = \"free\"\n    )\n  ),\n  \n  ## Plotting the mean-SD trend for transformed each dataset\n  tar_target(\n    mean_sd_plots_transformed,\n    plot_meansd_data(mo_set_transformed)\n  ),\n  \n  ## Summary table of the transformations applied\n  tar_target(\n    transformation_summary,\n    get_table_transformations(transformations_runs_list)\n  ),\n  \n  ## Running a PCA on each dataset\n  pca_complete_data_factory(\n    mo_set_transformed,\n    complete_data_name = \"mo_set_complete\"\n  ),\n  \n  ## PCA screeplots\n  tar_target(\n    pca_screeplots,\n    plot_screeplot_pca(pca_runs_list)\n  ),\n  \n  ## PCA sample plots\n  tar_target(\n    pca_sample_plots,\n    plot_samples_coordinates_pca(\n      pca_runs_list,\n      datasets = \"snps\",\n      pcs = 1:3,\n      mo_data = mo_set_de,\n      colour_upper = \"geno_comp_cluster\",\n      shape_upper = \"status\",\n      colour_lower = \"feedlot\"\n    )\n  )\n)"
  },
  {
    "objectID": "prefiltering.html#subsetting-samples-of-interest",
    "href": "prefiltering.html#subsetting-samples-of-interest",
    "title": "7  Dataset pre-filtering",
    "section": "\n7.1 Subsetting samples of interest",
    "text": "7.1 Subsetting samples of interest\nIt is possible that for the integration analysis, we might want to retain only a subset of samples of interest; for example to focus on a specific phenotypic group. In this section, we will see a number of ways to subset samples of interest from a MultiDataSet object.\n\n7.1.1 Based on sample IDs\nThe MultiDataSet package allows to subset a MultiDataSet object based on a vector of sample IDs. For example, here we generate a list of 10 samples to which we would like to restrict the MultiDataSet object:\n\n## Randomly selecting 10 samples\nset.seed(47)\nsamples_list <- get_samples(mo_set_complete) |>\n  unlist() |>\n  unname() |>\n  unique() |>\n  sample(10, replace = FALSE)\n\nhead(samples_list)\n#> [1] \"U5523\" \"R8953\" \"R21\"   \"G3594\" \"R107\"  \"O5245\"\n\nWe can restrict the MultiDataSet object to only these samples as follows:\n\nmo_samples_filtered <- mo_set_complete[samples_list, ]\n\nn_samples(mo_samples_filtered)\n#>       snps     rnaseq metabolome \n#>          9         10         10\n\nThe MultiDataSet object returned only contains the 10 samples of interest. One of the selected samples was not present in the genomics dataset, which is why this dataset has only 9 samples.\n\n7.1.2 Based on metadata\nAlternatively, we might want to select samples based on some information contained in the samples metadata associated with the omics datasets. Again, this option is implemented in the MultiDataSet package through the subset() function (see their vignette for more information). For this example, we want to retain only animals from feedlot 1. This information is encoded in the feedlot column from the samples metadata of the datasets:\n\nget_samples_metadata_combined(mo_set_complete) |> str()\n#> 'data.frame':    144 obs. of  10 variables:\n#>  $ id               : chr  \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n#>  $ feedlot          : chr  \"F1\" \"F1\" \"F1\" \"F2\" ...\n#>  $ gender           : chr  \"female\" \"male\" \"male\" \"male\" ...\n#>  $ status           : chr  \"Control\" \"Control\" \"Control\" \"Control\" ...\n#>  $ day_on_feed      : num  31 19 16 46 35 49 21 16 37 37 ...\n#>  $ rnaseq_batch     : chr  \"B2\" \"B2\" \"B2\" \"B1\" ...\n#>  $ geno_comp_1      : num  0.00785 0.85222 0.04417 0.21309 0.38939 ...\n#>  $ geno_comp_2      : num  0.8207 0.0936 0.1903 0.6763 0.5035 ...\n#>  $ geno_comp_3      : num  0.1715 0.0542 0.7656 0.1106 0.1071 ...\n#>  $ geno_comp_cluster: chr  \"K3\" \"K2\" \"K1\" \"K3\" ...\n\nIn the subset function, the first argument is the MultiDataSet object to subset, the second argument slot is for subsetting features based on their metadata (which we will see in the next section), and the third slot is for samples subsetting. We perform the subsetting by passing an expression, similar to what we would use with the dplyr::filter() function, i.e. we treat the column name on which to perform the subsetting as a variable name.\n\nmo_samples_filtered <- subset(mo_set_complete, , feedlot == \"F1\")\n\nn_samples(mo_samples_filtered)\n#>       snps     rnaseq metabolome \n#>         22         23         23\n\nThe MultiDataSet object returned contains only samples corresponding to animals from feedlot 1.\n\n7.1.3 Retaining common samples\nMost data integration tools only accept samples that are present in all omics datasets. When that is the case, the moiraine package will automatically remove samples that are absent from some datasets when preparing the input data for the corresponding integration tool. However, for convenience, we show here how to restrict a MultiDataSet object to only samples that are common to all datasets.\nThis is done through the commonSamples() function from the MultiDataSet package, which returns a filtered MultiDataSet object:\n\nmo_samples_filtered <- commonSamples(mo_set_complete)\n\nn_samples(mo_samples_filtered)\n#>       snps     rnaseq metabolome \n#>        135        135        135\n\nThe returned MultiDataSet object contains 135 samples which are present in all three omics datasets (which we can confirm with the Upset plot generated in Section 4.3)."
  },
  {
    "objectID": "prefiltering.html#subsetting-features-of-interest",
    "href": "prefiltering.html#subsetting-features-of-interest",
    "title": "7  Dataset pre-filtering",
    "section": "\n7.2 Subsetting features of interest",
    "text": "7.2 Subsetting features of interest\n\n7.2.1 Based on feature IDs\nAs with samples, we might want to filter a MultiDataSet object to only specific features of interest. We will randomly select feature IDs from each omics dataset:\n\nset.seed(36)\nfeatures_list <- get_features(mo_set_complete) |>\n  map(\\(x) sample(x, size = 5, replace = FALSE))\n\nstr(features_list)\n#> List of 3\n#>  $ snps      : chr [1:5] \"BovineHD0600012019\" \"BovineHD1200015003\" \"BTB-01046082\" \"BovineHD2600010539\" ...\n#>  $ rnaseq    : chr [1:5] \"ENSBTAG00000002154\" \"ENSBTAG00000009915\" \"ENSBTAG00000052111\" \"ENSBTAG00000012274\" ...\n#>  $ metabolome: chr [1:5] \"HMDB00201\" \"HMDB00641\" \"HMDB00123\" \"HMDB00294\" ...\n\nThe subset() method implemented in the MultiDataSet package can be used to restrict the omics datasets to specific features based on a list of IDs. However, this only works by directly passing the features ID in the command, as follows:\n\nmo_features_filtered <- subset(\n  mo_set_complete, \n  feature_id %in% c(\"BovineHD0600012019\", \"ENSBTAG00000002154\")\n)\n\nn_features(mo_features_filtered)\n#>       snps     rnaseq metabolome \n#>          1          1          0\n\nWhile passing a vector of feature IDs doesn’t work:\n\nfeatures_vec <- c(\"BovineHD0600012019\", \"ENSBTAG00000002154\")\nsubset(mo_set_complete, feature_id %in% features_vec)\n#> Error in .local(x, ...): feat expression could not be applied to any of the sets.\n\nThis type of subsetting is made possible with the subset_features() function in moiraine:\n\nmo_features_filtered <- subset_features(mo_set_complete, features_vec)\n\nn_features(mo_features_filtered)\n#>       snps     rnaseq metabolome \n#>          1          1          0\n\nThe subset_features() function accepts the features ID either as a vector, or as a list of vectors (typically one per dataset):\n\nmo_features_filtered <- subset_features(mo_set_complete, features_list)\nn_features(mo_features_filtered)\n#>       snps     rnaseq metabolome \n#>          5          5          5\n\n## Getting the selected IDs as a vector\nfeatures_vec <- features_list |>\n  unlist() |>\n  unname()\n\nhead(features_vec)\n#> [1] \"BovineHD0600012019\" \"BovineHD1200015003\" \"BTB-01046082\"      \n#> [4] \"BovineHD2600010539\" \"BovineHD2600008282\" \"ENSBTAG00000002154\"\n\nmo_features_filtered <- subset_features(mo_set_complete, features_vec)\nn_features(mo_features_filtered)\n#>       snps     rnaseq metabolome \n#>          5          5          5\n\n\n7.2.2 Based on metadata\nIt is also possible to subset features based on their metadata. For that, we can use the subset() function from the MultiDataSet package, as we did for samples subsetting. For example, for the transcriptomics and metabolomics dataset, we have in the features metadata a column (de_signif) that recaps the results of a differential abundance analysis on the corresponding dataset. We could decide to select only the differentially abundant compounds from this dataset. Note that it only performs the filtering for datasets that have this column in their features metadata.\n\nmo_features_filtered <- subset(mo_set_complete, de_signif == \"DE\")\n#> Warning in .local(x, ...): The following sets could not be filtered by feature\n#> id: snps\n\nn_features(mo_features_filtered)\n#>       snps     rnaseq metabolome \n#>      23036        111         30"
  },
  {
    "objectID": "prefiltering.html#features-preselection",
    "href": "prefiltering.html#features-preselection",
    "title": "7  Dataset pre-filtering",
    "section": "\n7.3 Features preselection",
    "text": "7.3 Features preselection\nIn the previous section, we saw how to restrict the MultiDataSet object to a set of features of interest. However, in a typical integration workflow, we instead want to reduce the dimensions of the omics datasets through a data-centric method that discards features least relevant to the biological problem of interest. Here, we present two approaches for features preselection: an unsupervised approach, which relies only on the omics measurements, and a supervised approach, which accounts for information we have about the samples. The choice between these two approaches will depend on the research question being investigated. Note that this preselection step is distinct from the data cleaning process that should be applied to each omics dataset, in which features with low expression or high missing values are removed. This ideally should be done before the multi-omics integration workflow constructed with moiraine, although it can be integrated in the analysis pipeline.\n\n7.3.1 Unsupervised features preselection\nIn order to reduce the number of features in the omics datasets, one option is to only retain the most variable features from each dataset. We refer to this approach as unsupervised preselection, as it only relies on the omics measurements to discard irrelevant features. In the package, two metrics of feature variability are implemented: the coefficient of variation (COV), and the Median Absolute Deviation (MAD). Careful consideration is required when determining which of these metrics should be used to select the most variable features, as each has some drawbacks. In particular:\n\nFiltering based on COV will retain features that are only present in very few samples. This might be problematic for noisy datasets in which some features are technical artefacts, or if we are looking for biomarkers that are expressed across all observations.\nFiltering based on MAD will discard any feature that is absent in more than half of the observations. This might be problematic if for example we are comparing two groups with unbalanced size, and we are looking for group-specific biomarkers.\n\nTherefore, a first step of data cleaning to remove artefact features, as well as consideration of the biological research question, is needed before proceeding.\nThe feature_preselection_cov_factory() and feature_preselection_mad_factory() functions allow us to perform unsupervised COV- or MAD-based preselection for some or all datasets within a MultiDataSet object. It provides two options to set the desired size of the filtered datasets: we can either specify the number of features to retain in each dataset (via the to_keep_ns argument), or the proportion of features that should be kept in each dataset (via the to_keep_props argument). For example, let’s say that we want to retain 1,000 features with the highest MAD score in both the genomics and transcriptomics datasets (as the metabolomics dataset contains only 55 compounds, no preselection will be applied to it):\n\nfeature_preselection_mad_factory(\n  mo_samples_complete,\n  to_keep_ns = c(\"snps\" = 1000, \"rnaseq\" = 1000),\n  with_ties = TRUE,\n  filtered_set_target_name = \"mo_presel_unsupervised\"\n)\n\nThe feature_preselection_mad_factory works as follows:\n\nit creates a grouped tibble in which each row is one of the datasets to be filtered, with the number or proportion of features to retain. It is stored in the mad_spec target:\n\n\ntar_read(mad_spec)\n#> # A tibble: 2 × 4\n#>   dsn      tkn wt    tar_group\n#>   <chr>  <dbl> <lgl>     <int>\n#> 1 snps    1000 TRUE          2\n#> 2 rnaseq  1000 TRUE          1\n\n\nit uses dynamic branching over the grouped tibble to extract each omics dataset as a matrix via the get_dataset_matrix() function. The result of this target, called mad_mat, is a list where each element is a matrix of omics measurements. The names of this list are specific to the dynamic branching, but the name of the omics dataset to which each matrix belongs is stored in their 'dataset_name' attribute:\n\n\ntar_load(mad_mat)\n\nmap_chr(mad_mat, attr, \"dataset_name\")\n#> mad_mat_e428ef62 mad_mat_d5a0e3cc \n#>         \"rnaseq\"           \"snps\"\nmap(mad_mat, \\(x) x[1:5, 1:5])\n#> $mad_mat_e428ef62\n#>                        R9497     R5969     R5327     R5979     R9504\n#> ENSBTAG00000000005 10.357314 11.289047 12.070536 10.201227 10.251942\n#> ENSBTAG00000000008  4.836495  4.937948  4.375764  4.986154  5.710581\n#> ENSBTAG00000000009  3.486141  4.054636  4.983434  3.486141  3.486141\n#> ENSBTAG00000000010 12.216690 11.937084 12.079359 11.383360 11.897780\n#> ENSBTAG00000000011  3.486141  4.054636  4.005139  3.979732  3.486141\n#> \n#> $mad_mat_d5a0e3cc\n#>                             R21 Y3660 Y3243 R5764 P4669\n#> 1_41768691                    1     0     2     2     1\n#> 10-27008241-A-C-rs42918694    2     2     2     1     2\n#> 10-37505419-T-C-rs136559242   0     1     0     2     0\n#> 10-49904259-G-A-rs471723345   1     2     2     2     2\n#> 1-109550832-G-A-rs209732846   2     2     1     2     2\n\n\nit uses dynamic branching over the list of matrices to perform the prefiltering for each dataset, by calling the select_features_mad_matrix() function. The function computes the MAD coefficient of each feature, then selects the features with the highest absolute MAD values. The with_ties argument determines whether more features than requested by to_keep_ns or to_keep_props should be kept if several features at the limit of selection have identical MAD values. The select_features_mad_matrix() function returns a tibble with the MAD coefficient of each feature in the dataset, as well as an indicator of whether the feature was retained or not. This is useful to produce some diagnostic plots, for example with the plot_feature_preselection_mad() function. The results of the prefiltering are stored as a list in the target called individual_mad_values.\n\n\ntar_load(individual_mad_values)\n\nmap_chr(individual_mad_values, attr, \"dataset_name\")\n#> individual_mad_values_0bdea42a individual_mad_values_19c0eba7 \n#>                       \"rnaseq\"                         \"snps\"\n\nmap(individual_mad_values, head, 3)\n#> $individual_mad_values_0bdea42a\n#> # A tibble: 3 × 3\n#>   feature_id           mad selected\n#>   <chr>              <dbl> <lgl>   \n#> 1 ENSBTAG00000049569  3.55 TRUE    \n#> 2 ENSBTAG00000048835  3.53 TRUE    \n#> 3 ENSBTAG00000051412  3.48 TRUE    \n#> \n#> $individual_mad_values_19c0eba7\n#> # A tibble: 3 × 3\n#>   feature_id                    mad selected\n#>   <chr>                       <dbl> <lgl>   \n#> 1 1_41768691                   1.48 TRUE    \n#> 2 10-27008241-A-C-rs42918694   1.48 TRUE    \n#> 3 10-37505419-T-C-rs136559242  1.48 TRUE\n\n\nIt creates a new MultiDataSet object in which the relevant datasets have been filtered to only contain the selected features, via get_filtered_dataset_variability(). By default, the target used to store this object is called filtered_set_mad, but this can be changed via the filtered_set_target_name argument (here we called it mo_presel_unsupervised instead).\n\n\ntar_read(mo_presel_unsupervised)\n#> Object of class 'MultiDataSet'\n#>  . assayData: 3 elements\n#>     . snps: 12618 features, 139 samples \n#>     . rnaseq: 1000 features, 143 samples \n#>     . metabolome: 55 features, 139 samples \n#>  . featureData:\n#>     . snps: 12618 rows, 13 cols (feature_id, ..., p_value)\n#>     . rnaseq: 1000 rows, 15 cols (feature_id, ..., de_signif)\n#>     . metabolome: 55 rows, 16 cols (feature_id, ..., de_signif)\n#>  . rowRanges:\n#>     . snps: YES\n#>     . rnaseq: YES\n#>     . metabolome: NO\n#>  . phenoData:\n#>     . snps: 139 samples, 10 cols (id, ..., geno_comp_3)\n#>     . rnaseq: 143 samples, 10 cols (id, ..., geno_comp_3)\n#>     . metabolome: 139 samples, 10 cols (id, ..., geno_comp_3)\n\nThe plot_feature_preselection_mad() function can be used to visualise the distribution of MAD values across each (non-filtered) dataset and the minimum MAD value retained in the filtered datasets:\n\nplot_feature_preselection_mad(individual_mad_values)\n\n\n\n\nIf we instead wanted to retain 50% of all features both the genomics and transcriptomics datasets, we would write:\n\nfeature_preselection_mad_factory(\n  mo_samples_complete,\n  to_keep_props = c(\"rnaseq\" = 0.5, \"metabolome\" = 0.5),\n  with_ties = TRUE,\n  filtered_set_target_name = \"mo_presel_unsupervised\"\n)\n\nNote that the feature_preselection_cov_factory() function works in exactly the same way, but calls the select_features_cov_matrix() function, and the results can be visualised with the plot_feature_preselection_cov() function.\nFor convenience, the select_features_mad() and select_features_cov() functions can be used to perform a MAD- or COV-based prefiltering on one of the omics datasets directly from a MultiDataSet object. These are wrappers around the select_features_mad_matrix() and select_features_cov_matrix() functions, respectively, and take as input a MultiDataSet object as well as the name of the omics dataset on which the preselection should be run, as well as either the number or proportion of features to retain, e.g.:\n\nselect_features_mad(mo_set_complete, \"rnaseq\", to_keep_n = 1000)\nselect_features_mad(mo_set_complete, \"rnaseq\", to_keep_prop = 0.5)\n\n\n7.3.2 Supervised features preselection\nAnother approach to features preselection can be preferred when we are trying to assess the features most relevant to an outcome of interest or to differences between sample groups. In this scenario, prior to integrating the datasets, it could be useful to reduce the size of the datasets by filtering out the features that are least associated with the outcome of interest. In this case, we can use some single-omics feature selection method to perform a first “crude” prefiltering.\nmoiraine relies on the sPLS-DA algorithm implemented in the mixOmics package for this. sparse Partial Least-Squares Discriminant Analysis (or sPLS-DA for short) is a feature selection method that aims to detect, in a multivariate dataset, the variables or features that best discriminate a categorical outcome of interest in the observations. The advantages of sPLS-DA is that it can handle datasets in which there are more features than samples, which is typically the case in omics datasets. More information can be found in Lê Cao, Boitard, and Besse (2011) or in the mixOmics vignette. By running an sPLS-DA analysis on each dataset separately, we can remove the features that are least informative with respect to the trait or outcome of interest. We refer to this approach as supervised preselection, as it relies on information about the samples to select the features of interest.\nThe feature_preselection_splsda_factory() function allows us to perform this supervised preselection for some or all datasets within a MultiDataSet object. It provides the option to set either the number or proportion of features to retain in each dataset, via the to_keep_ns and to_keep_props arguments. One additional argument that needs to be passed to the function is group, which gives the name of the column in the samples metadata information to be used as categorical outcome for the sPLS-DA run. This column must be present in the sample metadata of at least one of the datasets to be filtered. For this example, we will retain in each dataset 1,000 features that best discriminate the control and diseased animals. Warning: this function can take several minutes to run.\n\nfeature_preselection_splsda_factory(\n  mo_samples_complete,\n  group = \"status\",\n  to_keep_ns = c(\"snps\" = 1000, \"rnaseq\" = 1000),\n  filtered_set_target_name = \"mo_presel_supervised\"\n)\n\nThe function works as follows:\n\nit creates a grouped tibble in which each row is one of the datasets to be filtered, with the number or proportion of features to retain. It is stored in the splda_spec target:\n\n\ntar_read(splsda_spec)\n#> # A tibble: 2 × 3\n#>   dsn      tkn tar_group\n#>   <chr>  <dbl>     <int>\n#> 1 snps    1000         2\n#> 2 rnaseq  1000         1\n\n\nit uses dynamic branching over the grouped tibble to generate for each omics dataset the necessary input for the mixOmics package, via the get_input_splsda() function. The result, stored in the individual_splsda_input target, is a list of sPLS-DA inputs, i.e. a list itself containing the omics dataset as a matrix (with samples as rows and features as columns) and a vector indicating the grouping of the samples:\n\n\ntar_load(individual_splsda_input)\n\nmap(individual_splsda_input, names)\n#> $individual_splsda_input_a82e0f4d\n#> [1] \"rnaseq\" \"Y\"     \n#> \n#> $individual_splsda_input_de775b91\n#> [1] \"snps\" \"Y\"\nmap(individual_splsda_input, \\(x) head(x[[\"Y\"]]))\n#> $individual_splsda_input_a82e0f4d\n#> R9497 R5969 R5327 R5979 R9504 R5994 \n#>   BRD   BRD   BRD   BRD   BRD   BRD \n#> Levels: BRD Control\n#> \n#> $individual_splsda_input_de775b91\n#>     R21   Y3660   Y3243   R5764   P4669   R5452 \n#> Control Control Control Control     BRD Control \n#> Levels: BRD Control\n\n\nit uses dynamic branching to run a performance cross-validation analysis on each dataset, via the function perf_splsda() (which is essentially a wrapper for the mixOmics::perf() function). This cross-validation step selects the optimal number of components to compute for each dataset during the sPLS-DA analysis. The results of this cross-validation step are saved in a list, stored in the individual_splsda_perf target. It can take a bit of time (for this example, around 6 minutes per dataset).\n\n\ntar_load(individual_splsda_perf)\n\nmap_chr(individual_splsda_perf, attr, \"dataset_name\")\n#> individual_splsda_perf_68d22d74 individual_splsda_perf_746586a5 \n#>                        \"rnaseq\"                          \"snps\"\n\nThe cross-validation results be visualised with the plot_feature_preselection_splsda() function, in which the chosen value for the number of components to compute for each dataset is highlighted in grey:\n\nplot_feature_preselection_splsda(individual_splsda_perf)\n\n\n\n\n\nit uses dynamic branching to run sPLS-DA on each dataset, via the run_splsda() function. The results are stored as a list in the individual_splsda_run target.\n\n\nmap_chr(tar_read(individual_splsda_run), attr, \"dataset_name\")\n#> individual_splsda_run_fe6f99fe individual_splsda_run_4a7ecf19 \n#>                       \"rnaseq\"                         \"snps\"\n\n\nit creates a new MultiDataSet object in which the relevant datasets have been filtered to only contain the selected features. By default, the target used to store this object is called filtered_set_mad, but this can be changed via the filtered_set_target_name argument.\n\n\ntar_read(mo_presel_supervised)\n#> Object of class 'MultiDataSet'\n#>  . assayData: 3 elements\n#>     . snps: 1000 features, 139 samples \n#>     . rnaseq: 994 features, 143 samples \n#>     . metabolome: 55 features, 139 samples \n#>  . featureData:\n#>     . snps: 1000 rows, 13 cols (feature_id, ..., p_value)\n#>     . rnaseq: 994 rows, 15 cols (feature_id, ..., de_signif)\n#>     . metabolome: 55 rows, 16 cols (feature_id, ..., de_signif)\n#>  . rowRanges:\n#>     . snps: YES\n#>     . rnaseq: YES\n#>     . metabolome: NO\n#>  . phenoData:\n#>     . snps: 139 samples, 10 cols (id, ..., geno_comp_3)\n#>     . rnaseq: 143 samples, 10 cols (id, ..., geno_comp_3)\n#>     . metabolome: 139 samples, 10 cols (id, ..., geno_comp_3)\n\nYou can notice that with this approach, we are not guaranteed to retain exactly 1,000 features per dataset. This is because, in an sPLS-DA run, a same feature can be selected for more than one latent component, and so the number of features retained will be slightly smaller than the one requested."
  },
  {
    "objectID": "prefiltering.html#recap-targets-list",
    "href": "prefiltering.html#recap-targets-list",
    "title": "7  Dataset pre-filtering",
    "section": "\n7.4 Recap – targets list",
    "text": "7.4 Recap – targets list\nFor convenience, here is the list of targets that we created in this section:\n\nTargets list for datasets prefiltering\n\nlist(\n  ## Unsupervised feature selection based on MAD score\n  feature_preselection_mad_factory(\n    mo_set_complete,\n    to_keep_ns = c(\"snps\" = 1000, \"rnaseq\" = 1000),\n    with_ties = TRUE,\n    filtered_set_target_name = \"mo_presel_unsupervised\"\n  ),\n  \n  ## Diagnostic plot for MAD-based feature selection\n  tar_target(\n    preselection_mad_plot,\n    plot_feature_preselection_mad(individual_mad_values)\n  ),\n  \n  ## Supervised feature selection based on bruising groups\n  feature_preselection_splsda_factory(\n    mo_set_complete,\n    group = \"status\",\n    to_keep_ns = c(\"snps\" = 1000, \"rnaseq\" = 1000),\n    filtered_set_target_name = \"mo_presel_supervised\"\n  ),\n  \n  ## Diagnostic plot for sPLS-DA based feature selection\n  tar_target(\n    preselection_splsda_plot,\n    plot_feature_preselection_splsda(individual_splsda_perf)\n  )\n)\n\n\n\n\n\nLê Cao, Kim-Anh, Simon Boitard, and Philippe Besse. 2011. “Sparse PLS Discriminant Analysis: Biologically Relevant Feature Selection and Graphical Displays for Multiclass Problems.” BMC Bioinformatics 12 (1): 253. https://doi.org/10.1186/1471-2105-12-253."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Hernandez-Ferrer, Carles, Carlos Ruiz-Arenas, Alba Beltran-Gomila, and\nJuan R. González. 2017. “MultiDataSet: An r Package for\nEncapsulating Multiple Data Sets with Application to Omic Data\nIntegration.” BMC Bioinformatics 18 (1): 36. https://doi.org/10.1186/s12859-016-1455-1.\n\n\nLê Cao, Kim-Anh, Simon Boitard, and Philippe Besse. 2011. “Sparse\nPLS Discriminant Analysis: Biologically Relevant Feature Selection and\nGraphical Displays for Multiclass Problems.” BMC\nBioinformatics 12 (1): 253. https://doi.org/10.1186/1471-2105-12-253.\n\n\nLi, Jiyuan, Robert Mukiibi, Janelle Jiminez, Zhiquan Wang, Everestus C.\nAkanno, Edouard Timsit, and Graham S. Plastow. 2022. “Applying\nMulti-Omics Data to Study the Genetic Background of Bovine Respiratory\nDisease Infection in Feedlot Crossbred Cattle.” Frontiers in\nGenetics 13. https://www.frontiersin.org/articles/10.3389/fgene.2022.1046192."
  },
  {
    "objectID": "diablo.html#what-is-diablo",
    "href": "diablo.html#what-is-diablo",
    "title": "8  Data integration with DIABLO",
    "section": "\n8.1 What is DIABLO?",
    "text": "8.1 What is DIABLO?\nDIABLO (for Data Integration Analysis for Biomarker discovery using Latent Components) is a multivariate approach to perform supervised data integration. Given two or more omics datasets for which measurements are taken on the same samples, DIABLO aims at selecting correlated features across the datasets that best discriminate between the different sample groups for a categorical outcome of interest.\nDIABLO works by iteratively constructing linear combinations of the features, called latent components, which maximise the correlation between the datasets and with the categorical outcome. In order to perform feature selection, the latent components are subjected to \\(L1\\)-regularisation (or LASSO), i.e. the number of features included in the linear combination is constrained by the user. Moreover, the optimisation problem is weighted to allow the user to control the balance between maximising the correlation between omics datasets and discriminating between the outcome groups of interest.\nDIABLO requires as input the matrices of omics measurements, all with the same samples, as well as a factor variable indicating the outcome group for each sample. While the omics datasets are automatically centred and scaled by DIABLO, proper preprocessing and normalisation is assumed to be carried out by the user. Although the DIABLO algorithm can handle the presence of missing features, it will prohibit the use of cross-validation. It is thus recommended to perform data imputation prior to running a DIABLO analysis. Importantly, DIABLO tends to perform better when the number of features in the datasets is not too large. Therefore, it is highly recommended to perform some prefiltering prior to using DIABLO."
  },
  {
    "objectID": "diablo.html#creating-the-diablo-input",
    "href": "diablo.html#creating-the-diablo-input",
    "title": "8  Data integration with DIABLO",
    "section": "\n8.2 Creating the DIABLO input",
    "text": "8.2 Creating the DIABLO input\nThe first step is to transform the MultiDataSet object into a suitable format for the mixOmics package. This is done with the get_input_mixomics_supervised() function, which takes as input:\n\na MultiDataSet object,\nthe name of the column in the samples metadata table that corresponds to the categorical outcome of interest,\noptionally, the names of the datasets to include in the analysis. This is useful if we want to exclude one of more datasets from the analysis.\n\nIn our case, we want to find differences between the healthy and diseased animals. We will use the multi-omics datasets that have gone through supervised prefiltering (i.e. we discarded the features least related with the disease status, as seen in Chapter 7).\n\ntar_target(\n  diablo_input,\n  get_input_mixomics_supervised(\n    mo_presel_supervised,\n    group = \"status\"\n  )\n)\n\nImportantly, the get_input_mixomics_supervised() function only retains samples that are present in all omics datasets to be analysed. It also makes sure that the column provided as categorical outcome does not contain numerical values, as DIABLO can only handle categorical outcome. If the column contains integers, they will be considered as levels of a factor.\nThe result of the function is a named list with one element per dataset to integrate, plus a Y element that contains the categorical outcome. The omics datasets are stored as matrices with samples as rows and features as columns; the categorical outcome is a named factor vector.\n\ntar_load(diablo_input)\nstr(diablo_input)\n#> List of 4\n#>  $ snps      : num [1:135, 1:1000] 2 1 2 2 2 2 1 2 2 2 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : chr [1:135] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n#>   .. ..$ : chr [1:1000] \"21-25977541-C-T-rs41974686\" \"22-51403583-A-C-rs210306176\" \"24-12959068-G-T-rs381471286\" \"8-85224224-T-C-rs43565287\" ...\n#>   ..- attr(*, \"datatype\")= chr \"SnpSet\"\n#>   .. ..- attr(*, \"package\")= chr \"Biobase\"\n#>  $ rnaseq    : num [1:135, 1:994] 3.87 4.97 4.08 3.49 3.49 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : chr [1:135] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n#>   .. ..$ : chr [1:994] \"ENSBTAG00000000020\" \"ENSBTAG00000000046\" \"ENSBTAG00000000056\" \"ENSBTAG00000000061\" ...\n#>   ..- attr(*, \"datatype\")= chr \"ExpressionSet\"\n#>   .. ..- attr(*, \"package\")= chr \"Biobase\"\n#>  $ metabolome: num [1:135, 1:55] 3.19 3.28 3.22 3.77 3.63 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : chr [1:135] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n#>   .. ..$ : chr [1:55] \"HMDB00001\" \"HMDB00008\" \"HMDB00042\" \"HMDB00043\" ...\n#>   ..- attr(*, \"datatype\")= chr \"MetabolomeSet\"\n#>   .. ..- attr(*, \"package\")= chr \"moiraine\"\n#>  $ Y         : Factor w/ 2 levels \"BRD\",\"Control\": 2 2 2 2 1 2 2 2 2 2 ...\n#>   ..- attr(*, \"names\")= chr [1:135] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ..."
  },
  {
    "objectID": "diablo.html#constructing-the-design-matrix",
    "href": "diablo.html#constructing-the-design-matrix",
    "title": "8  Data integration with DIABLO",
    "section": "\n8.3 Constructing the design matrix",
    "text": "8.3 Constructing the design matrix\nDIABLO relies on a design matrix to balance its two optimisation objectives: maximising the covariance between the omics datasets, and maximising the discrimination between the outcome categories. The design matrix is a matrix with one row and one column per dataset, plus a row and a column for the \"Y\" dataset, i.e. the categorical outcome. The values within each cell of the matrix indicate the ratio between the two objectives for this combination of dataset. A value of 0 means that we want to prioritise outcome discrimination, while a value of 1 indicates that we want to prioritise maximising the covariance between the two corresponding datasets. All values must be between 0 and 1.\nThere are two options for constructing the design matrix, which we present below.\n\n8.3.1 Predefined design matrices\nA first option is to choose a strategy based on what we are trying to obtain from the integration:\n\nif we want to strike a balance between the two objectives (recommended option), we’ll constructed a “weighted full” design matrix that looks like this:\n\n\ndiablo_predefined_design_matrix(names(diablo_input), \"weighted_full\")\n#>            snps rnaseq metabolome Y\n#> snps        0.0    0.1        0.1 1\n#> rnaseq      0.1    0.0        0.1 1\n#> metabolome  0.1    0.1        0.0 1\n#> Y           1.0    1.0        1.0 0\n\n\nif we want to maximise the discrimination between the outcome categories, we’ll construct a “null” design matrix that looks like this:\n\n\ndiablo_predefined_design_matrix(names(diablo_input), \"null\")\n#>            snps rnaseq metabolome Y\n#> snps          0      0          0 1\n#> rnaseq        0      0          0 1\n#> metabolome    0      0          0 1\n#> Y             1      1          1 0\n\n\nif we want only to maximise the covariance between the datasets, we’ll construct a “full” design matrix that looks like this:\n\n\ndiablo_predefined_design_matrix(names(diablo_input), \"full\")\n#>            snps rnaseq metabolome Y\n#> snps          0      1          1 1\n#> rnaseq        1      0          1 1\n#> metabolome    1      1          0 1\n#> Y             1      1          1 0\n\nWe will show how to use these pre-defined design matrices when running DIABLO.\n\n8.3.2 Estimating the design matrix through pairwise PLS\nAlternatively, we can let the data guide the construction of the design matrix. This is achieved by assessing the correlation between each pair of datasets, through a PLS (Projection to Latent Structures) run. More specifically, the correlation between the datasets is computed as the correlation coefficient between the first component constructed for each dataset during the PLS run. Then, based on the correlation obtained between a pair of dataset, we can decide on a value to use for the design matrix. Typically, the following thresholds are recommended by the authors of the mixOmics package:\n\ncorrelation coefficient of 0.8 or above between two datasets: assign a value of 1 in the corresponding cell of the design matrix;\ncorrelation coefficient below 0.8: assign a value of 0.1 in the corresponding cell of the design matrix.\n\nThe diablo_pairwise_pls_factory() function automates this process. It takes as input the DIABLO input object that we constructed previously:\n\ndiablo_pairwise_pls_factory(diablo_input)\n\nThe function works as follows:\n\nIt creates a list of all possible pairs of datasets, which is stored in the diablo_pairs_datasets target:\n\n\ntar_read(diablo_pairs_datasets)\n#> [[1]]\n#> [1] \"snps\"   \"rnaseq\"\n#> \n#> [[2]]\n#> [1] \"snps\"       \"metabolome\"\n#> \n#> [[3]]\n#> [1] \"rnaseq\"     \"metabolome\"\n\n\nIt uses dynamic branching to perform a PLS run on each pair of datasets, via the run_pairwise_pls() function. The results are stored as a list in the diablo_pls_runs_list target. Each element of the list has a datasets_name attribute to indicate which datasets were analysed:\n\n\nmap(tar_read(diablo_pls_runs_list), attr, \"datasets_name\")\n#> $diablo_pls_runs_list_05fb1980\n#> [1] \"snps\"   \"rnaseq\"\n#> \n#> $diablo_pls_runs_list_1b4ec539\n#> [1] \"snps\"       \"metabolome\"\n#> \n#> $diablo_pls_runs_list_4f48d450\n#> [1] \"rnaseq\"     \"metabolome\"\n\n\nIt constructs the estimated correlation matrix between the datasets, based on the results of the PLS runs, via the diablo_get_pairwise_pls_corr() function. The resulting matrix is available through the diablo_pls_correlation_matrix target:\n\n\ntar_read(diablo_pls_correlation_matrix)\n#>                 snps    rnaseq metabolome\n#> snps       1.0000000 0.6474490  0.6294428\n#> rnaseq     0.6474490 1.0000000  0.8513394\n#> metabolome 0.6294428 0.8513394  1.0000000\n\n\nIt constructs the design matrix according to the datasets correlation matrix, through the diablo_generate_design_matrix() function. This function has parameters to customise how the correlation matrix should be translated into a design matrix, notably by setting the threshold to use on the correlation coefficients (default is 0.8, as recommended). These arguments can be customised in the diablo_pairwise_pls_factory() function. The resulting design function is stored in the target diablo_design_matrix:\n\n\ntar_read(diablo_design_matrix)\n#>            snps rnaseq metabolome Y\n#> snps        0.0    0.1        0.1 1\n#> rnaseq      0.1    0.0        1.0 1\n#> metabolome  0.1    1.0        0.0 1\n#> Y           1.0    1.0        1.0 0"
  },
  {
    "objectID": "diablo.html#choosing-the-number-of-latent-components",
    "href": "diablo.html#choosing-the-number-of-latent-components",
    "title": "8  Data integration with DIABLO",
    "section": "\n8.4 Choosing the number of latent components",
    "text": "8.4 Choosing the number of latent components\nOne important parameter that must be set when performing a DIABLO analysis is the number of latent components to construct for each dataset. The optimal number of components can be estimated by cross-validation, implemented in the mixOmics::perf() function. This function assesses the classification performance (i.e. how well the different outcome groups are separated) achieved by DIABLO for different numbers of latent components.\nChoosing the optimal number of latent components to construct is a multi-step process. The first step is to run DIABLO without feature selection, setting the number of latent components to the maximum value we wish to test. We recommend to set this to the number of groups in the categorical outcome + 2, which in our case equals 4; however this can be further refined after checking the results. For this example, we will set the maximum to 7. The function also requires as input the design matrix to be used; here we will use the one constructed from the PLS runs:\n\ntar_target(\n  diablo_novarsel,\n  diablo_run(\n    diablo_input, \n    diablo_design_matrix, \n    ncomp = 7\n  )\n)\n\nAlternatively, if we want to use one of the predefined design matrices, we can pass on one of 'null', 'weighted_full' or 'full' instead of the computed diablo_design_matrix, e.g.:\n\ntar_target(\n  diablo_novarsel,\n  diablo_run(\n    diablo_input, \n    \"weighted_full\", \n    ncomp = 7\n  )\n)\n\nThen, we call the mixOmics::perf() function on the result of this first DIABLO run. There are a number of parameters to set:\n\nvalidation: the type of cross-validation to perform, M-fold (\"Mfold\") or leave-one-out (\"loo\"). We recommend to use M-fold validation, except when the number of samples is very small.\nfolds: for M-fold cross-validation, the number of folds to construct, i.e. the number of groups in which to split the samples. Each group in turn will be considered as test set while the remaining groups will be considered the training set. The value to use depends on the number of samples in the datasets. By default, 10 is a reasonable number. For leave-one-out cross-validation, this parameter is set to the number of samples (that is the principle of leave-one-out cross-validation).\nnrepeat: the number of times the cross-validation will be repeated. This is important for M-fold cross-validation, as the way the samples are split into groups affects the results. Therefore, by repeating the cross-validation scheme we’re averaging the results over different splits, thus reducing the impact of samples splitting. We recommend at least 10 repeats. Irrelevant for leave-one-out cross-validation, so can be left to 1.\ncpus: number of CPUs to use for the computation. Useful if folds \\(\\times\\) repeats is large, as this can be computationally intensive.\n\nHere we’ll perform a 10-fold cross validation with 10 repeats.\n\ntar_target(\n  diablo_perf_res,\n  mixOmics::perf(\n    diablo_novarsel,\n    validation = \"Mfold\",\n    folds = 10,\n    nrepeat = 10,\n    cpus = 3\n  )\n)\n\nWe can visualise the results of the cross-validation with the diablo_plot_perf() function:\n\ntar_load(diablo_perf_res)\ndiablo_plot_perf(diablo_perf_res)\n\n\n\n\nThe plot displays the cross-validation results computed with several different distances and error rates:\n\nDistance: this refers to the prediction distance that is used to predict the samples group in the test set, based on the samples grouping in the training set. DIABLO tests the maximum, centroids and Mahalanobis distance. The authors of the package recommend using either the centroids or the Mahalanobis distance over the maximum distance when choosing the optimal number of components.\nError rate: this refers to the method by which the performance of the produced model is computed. DIABLO uses both the overall misclassification error rate and the balanced error rate. The authors recommend the latter, as it is is less biased towards the majority group when there is an unbalanced number of samples per group.\n\nThe function diablo_get_optim_ncomp() extracts from the cross-validation results the optimal number of components to compute, given a chosen distance and error rate. The authors of the package recommend to use the results obtained with the centroids distance and the balanced error rate; these are used by default by the diablo_get_optim_ncomp() function. In our example, the optimal number of components is:\n\ndiablo_get_optim_ncomp(diablo_perf_res)\n#> [1] 4\n\nFor ease of reuse we will save this value as a target in our analysis pipeline:\n\ntar_target(\n  diablo_optim_ncomp,\n  diablo_get_optim_ncomp(diablo_perf_res)\n)"
  },
  {
    "objectID": "diablo.html#choosing-the-number-of-features-to-retain",
    "href": "diablo.html#choosing-the-number-of-features-to-retain",
    "title": "8  Data integration with DIABLO",
    "section": "\n8.5 Choosing the number of features to retain",
    "text": "8.5 Choosing the number of features to retain\nThe next parameter to set is the number of features to retain from the different datasets for each latent component. This is usually chosen by performing cross-validation on a grid of possible values. The range of values to test depends on the type of question we are trying to answer: selecting a larger number of features might lead to a better discrimination of the outcome groups, but will be hard to manually inspect for further interpretation.\nThe function diablo_tune() provides a wrapper around the mixOmics::tune() function that performs this cross-validation. Some of the arguments are similar to the mixOmics::perf() function, e.g. validation, folds, nrepeats or cpus. In addition, we recommend setting the dist argument, which corresponds to the prediction distance metric used for performance assessment, to \"centroids.dist\" (or \"mahalanobis.dist\").\nThe keepX_list argument controls the grid of values to be tested as possible number of features to retain from each dataset. It should be in the form of a named list, with one element per dataset, and where each element is a vector of integers corresponding to the values to test. The names of the list should correspond to the names of the datasets in the MultiDataSet object. If no value is provided for keepX_list, six values ranging from 5 to 30 (by increments of 5) are tested for each dataset.\n\ntar_target(\n  diablo_tune_res,\n  diablo_tune(\n    diablo_input,\n    diablo_design_matrix,\n    ncomp = diablo_optim_ncomp,\n    validation = \"Mfold\",\n    folds = 10,\n    nrepeat = 5,\n    dist = \"centroids.dist\",\n    cpus = 3\n  )\n)\n\nThis step can be very time-consuming, especially if the grid of values to test is very large. For this example, it takes around 50 minutes to run.\nThe cross-validation results can be inspected with the diablo_plot_tune() function:\n\ntar_load(diablo_tune_res)\ndiablo_plot_tune(diablo_tune_res)\n\n\n\n\nThe visualisation shows the performance of DIABLO runs with different number of features retained from each dataset. The different runs are ordered according to their performance. Here, we can see for example that it seems preferable to retain more genes and less metabolites for component 1.\nThe optimal number of features to retain from each dataset for the different latent components is stored in the cross-validation results object, and can be accessed with:\n\ndiablo_tune_res$choice.keepX\n#> $snps\n#> [1] 25 25 30 20\n#> \n#> $rnaseq\n#> [1] 30 30 20 25\n#> \n#> $metabolome\n#> [1] 10  5 30 10\n\nFor reporting purposes, the diablo_table_optim_keepX() function displays the optimal keepX values in a table format:\n\ndiablo_table_optim_keepX(diablo_tune_res)\n#> # A tibble: 3 × 6\n#>   Dataset    `Component 1` `Component 2` `Component 3` `Component 4` Total\n#>   <chr>              <dbl>         <dbl>         <dbl>         <dbl> <dbl>\n#> 1 snps                  25            25            30            20   100\n#> 2 rnaseq                30            30            20            25   105\n#> 3 metabolome            10             5            30            10    55"
  },
  {
    "objectID": "diablo.html#final-diablo-run",
    "href": "diablo.html#final-diablo-run",
    "title": "8  Data integration with DIABLO",
    "section": "\n8.6 Final DIABLO run",
    "text": "8.6 Final DIABLO run\nOnce a value has been selected for all parameters, it is time to perform the final DIABLO run. This can be done through the diablo_run() function, which is a wrapper for the mixOmics::block.splsda() function.\n\ntar_target(\n  diablo_final_run,\n  diablo_run(\n    diablo_input,\n    diablo_design_matrix,\n    ncomp = diablo_optim_ncomp,\n    keepX = diablo_tune_res$choice.keepX\n  )\n)\n\n\ntar_load(diablo_final_run)"
  },
  {
    "objectID": "diablo.html#samples-plots",
    "href": "diablo.html#samples-plots",
    "title": "8  Data integration with DIABLO",
    "section": "\n8.7 Samples plots",
    "text": "8.7 Samples plots\nFirst, we can assess how the latent components constructed correlate across the datasets and how well they discriminate the different outcome groups.\n\n8.7.1 Correlation between datasets\nThe diablo_plot() function is adapted from the mixOmics::plotDiablo() function, and displays, for a given latent component (specified with the ncomp argument), the correlation between the samples coordinates for this latent component across the datasets. Additionally, it allows to assess how well the latent component allows to discriminate between the outcome groups in each dataset.\n\nn_comps <- diablo_get_optim_ncomp(diablo_perf_res)\nwalk(seq_len(n_comps), \\(x) diablo_plot(diablo_final_run, ncomp = x))\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere is a strong positive correlation between the first latent component of the genomics and transcriptomics dataset, and a moderate positive correlation between the first latent component of the metabolome dataset and that of the other datasets. For the second latent component, the strongest correlation is observed between the genomics and transcriptomics datasets, and the lowest one between the genomics and metabolomics datasets. As each latent component maximises the correlation between the datasets, these plots inform us about co-variation across the datasets.\n\n8.7.2 Samples projection to the latent component space\nWe can also represent the samples in the subspace spanned by the latent components for each dataset, using the mixOmics::plotIndiv() function. This function creates 2D-plots, so with more that two components, we need to plot latent components two at a time:\n\n## the combn function generates all possible combinations\n## of elements 1, 2, 3 taken two at a time\nwalk(\n  combn(seq_len(n_comps), 2, simplify = FALSE),\n  \\(x) plotIndiv(diablo_final_run,\n    comp = x,\n    ind.names = FALSE,\n    legend = TRUE,\n    legend.title = \"Phenotype group\"\n  )\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom these plots, it appears that the latent components 1 and 2 from the transcriptomics datasets are most able to separate the two phenotype groups.\nMore generally, we can plot the samples in the subspace spanned by the different components using the plot_samples_score() function. This function takes as input the DIABLO result in standardised format (from the get_output() function), and creates a matrix of scatter-plots to compare all possible pairs of components. The function also accepts a MultiDataSet object as an optional input, which can be used to enrich the plot with information about the samples extracted from the samples metadata. The plots in the resulting matrix are redundant: the lower plots (below the diagonal) are just a rotated version of the upper plots (above the diagonal); this is useful to represent several properties of the samples in one plot. For more details, see the help of the function. Here, we’ll show in the upper plots the bruising groups and replicate ID, and in the lower plots the parents of each sample.\n\nplot_samples_score(\n  diablo_output,\n  mo_data = tar_read(mo_set),\n  colour_upper = \"status\",\n  scale_colour_upper = scale_colour_brewer(palette = \"Set1\"),\n  shape_upper = \"feedlot\",\n  colour_lower = \"geno_comp_cluster\",\n  shape_lower = NULL\n) +\n  theme(legend.box = \"vertical\")\n#> Registered S3 method overwritten by 'GGally':\n#>   method from   \n#>   +.gg   ggplot2\n\n\n\n\nRemember, the get_output() function will by default compute a weighted average of the samples score across the datasets for each latent component, which is why we are seeing two latent components in the plot.\nTwo other related functions allow us to visualise the samples score in different ways. The plot_samples_score_pair() function creates a scatterplot of samples score for two user-selected latent components. The latent components must be selected by name, which we can find through:\n\nget_latent_dimensions(diablo_output)\n#> [1] \"Component 1\" \"Component 2\" \"Component 3\" \"Component 4\"\n\nAnd, as for the previous example, the MultiDataSet object can be used to enrich the plot with samples properties:\n\nplot_samples_score_pair(\n  diablo_output,\n  c(\"Component 1\", \"Component 2\"),\n  mo_data = tar_read(mo_set),\n  colour_by = \"status\",\n  shape_by = \"geno_comp_cluster\"\n) +\n  scale_colour_brewer(palette = \"Set1\")\n\n\n\n\nThe plot_samples_score_covariate() function displays the samples score for each component against a samples covariate from the samples metadata. For example, to show the distribution of samples score between the different sibling groups, we can use:\n\nplot_samples_score_covariate(\n  diablo_output,\n  mo_data = tar_read(mo_set),\n  covariate = \"status\",\n  colour_by = \"feedlot\",\n  ncol = 1\n)\n\n\n\n\nNote that the function creates different plots depending on whether the covariate is categorical (as above) or numeric. For numerical variables, it will create scatterplots, e.g.:\n\nplot_samples_score_covariate(\n  diablo_output,\n  mo_data = tar_read(mo_set),\n  covariate = \"day_on_feed\",\n  colour_by = \"feedlot\",\n  latent_dimensions = \"Component 1\"\n)"
  },
  {
    "objectID": "diablo.html#features-plots",
    "href": "diablo.html#features-plots",
    "title": "8  Data integration with DIABLO",
    "section": "\n8.8 Features plots",
    "text": "8.8 Features plots\nSecond, we can see how the features from each datasets contribute to the constructed latent components.\n\n8.8.1 Extracting the selected features\nFirst, we can extract the features that were selected for the different latent components with the function get_selected_features(), which takes as input the DIABLO results in standardised format:\n\nget_selected_features(diablo_output) |>\n  head()\n#> # A tibble: 6 × 5\n#>   feature_id         dataset latent_dimension weight importance\n#>   <chr>              <fct>   <fct>             <dbl>      <dbl>\n#> 1 ARS-BFGL-NGS-27468 snps    Component 1      -0.578      1    \n#> 2 BovineHD2300010006 snps    Component 1       0.470      0.813\n#> 3 BovineHD0300000351 snps    Component 1       0.333      0.576\n#> 4 BovineHD1900011146 snps    Component 1      -0.226      0.391\n#> 5 BovineHD0900026231 snps    Component 1      -0.216      0.373\n#> 6 BovineHD1100030384 snps    Component 1      -0.208      0.359\n\nThe function returns a tibble indicating:\n\nthe features ID;\nthe dataset from which the features originate;\nthe latent component for which the features have been selected;\nthe features’ loading for this latent component, i.e. their weight in the linear combination that constitutes the latent component;\nthe features’ importance score, i.e. their absolute weight divided by the maximum weight for the corresponding dataset and latent component.\n\nBy passing the original MultiDataSet object as input to this function, we can extract the feature metadata associated with the selected features:\n\nget_selected_features(\n  diablo_output,\n  mo_data = tar_read(mo_set)\n) |>\n  head()\n#> # A tibble: 6 × 37\n#>   feature_id      dataset latent_dimension weight importance chromosome position\n#>   <chr>           <fct>   <fct>             <dbl>      <dbl> <chr>         <dbl>\n#> 1 ARS-BFGL-NGS-2… snps    Component 1      -0.578      1     1            1.34e8\n#> 2 BovineHD230001… snps    Component 1       0.470      0.813 23           3.43e7\n#> 3 BovineHD030000… snps    Component 1       0.333      0.576 3            1.25e6\n#> 4 BovineHD190001… snps    Component 1      -0.226      0.391 19           3.78e7\n#> 5 BovineHD090002… snps    Component 1      -0.216      0.373 9            9.14e7\n#> 6 BovineHD110003… snps    Component 1      -0.208      0.359 11           1.04e8\n#> # ℹ 30 more variables: gen_train_score <dbl>, ref <chr>, alt <chr>,\n#> #   ilmn_strand <chr>, customer_strand <chr>, norm_id <dbl>, qtl_type <chr>,\n#> #   qtl_effect <dbl>, p_value <dbl>, fdr <dbl>, start <int>, end <int>,\n#> #   width <int>, strand <fct>, Name <chr>, description <chr>, hmdb_id <chr>,\n#> #   name <chr>, chemical_formula <chr>, monisotopic_molecular_weight <dbl>,\n#> #   cas_registry_number <chr>, smiles <chr>, inchikey <chr>, kegg_id <chr>,\n#> #   direct_parent <chr>, super_class <chr>, t_value <dbl>, padj <dbl>, …\n\nBy default, the get_selected_features() function returns the selected features for all datasets and latent components, but we can focus on a subset of these by passing datasets or latent components names to the datasets and latent_dimensions parameters of the function. For example, let us get the selected features from the transcriptomics and metabolomics datasets for the first latent component:\n\nget_selected_features(\n  diablo_output,\n  latent_dimensions = \"Component 1\",\n  datasets = c(\"rnaseq\", \"metabolome\"),\n  mo_data = tar_read(mo_set)\n) |>\n  head()\n#> # A tibble: 6 × 27\n#>   feature_id       dataset latent_dimension weight importance chromosome p_value\n#>   <chr>            <fct>   <fct>             <dbl>      <dbl> <chr>        <dbl>\n#> 1 ENSBTAG00000022… rnaseq  Component 1       0.487      1     26              NA\n#> 2 ENSBTAG00000050… rnaseq  Component 1       0.385      0.791 26              NA\n#> 3 ENSBTAG00000049… rnaseq  Component 1       0.316      0.649 15              NA\n#> 4 ENSBTAG00000050… rnaseq  Component 1       0.246      0.505 8               NA\n#> 5 ENSBTAG00000049… rnaseq  Component 1       0.246      0.504 3               NA\n#> 6 ENSBTAG00000010… rnaseq  Component 1       0.235      0.481 6               NA\n#> # ℹ 20 more variables: start <int>, end <int>, width <int>, strand <fct>,\n#> #   Name <chr>, description <chr>, hmdb_id <chr>, name <chr>,\n#> #   chemical_formula <chr>, monisotopic_molecular_weight <dbl>,\n#> #   cas_registry_number <chr>, smiles <chr>, inchikey <chr>, kegg_id <chr>,\n#> #   direct_parent <chr>, super_class <chr>, t_value <dbl>, padj <dbl>,\n#> #   de_signif <chr>, de_status <chr>\n\nAlternatively, the get_top_features() function facilitates the extraction of the top contributing features per dataset and latent component. The function offers two options:\n\nselect from each dataset the top N features that contribute the most to a latent component; N is set through the n_features argument of the function (note that if there are ties in the features importance all ties will be returned).\nselect from each dataset all features that have an importance score equal to or greater than a certain threshold. The threshold is set through the min_importance argument of the function.\n\nAs for the get_selected_features() function, it is possible to focus on specific datasets and/or latent components, and to pass on a MultiDataSet object to extract features metadata.\n\nget_top_features(diablo_output, n_features = 3, mo_data = tar_read(mo_set)) |>\n  head()\n#> # A tibble: 6 × 37\n#> # Groups:   latent_dimension, dataset [2]\n#>   feature_id      dataset latent_dimension weight importance chromosome position\n#>   <chr>           <fct>   <fct>             <dbl>      <dbl> <chr>         <dbl>\n#> 1 ARS-BFGL-NGS-2… snps    Component 1      -0.578      1     1            1.34e8\n#> 2 BovineHD230001… snps    Component 1       0.470      0.813 23           3.43e7\n#> 3 BovineHD030000… snps    Component 1       0.333      0.576 3            1.25e6\n#> 4 ENSBTAG0000002… rnaseq  Component 1       0.487      1     26          NA     \n#> 5 ENSBTAG0000005… rnaseq  Component 1       0.385      0.791 26          NA     \n#> 6 ENSBTAG0000004… rnaseq  Component 1       0.316      0.649 15          NA     \n#> # ℹ 30 more variables: gen_train_score <dbl>, ref <chr>, alt <chr>,\n#> #   ilmn_strand <chr>, customer_strand <chr>, norm_id <dbl>, qtl_type <chr>,\n#> #   qtl_effect <dbl>, p_value <dbl>, fdr <dbl>, start <int>, end <int>,\n#> #   width <int>, strand <fct>, Name <chr>, description <chr>, hmdb_id <chr>,\n#> #   name <chr>, chemical_formula <chr>, monisotopic_molecular_weight <dbl>,\n#> #   cas_registry_number <chr>, smiles <chr>, inchikey <chr>, kegg_id <chr>,\n#> #   direct_parent <chr>, super_class <chr>, t_value <dbl>, padj <dbl>, …\n\n\nget_top_features(diablo_output, min_importance = 0.8, mo_data = tar_read(mo_set)) |>\n  head()\n#> # A tibble: 6 × 37\n#> # Groups:   latent_dimension, dataset [3]\n#>   feature_id      dataset latent_dimension weight importance chromosome position\n#>   <chr>           <fct>   <fct>             <dbl>      <dbl> <chr>         <dbl>\n#> 1 ARS-BFGL-NGS-2… snps    Component 1      -0.578      1     1            1.34e8\n#> 2 BovineHD230001… snps    Component 1       0.470      0.813 23           3.43e7\n#> 3 ENSBTAG0000002… rnaseq  Component 1       0.487      1     26          NA     \n#> 4 HMDB00094       metabo… Component 1      -0.492      1     <NA>        NA     \n#> 5 HMDB00042       metabo… Component 1      -0.422      0.859 <NA>        NA     \n#> 6 HMDB00169       metabo… Component 1       0.403      0.820 <NA>        NA     \n#> # ℹ 30 more variables: gen_train_score <dbl>, ref <chr>, alt <chr>,\n#> #   ilmn_strand <chr>, customer_strand <chr>, norm_id <dbl>, qtl_type <chr>,\n#> #   qtl_effect <dbl>, p_value <dbl>, fdr <dbl>, start <int>, end <int>,\n#> #   width <int>, strand <fct>, Name <chr>, description <chr>, hmdb_id <chr>,\n#> #   name <chr>, chemical_formula <chr>, monisotopic_molecular_weight <dbl>,\n#> #   cas_registry_number <chr>, smiles <chr>, inchikey <chr>, kegg_id <chr>,\n#> #   direct_parent <chr>, super_class <chr>, t_value <dbl>, padj <dbl>, …\n\n\n8.8.2 Visualising the top features\nWe can also look at the loading of the features from each dataset that most contribute to each of the latent components with the function plot_top_features(). The function takes as input the formatted DIABLO output. By default, feature IDs will be used as labels, but it is possible to make use of the feature metadata in our MultiDataSet object to label the features. In this example, we select columns from the feature metadata of the transcriptomics and metabolomics datasets to get more meaningful labels, but leave the SNPs’ label to be their ID.\n\nplot_top_features(\n  diablo_output,\n  mo_data = tar_read(mo_set),\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  )\n) +\n  theme(\n    axis.text.y = element_text(size = 8)\n  )\n\n\n\n\nBy default, the function displays the top 20 features per dataset and component, but that can be changed with the n_features dataset. If less than 20 features were selected for a given dataset and component, only the select features will be shown.\nWe can investigate further these features by looking at their measurements in the datasets, with the plot_data_heatmap() or plot_data_covariate() functions (more details in the vignettes on Inspecting a MultiDataSet object). We will extract the ID of the top 3 features from each dataset for component 1 with the get_top_features() that we saw in the previous section:\n\ntop_features <- get_top_features(\n  diablo_output,\n  n_features = 3,\n  latent_dimensions = \"Component 1\"\n) |> \n  pull(feature_id)\n\ntop_features\n#> [1] \"ARS-BFGL-NGS-27468\" \"BovineHD2300010006\" \"BovineHD0300000351\"\n#> [4] \"ENSBTAG00000022715\" \"ENSBTAG00000050618\" \"ENSBTAG00000049888\"\n#> [7] \"HMDB00094\"          \"HMDB00042\"          \"HMDB00169\"\n\nWe can visualise these features as a heatmap:\n\nplot_data_heatmap(\n  tar_read(mo_presel_supervised),\n  top_features,\n  center = TRUE,\n  scale = TRUE,\n  only_common_samples = TRUE,\n  show_column_names = FALSE,\n  samples_info = \"status\",\n  colours_list = list(\n    \"status\" = c(\"Control\" = \"gold\", \"BRD\" = \"lightblue\")\n  ),\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  )\n)\n#> The automatically generated colors map from the minus and plus 99^th of\n#> the absolute values in the matrix. There are outliers in the matrix\n#> whose patterns might be hidden by this color mapping. You can manually\n#> set the color to `col` argument.\n#> \n#> Use `suppressMessages()` to turn off this message.\n\n\n\n\nor a violin plot against samples bruising group:\n\nplot_data_covariate(\n  tar_read(mo_presel_supervised), \n  \"status\",\n  top_features,\n  only_common_samples = TRUE,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  )\n)\n\n\n\n\n\n8.8.3 Correlation circle plots\nThe correlation circle plots produced by the mixOmics::plotVar() function allows to visualise the correlation between each of the selected features and the different latent components:\n\nwalk(\n  combn(seq_len(n_comps), 2, simplify = FALSE),\n  \\(x) {\n    plotVar(diablo_final_run,\n            comp = x,\n            var.names = FALSE,\n            ## If overlap = TRUE, features from the\n            ## different datasets are shown in one plot\n            overlap = FALSE,\n            pch = rep(16, 3),\n            cex = rep(2, 3)\n    )\n  } \n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe plotVar() function offers the option to show the label of the features rather than representing them as points. However, it can be more informative to use information from the feature metadata to label the features, rather than using the features’ ID. For example in the transcriptomics dataset, the ID of the transcripts is their Ensembl ID . It would be more interesting to use the name of the genes instead. This information is available in the datasets’ features metadata:\n\nget_features_metadata(tar_read(mo_set))[[\"rnaseq\"]] |>\n  head()\n#>                            feature_id chromosome    start      end  width\n#> ENSBTAG00000000005 ENSBTAG00000000005         17 65389743 65505336 115594\n#> ENSBTAG00000000008 ENSBTAG00000000008         29 32214439 32244810  30372\n#> ENSBTAG00000000009 ENSBTAG00000000009         18 12338037 12342272   4236\n#> ENSBTAG00000000010 ENSBTAG00000000010         21 34209956 34223394  13439\n#> ENSBTAG00000000011 ENSBTAG00000000011          8  7950815  7971600  20786\n#> ENSBTAG00000000012 ENSBTAG00000000012         20 33708626 33732944  24319\n#>                    strand  Name\n#> ENSBTAG00000000005      +  GRK3\n#> ENSBTAG00000000008      - KCNJ1\n#> ENSBTAG00000000009      + FOXF1\n#> ENSBTAG00000000010      +  UBL7\n#> ENSBTAG00000000011      -   TDH\n#> ENSBTAG00000000012      + TTC33\n#>                                                                                                       description\n#> ENSBTAG00000000005                        G protein-coupled receptor kinase 3 [Source:VGNC Symbol;Acc:VGNC:53904]\n#> ENSBTAG00000000008 potassium inwardly rectifying channel subfamily J member 1 [Source:VGNC Symbol;Acc:VGNC:30453]\n#> ENSBTAG00000000009                                            forkhead box F1 [Source:VGNC Symbol;Acc:VGNC:29084]\n#> ENSBTAG00000000010                                           ubiquitin like 7 [Source:VGNC Symbol;Acc:VGNC:50128]\n#> ENSBTAG00000000011                                 L-threonine dehydrogenase [Source:VGNC Symbol;Acc:VGNC:108945]\n#> ENSBTAG00000000012                         tetratricopeptide repeat domain 33 [Source:VGNC Symbol;Acc:VGNC:36471]\n\nIn order to use columns from the features metadata as feature labels in the plot, we provide the diablo_plot_var() function. It takes as an input the DIABLO result object as well as the MultiDataSet object (which contains features metadata for each dataset), and a named list providing for each dataset the name of the column in the feature metadata data-frame to use as features label:\n\ndiablo_plot_var(\n  diablo_final_run,\n  tar_read(mo_set),\n  label_cols = list(\n    \"snps\" = \"feature_id\",\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  overlap = FALSE,\n  cex = rep(2, 3),\n  comp = 1:2\n)\n\n\n\n\n\n8.8.4 Comparing features importance between latent components\nWe can also compare the importance given to the features between any two latent components with the plot_features_weight_pair() function.\n\nplot_features_weight_pair(\n  diablo_output,\n  c(\"Component 1\", \"Component 2\"),\n  mo_data = tar_read(mo_set),\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  )\n)\n\n\n\n\nIn this case, the plot is not extremely interesting, but allows us to quickly confirm that different features were selected for the two latent components. The top 5 features according to their consensus importance (see section about methods comparison) are highlighted in red.\nBy default, the function plots the signed importance score of the features, i.e. their importance score to which the sign of their weight was added. This can be changed through the features_metric argument of the function.\n\n8.8.5 Circos plot\nLastly, it is possible to represent the correlation between features from different datasets, with the mixOmics::circosPlot() function. For ease of visualisation, it only displays correlations above a certain threshold (specified via the cutoff argument)\n\ncircosPlot(\n  diablo_final_run,\n  cutoff = 0.7,\n  size.variables = 0.5\n)\n\n\n\n\nSimilarly to the correlation circle plot function, we implemented the diablo_plot_circos() function to use columns in the feature metadata of each dataset as feature labels:\n\ndiablo_plot_circos(\n  diablo_final_run,\n  tar_read(mo_set),\n  label_cols = list(\n    \"snps\" = \"feature_id\",\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  cutoff = 0.7,\n  size.variables = 0.5\n)\n\n\n\n\nThis plot is useful to identify features across the datasets with high correlations."
  },
  {
    "objectID": "diablo.html#things-to-consider",
    "href": "diablo.html#things-to-consider",
    "title": "8  Data integration with DIABLO",
    "section": "\n8.9 Things to consider",
    "text": "8.9 Things to consider\n\n8.9.1 Features pre-filtering is essential!\nIt is extremely important to perform some pre-filtering of the datasets prior to using DIABLO. Otherwise, DIABLO tends to not be able to construct latent components that can discriminate the groups efficiently. As an example, consider what happens when we don’t pre-filter our datasets for the analysis:\nsection in construction"
  },
  {
    "objectID": "diablo.html#recap-targets-list",
    "href": "diablo.html#recap-targets-list",
    "title": "8  Data integration with DIABLO",
    "section": "\n8.8 Recap – targets list",
    "text": "8.8 Recap – targets list\nFor convenience, here is the list of targets that we created in this section:\n\nTargets list for DIABLO analysis\n\nlist(\n  ## Creating the DIABLO input\n  tar_target(\n    diablo_input,\n    get_input_mixomics_supervised(\n      mo_presel_supervised,\n      group = \"status\"\n    )\n  ),\n  \n  ## Running sPLS on each dataset to construct the design matrix\n  diablo_pairwise_pls_factory(diablo_input),\n  \n  ## Initial DIABLO run with no feature selection and large number of components\n  tar_target(\n    diablo_novarsel,\n    diablo_run(\n      diablo_input,\n      diablo_design_matrix,\n      ncomp = 7\n    )\n  ),\n  \n  ## Cross-validation for number of components\n  tar_target(\n    diablo_perf_res,\n    mixOmics::perf(\n      diablo_novarsel,\n      validation = \"Mfold\",\n      folds = 10,\n      nrepeat = 10,\n      cpus = 3\n    )\n  ),\n  \n  ## Plotting cross-validation results (for number of components)\n  tar_target(\n    diablo_perf_plot,\n    diablo_plot_perf(diablo_perf_res)\n  ),\n  \n  ## Selected value for ncomp\n  tar_target(\n    diablo_optim_ncomp,\n    diablo_get_optim_ncomp(diablo_perf_res)\n  ),\n  \n  ## Cross-validation for number of features to retain\n  tar_target(\n    diablo_tune_res,\n    diablo_tune(\n      diablo_input,\n      diablo_design_matrix,\n      ncomp = diablo_optim_ncomp,\n      validation = \"Mfold\",\n      folds = 10,\n      nrepeat = 5,\n      dist = \"centroids.dist\",\n      cpus = 3\n    )\n  ),\n  \n  ## Plotting cross-validation results (for number of features)\n  tar_target(\n    diablo_tune_plot,\n    diablo_plot_tune(diablo_tune_res)\n  ),\n  \n  ## Final DIABLO run\n  tar_target(\n    diablo_final_run,\n    diablo_run(\n      diablo_input,\n      diablo_design_matrix,\n      ncomp = diablo_optim_ncomp,\n      keepX = diablo_tune_res$choice.keepX\n    )\n  )\n)"
  },
  {
    "objectID": "diablo.html#results-interpretation",
    "href": "diablo.html#results-interpretation",
    "title": "8  Data integration with DIABLO",
    "section": "\n8.7 Results interpretation",
    "text": "8.7 Results interpretation\nIn Chapter 9, we show the different functionalities implemented in the moiraine package that facilitate the interpretation of the results from an integration tool. In this section, we show some of the DIABLO-specific plots that can be generated to help interpret the results of a DIABLO run.\n\n8.7.1 Correlation between datasets\nFirst, we can assess how well the latent components correlate across the datasets. The diablo_plot() function is adapted from the mixOmics::plotDiablo() function, and displays, for a given latent component (specified with the ncomp argument), the correlation between the samples coordinates for this latent component across the datasets. Additionally, it allows to assess how well the latent components discriminate the outcome groups in each dataset.\n\nn_comp <- diablo_get_optim_ncomp(diablo_perf_res)\nwalk(\n  seq_len(n_comp), \n  \\(x) {\n    diablo_plot(diablo_final_run, ncomp = x)\n    title(paste(\"Latent component\", x))\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor the first three latent components, the strongest correlation is observed between the transcriptomics and metabolomics components, while the lowest correlation is observed between the genomics and metabolomics components. Across all three datasets, the first latent component alone is able to separate quite clearly the control and diseased animals. Note that as each latent component maximises the correlation between the datasets, these plots inform us about co-variation across the datasets.\n\n8.7.2 Samples projection to the latent component space\nWe can also represent the samples in the subspace spanned by the latent components for each dataset, using the mixOmics::plotIndiv() function. For example, we can have a look at the samples coordinates for the first two latent components:\n\nplotIndiv(\n  diablo_final_run,\n  comp = 1:2,\n  ind.names = FALSE,\n  legend = TRUE,\n  legend.title = \"Disease status\"\n)\n\n\n\n\nAs noted above, based on the first two latent components, there is a clear separation of the control and BRD animals across all three datasets.\nIdeally, we would look at all possible combinations of latent components, as follows:\n\nwalk(\n  combn(seq_len(n_comp), 2, simplify = FALSE),\n  \\(x) {\n    plotIndiv(\n      diablo_final_run,\n      comp = x,\n      ind.names = FALSE,\n      legend = TRUE,\n      legend.title = \"Phenotype group\"\n    )\n  } \n)\n\n\n8.7.3 Correlation circle plots\nThe correlation circle plots produced by the mixOmics::plotVar() function displays the contribution of the selected features to the different latent components. We will focus here on the first two latent components:\n\nplotVar(\n  diablo_final_run,\n  comp = 1:2,\n  var.names = FALSE,\n  ## If overlap = TRUE, features from the\n  ## different datasets are shown in one plot\n  overlap = FALSE,\n  pch = rep(16, 3),\n  cex = rep(2, 3)\n)\n\n\n\n\nAcross all three datasets, it seems that most selected features contribute to either one or the other latent component, but not both.\nThe plotVar() function offers the option to show the label of the features rather than representing them as points. However, it can be more informative to use information from the feature metadata as labels, rather than using the feature IDs. For example in the transcriptomics dataset, it would be more interesting to use the name of the genes. This information is available in the datasets’ features metadata:\n\ntar_load(mo_set_de)\nget_features_metadata(mo_set_de)[[\"rnaseq\"]] |>\n  str()\n#> 'data.frame':    20335 obs. of  15 variables:\n#>  $ feature_id : chr  \"ENSBTAG00000000005\" \"ENSBTAG00000000008\" \"ENSBTAG00000000009\" \"ENSBTAG00000000010\" ...\n#>  $ chromosome : Factor w/ 178 levels \"1\",\"2\",\"3\",\"4\",..: 17 29 18 21 8 20 20 5 5 23 ...\n#>  $ start      : int  65389743 32214439 12338037 34209956 7950815 33708626 33674806 74883636 74905031 27720176 ...\n#>  $ end        : int  65505336 32244810 12342272 34223394 7971600 33732944 33703223 74893752 74919112 27721739 ...\n#>  $ width      : int  115594 30372 4236 13439 20786 24319 28418 10117 14082 1564 ...\n#>  $ strand     : Factor w/ 3 levels \"+\",\"-\",\"*\": 1 2 1 1 2 1 1 2 2 2 ...\n#>  $ Name       : chr  \"GRK3\" \"KCNJ1\" \"FOXF1\" \"UBL7\" ...\n#>  $ description: chr  \"G protein-coupled receptor kinase 3 [Source:VGNC Symbol;Acc:VGNC:53904]\" \"potassium inwardly rectifying channel subfamily J member 1 [Source:VGNC Symbol;Acc:VGNC:30453]\" \"forkhead box F1 [Source:VGNC Symbol;Acc:VGNC:29084]\" \"ubiquitin like 7 [Source:VGNC Symbol;Acc:VGNC:50128]\" ...\n#>  $ log_fc     : num  0.136 -0.1297 1.2714 0.3957 0.0777 ...\n#>  $ log_cpm    : num  5.905 -0.744 -2.563 6.256 -2.761 ...\n#>  $ f          : num  4.163 1.068 23.956 60.53 0.142 ...\n#>  $ p_value    : num  4.32e-02 3.03e-01 2.73e-06 1.58e-12 7.07e-01 ...\n#>  $ fdr        : num  7.17e-02 3.94e-01 9.67e-06 1.52e-11 7.77e-01 ...\n#>  $ de_signif  : chr  \"Not DE\" \"Not DE\" \"Not DE\" \"Not DE\" ...\n#>  $ de_status  : chr  \"Not DE\" \"Not DE\" \"Not DE\" \"Not DE\" ...\n\nThe diablo_plot_var() function is a variant of plotVar(), which uses columns from the features metadata to label features plot. It takes as an input the DIABLO result object as well as the MultiDataSet object, and a named list providing for each dataset the name of the column in the feature metadata data-frame to use as features label:\n\ndiablo_plot_var(\n  diablo_final_run,\n  mo_set_de,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  overlap = FALSE,\n  cex = rep(2, 3),\n  comp = 1:2\n)\n\n\n\n\nNote that if a dataset is not present in the list passed to label_cols (here, that is the case of the genomics dataset), the feature IDs will be used as labels.\n\n8.7.4 Circos plot\nLastly, it is possible to represent the correlation between features selected from different datasets, with the mixOmics::circosPlot() function. For ease of visualisation, it only displays correlations above a certain threshold (specified via the cutoff argument). By default, it displays the features selected for all latent components, but this can be controlled via the comp argument:\n\ncircosPlot(\n  diablo_final_run,\n  cutoff = 0.7,\n  size.variables = 0.5,\n  comp = 1:2\n)\n\n\n\n\nAs for the correlation circle plot function, the diablo_plot_circos() function generates the same plot, but allows us to use columns in the feature metadata of each dataset as feature labels:\n\ndiablo_plot_circos(\n  diablo_final_run,\n  tar_read(mo_set),\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  cutoff = 0.7,\n  size.variables = 0.5,\n  comp = 1:2\n)\n\n\n\n\nThis plot is useful to identify features across the datasets with high correlations."
  }
]