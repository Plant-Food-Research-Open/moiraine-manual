[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The moiraine R package user manual",
    "section": "",
    "text": "Introduction\nOmics datasets provide an overview of the content of cells for a specific molecular layer (e.g. transcriptome, proteome, metabolome). By integrating different omics datasets obtained on the same biological samples, we can gain a deeper understanding of the interactions between these molecular layers, and shed light on the regulations occurring both within and between layers.\nA number of statistical methods have been developed to extract such information from multi-omics datasets, and many have been implemented as R packages. However, these tools differ conceptually, in terms of the input data they require, the assumptions they make, the statistical approaches they use or even the biological questions they seek to answer. They also differ at a practical level in terms of the format required for data input, the parameters to tune or select, and the format in which the results are returned. These differences render the application of several integration tools to a same multi-omics dataset and the comparison of their results complex and time-consuming.\nThe moiraine package aims at alleviating these issues, by providing a framework to easily and consistently apply different integration tools to a same multi-omics dataset. It implements numerous visualisation and reporting functions to facilitate the interpretation of the integration results as well as the comparison of these results across integration methods. In addition, in an effort to make these computations reproducible, moiraine heavily relies on the targets package for the construction of reproducible analysis pipelines."
  },
  {
    "objectID": "index.html#the-moiraine-package",
    "href": "index.html#the-moiraine-package",
    "title": "The moiraine R package user manual",
    "section": "The moiraine package",
    "text": "The moiraine package\nThe workflow for a typical multi-omics integration analysis handled with moiraine includes the following steps:\n\nData import: this covers the import of omics measurements as well as associated metadata (i.e. information about the omics features and samples) – moiraine relies on the MultiDataSet package to store this information in a consistent format;\nInspection of the omics datasets: including checking values density distribution, samples overlap between omics datasets, or presence of missing values;\nPreprocessing of the omics datasets: missing values imputation, transformation, and pre-filtering of samples and omics features;\n\nIntegration of the omics datasets by one or more of the supported tools; currently, the following integration methods are covered in moiraine:\n\nsPLS and DIABLO from the mixOmics package\nsO2PLS from the OmicsPLS package\nMOFA and MEFISTO from the MOFA2 package\n\n\nInterpretation of the integration results using standardised visualisations enriched with features and samples metadata;\nComparison of the integration results obtained by different methods or pre-processing approaches.\n\nNote that in the moiraine package, we refer to the different biological entities measured in a given dataset (e.g. genes, transcripts, metabolic compounds, etc) as features, and the observations in a dataset as samples. Samples metadata and features metadata denote information about the samples (such as treatment, collection date, etc) and features (e.g. name, biological function, etc), respectively."
  },
  {
    "objectID": "index.html#about-this-manual",
    "href": "index.html#about-this-manual",
    "title": "The moiraine R package user manual",
    "section": "About this manual",
    "text": "About this manual\nIn this manual, we are showcasing the functionalities of the moiraine package by walking through an in-depth example of a multi-omics integration analysis. We will be covering not only the functionalities of moiraine, but also discuss the different integration tools and provide recommendations for parameters setting and interpretation.\nThe moiraine package was designed to be used in the context of targets pipelines, therefore some familiarity with the targets package is necessary to follow this manual. Nevertheless, for users preferring R scripts to targets pipelines, alternative code will be provided to translate the target factories implemented in moiraine. To learn about targets, we refer readers to the excellent targets manual.\nFor clarity, throughout this manual, any code that belongs in a targets script (e.g. in the targets list in _targets.R) will be shown in a blue chunk, e.g.:\n\n\ntar_target(\n    my_first_target,\n    c(2 + 2)\n)\n\n\nAny code shown in a regular code chunk (see below) is code that should be run in the command line, or saved in a regular R script. It often showcases how to inspect a certain target output after having run tar_make() to execute the targets pipeline, e.g.:\n\nlibrary(targets)\n\ntar_read(my_first_target)\n#> [1] 4\n\nNote that for readers that prefer to use regular R scripts to targets pipelines, the target command in the example target chunk above can be converted to R script-compatible code as follows:\n\nmy_first_target <- 2 + 2\n\nand the calls to tar_read() and tar_load() ignored.\nLastly, throughout the manual, the following options are set to improve upon the default colour scales:\n\noptions(\n  ggplot2.continuous.colour = \"viridis\",\n  ggplot2.continuous.fill = \"viridis\",\n  ggplot2.discrete.colour = function() {\n    ggplot2::scale_colour_brewer(\n      palette = \"Paired\", \n      na.value = \"grey\"\n    )\n  } ,\n  ggplot2.discrete.fill = function() {\n    ggplot2::scale_fill_brewer(\n      palette = \"Paired\",\n      na.value = \"grey\"\n    )\n  } \n)"
  },
  {
    "objectID": "overview.html#input-data",
    "href": "overview.html#input-data",
    "title": "1  Overview of moiraine",
    "section": "\n1.1 Input data",
    "text": "1.1 Input data\nThe first step is to import the omics datasets and associated information into R. For each omics dataset, the moiraine package expects three pieces of information, which are read from csv files (or other specific formats when possible such as gtf or gff3):\n\nthe measurements of omics features across the samples (the dataset)\ninformation about the omics features measured (the features metadata)\ninformation about the samples measured (the samples metadata)\n\nAn example of input files is shown below:\n\n\nAn example of input files for moiraine (first 10 rows and 4 columns only): A) RNAseq read counts across genes (rows) and samples (columns). B) Table of features metadata, providing information about the genes measured. c) Table of samples metadata, i.e. information about the animals that were observed.\n\n\nmoiraine uses the MultiDataSet package to store the omics datasets and associated metadata into a single R object, which can be used as input for the different moiraine functions (see Chapter 3 for details about data import). This ensures that these functions can be used regardless of the number or type of omics datasets to analyse. At any point, the datasets, features and samples metadata can easily be extracted from the MultiDataSet object through get_datasets(), get_features_metadata() and get_samples_metadata().\nHere is an example of a MultiDataSet object:\n\n#> Object of class 'MultiDataSet'\n#>  . assayData: 3 elements\n#>     . snps: 23036 features, 139 samples \n#>     . rnaseq: 20335 features, 143 samples \n#>     . metabolome: 55 features, 139 samples \n#>  . featureData:\n#>     . snps: 23036 rows, 13 cols (feature_id, ..., p_value)\n#>     . rnaseq: 20335 rows, 15 cols (feature_id, ..., de_signif)\n#>     . metabolome: 55 rows, 16 cols (feature_id, ..., de_signif)\n#>  . rowRanges:\n#>     . snps: YES\n#>     . rnaseq: YES\n#>     . metabolome: NO\n#>  . phenoData:\n#>     . snps: 139 samples, 10 cols (id, ..., geno_comp_3)\n#>     . rnaseq: 143 samples, 10 cols (id, ..., geno_comp_3)\n#>     . metabolome: 139 samples, 10 cols (id, ..., geno_comp_3)\n\nImportantly, this means that all the information that we have about the omics features and samples are available to moiraine for customising plots or outputs. For example, it is possible to quickly generate a heatmap displaying the measurements for specific features of interest, and add information about the features and samples to facilitate the interpretation of the plot:\n\nCodehead(interesting_features) ## vector of feature IDs\n#> [1] \"ARS-BFGL-NGS-27468\" \"BovineHD2300010006\" \"BovineHD0300000351\"\n#> [4] \"BovineHD1900011146\" \"BovineHD0900026231\" \"ENSBTAG00000022715\"\n\ncolours_list <- list(                       \n  \"status\" = c(\"Control\" = \"gold\", \"BRD\" = \"lightblue\"),\n  \"day_on_feed\" = colorRamp2(c(5, 70), c(\"white\", \"pink3\")),\n  \"de_status\" = c(\"downregulated\" = \"deepskyblue\", \n                  \"upregulated\" = \"chartreuse3\")\n)\n\nplot_data_heatmap(\n  mo_set,                                    # the MultiDataSet object\n  interesting_features,                      # vector of feature IDs of interest\n  center = TRUE,                             # centering and scaling data for\n  scale = TRUE,                              #   easier visualisation\n  show_column_names = FALSE,                 # hide sample IDs\n  only_common_samples = TRUE,                # only samples present in all omics\n  samples_info = c(\"status\", \"day_on_feed\"), # add info about samples\n  features_info = c(\"de_status\"),            # add info about features\n  colours_list = colours_list,               # customise colours\n  label_cols = list(                         # specify features label\n    \"rnaseq\" = \"Name\",                       #   from features metadata\n    \"metabolome\" = \"name\"\n  )\n)\n\n\n\n\nSimilarly, a number of functions allow to quickly summarise different aspects of the multi-omics dataset, such as creating an upset plot to compare the samples present in each omics dataset (plot_samples_upset()), or generating a density plot for each omics dataset (plot_density_data()). See Chapter 4 for more details about the different visualisations and summary functions implemented."
  },
  {
    "objectID": "overview.html#data-pre-processing",
    "href": "overview.html#data-pre-processing",
    "title": "1  Overview of moiraine",
    "section": "\n1.2 Data pre-processing",
    "text": "1.2 Data pre-processing\nTarget factories have been implemented to facilitate the application of similar tasks across the different omics datasets. For example, the transformation_datasets_factory() function generates a sequence of targets to apply one of many possible transformations (from the vsn, DESeq2, or bestNormalize packages, for example) on each omics dataset, store information about each transformation performed, and generate a new MultiDataSet object in which the omics measurements have been transformed:\n\nCode\n\n\ntransformation_datasets_factory(\n  mo_set,                                      # MultiDataSet object\n  c(\"rnaseq\" = \"vst-deseq2\",                   # VST through DESeq2 for RNAseq\n    \"metabolome\" = \"logx\"),                    # log2-transf. for NMR dataset\n  log_bases = 2,                               # Base for log transformation\n  pre_log_functions = zero_to_half_min,        # Handling 0s in log2-transf.\n  transformed_data_name = \"mo_set_transformed\" # New MultiDataSet object\n)\n\n\n\nNote that there is also the option for users to apply their own custom transformations to the datasets (see Chapter 5).\nSimilarly, the pca_complete_data_factory generates a list of targets to run a PCA on each omics dataset via the pcaMethods package, and if necessary imputes missing values through NIPALS-PCA. The PCA results can be easily visualised for all or specific omics datasets:\n\nCodeplot_screeplot_pca(pca_runs_list)\n\n\n\n\n\nCodeplot_samples_coordinates_pca(\n  pca_runs_list,                              # List of PCA results\n  datasets = \"snps\",                          # Dataset to plot\n  pcs = 1:3,                                  # Principal components to display\n  mo_data = mo_set,                           # MultiDataSet object\n  colour_upper = \"geno_comp_cluster\",         # Samples covariate\n  shape_upper = \"status\",                     # Samples covariate\n  colour_lower = \"feedlot\",                   # Samples covariate\n  scale_colour_lower = scale_colour_brewer(palette = \"Set1\") # Custom palette\n) +\n  theme(legend.box = \"vertical\")              # Plot legend vertically\n\n\n\n\nMore information about data pre-processing can be found in Chapter 6."
  },
  {
    "objectID": "overview.html#data-pre-filtering",
    "href": "overview.html#data-pre-filtering",
    "title": "1  Overview of moiraine",
    "section": "\n1.3 Data pre-filtering",
    "text": "1.3 Data pre-filtering\nThe created MultiDataSet object can be filtered, both in terms of samples and features, by passing a list of sample or feature IDs to retain, or by using logical tests on samples or features metadata. In addition, we implement target factories to retain only the most variable features in each omics dataset –unsupervised filtering–, or to retain the features most associated with an outcome of interest, via sPLS-DA from mixOmics –supervised filtering– (see Chapter 7). This pre-filtering step is essential to reduce the size of the datasets prior to multi-omics integration.\n\nCode\n\n\nfeature_preselection_splsda_factory(\n  mo_set_complete,            # A MultiDataSet object\n  group = \"status\",           # Sample covariate to use for supervised filtering\n  to_keep_ns = c(             # Number of features to retain per dataset\n    \"snps\" = 1000, \n    \"rnaseq\" = 1000\n  ), \n  filtered_set_target_name = \"mo_presel_supervised\" # Name of filtered object\n)\n\n\n\n#> Object of class 'MultiDataSet'\n#>  . assayData: 3 elements\n#>     . snps: 1000 features, 139 samples \n#>     . rnaseq: 994 features, 143 samples \n#>     . metabolome: 55 features, 139 samples \n#>  . featureData:\n#>     . snps: 1000 rows, 13 cols (feature_id, ..., p_value)\n#>     . rnaseq: 994 rows, 15 cols (feature_id, ..., de_signif)\n#>     . metabolome: 55 rows, 16 cols (feature_id, ..., de_signif)\n#>  . rowRanges:\n#>     . snps: YES\n#>     . rnaseq: YES\n#>     . metabolome: NO\n#>  . phenoData:\n#>     . snps: 139 samples, 10 cols (id, ..., geno_comp_3)\n#>     . rnaseq: 143 samples, 10 cols (id, ..., geno_comp_3)\n#>     . metabolome: 139 samples, 10 cols (id, ..., geno_comp_3)"
  },
  {
    "objectID": "overview.html#multi-omics-data-integration",
    "href": "overview.html#multi-omics-data-integration",
    "title": "1  Overview of moiraine",
    "section": "\n1.4 Multi-omics data integration",
    "text": "1.4 Multi-omics data integration\nCurrently, moiraine provides functions and target factories to facilitate the use of five integration methods: sPLS and DIABLO from the mixOmics package, sO2PLS from OmicsPLS, as well as MOFA and MEFISTO from MOFA2.\nThis includes functions that transform a MultiDataSet object into the required input format for each integration method; for example for sPLS (only top of the matrices shown):\n\nCodeget_input_spls(\n  mo_presel_supervised,\n  mode = \"canonical\",\n  datasets = c(\"rnaseq\", \"metabolome\")\n)\n\n\n\n#> $rnaseq\n#>       ENSBTAG00000000020 ENSBTAG00000000046 ENSBTAG00000000056\n#> R9497           3.486141           7.211634           10.25302\n#> R5969           3.486141           7.436865           10.45008\n#> R5327           4.005139           6.731310           10.72323\n#> R5979           3.486141           7.538956           10.46189\n#> R9504           4.252314           7.493829           10.20723\n#>       ENSBTAG00000000061 ENSBTAG00000000113\n#> R9497           5.028442           13.49233\n#> R5969           4.285078           12.95106\n#> R5327           5.313842           13.14427\n#> R5979           4.333030           12.55548\n#> R9504           4.784574           12.71693\n#> \n#> $metabolome\n#>       HMDB00001 HMDB00008 HMDB00042 HMDB00043 HMDB00060\n#> R9497  3.397217  3.405992  9.654099  7.559186 0.5849625\n#> R5969  3.318827  2.137504  7.639522  6.539159 2.5849625\n#> R5327  3.721137  6.270529  6.963474  6.024586 2.6322682\n#> R5979  3.326626  2.232661  8.401306  7.394891 2.5849625\n#> R9504  3.603548  5.675251  7.879583  7.669594 0.8479969\n\nmoiraine also offers helper functions and target factories to facilitate the application of these integration tools. For example, the diablo_predefined_design_matrix() function generates, for a given DIABLO input object, one of the three recommended design matrices for DIABLO (null, full or weighted full), while the diablo_pairwise_pls_factory() factory creates a list of targets to estimate the optimal design matrix to use for DIABLO based on datasets pairwise correlations estimated using PLS:\n\nCode\n\n\nlist(\n  tar_target(\n    diablo_input,                            # DIABLO input object\n    get_input_mixomics_supervised(\n      mo_presel_supervised,                  # MultiDataSet object (prefiltered)\n      group = \"status\"                       # Samples covariate of interest\n    )\n  ),\n  diablo_pairwise_pls_factory(diablo_input)  # Target factory for design matrix\n                                             #   estimation\n)\n\n\n\nIn addition, a number of plotting functions have been implemented e.g. to visualise different aspects of the integration process: e.g. diablo_plot_tune() to show the results of model tuning in DIABLO or so2pls_plot_summary() (shown below) to display the percentage of variance explained by each latent component constructed by sO2PLS:\n\nCodeso2pls_plot_summary(so2pls_final_run)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWouldn’t it be nice to have informative labels for the features in DIABLO’s circos plots? With moiraine, it is possible to use information from the features metadata provided as labels for the features in the plots. So, we can go from:\n\nCodemixOmics::circosPlot(\n  diablo_final_run,\n  cutoff = 0.7,\n  size.variables = 0.5,\n  comp = 1\n)\n\n\n\n\nto:\n\nCodediablo_plot_circos(\n  diablo_final_run,\n  mo_set,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  cutoff = 0.7,\n  size.variables = 0.5,\n  comp = 1\n)\n\n\n\n\n\n\nMore details about how to use these integration tools through moiraine can be found in Chapters 8 to 11."
  },
  {
    "objectID": "overview.html#interpreting-the-integration-results",
    "href": "overview.html#interpreting-the-integration-results",
    "title": "1  Overview of moiraine",
    "section": "\n1.5 Interpreting the integration results",
    "text": "1.5 Interpreting the integration results\nOne of the main goals of moiraine is to facilitate the interpretation of the omics integration results. To this end, the outcome of any of the supported integration methods can be converted to a standardised integration output format, e.g.:\n\nCodeget_output(mofa_trained)\n\n\n\n#> $features_weight\n#> # A tibble: 8,196 × 5\n#>    feature_id                  dataset latent_dimension     weight importance\n#>    <chr>                       <fct>   <fct>                 <dbl>      <dbl>\n#>  1 21-25977541-C-T-rs41974686  snps    Factor 1          0.000374      0.139 \n#>  2 22-51403583-A-C-rs210306176 snps    Factor 1          0.0000535     0.0199\n#>  3 24-12959068-G-T-rs381471286 snps    Factor 1          0.000268      0.0999\n#>  4 8-85224224-T-C-rs43565287   snps    Factor 1         -0.000492      0.183 \n#>  5 ARS-BFGL-BAC-16973          snps    Factor 1         -0.000883      0.329 \n#>  6 ARS-BFGL-BAC-19403          snps    Factor 1         -0.000500      0.186 \n#>  7 ARS-BFGL-BAC-2450           snps    Factor 1          0.000555      0.207 \n#>  8 ARS-BFGL-BAC-2600           snps    Factor 1         -0.0000325     0.0121\n#>  9 ARS-BFGL-BAC-27911          snps    Factor 1         -0.000568      0.212 \n#> 10 ARS-BFGL-BAC-35925          snps    Factor 1          0.000803      0.299 \n#> # ℹ 8,186 more rows\n#> \n#> $samples_score\n#> # A tibble: 576 × 3\n#>    sample_id latent_dimension score\n#>    <chr>     <fct>            <dbl>\n#>  1 G1979     Factor 1          1.95\n#>  2 G2500     Factor 1          1.98\n#>  3 G3030     Factor 1          3.39\n#>  4 G3068     Factor 1          3.65\n#>  5 G3121     Factor 1          1.57\n#>  6 G3315     Factor 1         -1.81\n#>  7 G3473     Factor 1         -2.63\n#>  8 G3474     Factor 1         -2.30\n#>  9 G3550     Factor 1          2.98\n#> 10 G3594     Factor 1         -1.88\n#> # ℹ 566 more rows\n#> \n#> $variance_explained\n#> # A tibble: 12 × 3\n#>    latent_dimension dataset    prop_var_expl\n#>    <fct>            <fct>              <dbl>\n#>  1 Factor 1         snps           0.000313 \n#>  2 Factor 1         rnaseq         0.496    \n#>  3 Factor 1         metabolome     0.137    \n#>  4 Factor 2         snps           0.239    \n#>  5 Factor 2         rnaseq         0.000197 \n#>  6 Factor 2         metabolome     0.0108   \n#>  7 Factor 3         snps           0.000108 \n#>  8 Factor 3         rnaseq         0.199    \n#>  9 Factor 3         metabolome     0.0000872\n#> 10 Factor 4         snps           0.0000927\n#> 11 Factor 4         rnaseq         0.0759   \n#> 12 Factor 4         metabolome     0.0194   \n#> \n#> attr(,\"class\")\n#> [1] \"output_dimension_reduction\"\n#> attr(,\"method\")\n#> [1] \"MOFA\"\n\nThis object can then be used to visualise the integration results in a number of ways, including:\n\npercentage of variance explained:\n\n\nCodeplot_variance_explained(mofa_output)\n\n\n\n\n\nSample scores as pairwise scatterplots:\n\n\nCodeplot_samples_score(\n  mofa_output,                                        # MOFA standardised output\n  latent_dimensions = paste(\"Factor\", 1:3),           # MOFA factors to display\n  mo_data = mo_set,                                   # MultiDataSet object\n  colour_upper = \"status\",                            # Sample covariate\n  scale_colour_upper = scale_colour_brewer(palette = \"Set1\"), # Custom palette\n  shape_upper = \"gender\",                             # Sample covariate\n  colour_lower = \"geno_comp_cluster\"                  # Sample covariate\n) +\n  theme(legend.box = \"vertical\")\n\n\n\n\n\nSample scores against a sample covariate of interest (either categorical or continuous):\n\n\nCodeplot_samples_score_covariate(\n  mofa_output,                             # MOFA standardised output\n  mo_set,                                  # MultiDataSet object\n  \"status\",                                # Sample covariate of interest\n  colour_by = \"status\",                    # Other sample covariate\n  shape_by = \"geno_comp_cluster\",          # Other sample covariate\n  latent_dimensions = paste(\"Factor\", 1:2) # MOFA factors to display\n)\n\n\n\n\n\nTop contributing features with their importance:\n\n\nCodeplot_top_features(\n  mofa_output,                             # MOFA standardised output\n  mo_data = mo_set,                        # MultiDataSet object\n  label_cols = list(                       # Custom labels for features from\n    \"rnaseq\" = \"Name\",                     #   features metadata\n    \"metabolome\" = \"name\"\n  ),\n  truncate = 25,                           # truncate long feature labels\n  latent_dimensions = paste(\"Factor\", 1:2) # MOFA factors to display\n)\n\n\n\n\nMore details can be found in Chapter 12."
  },
  {
    "objectID": "overview.html#evaluating-the-integration-results",
    "href": "overview.html#evaluating-the-integration-results",
    "title": "1  Overview of moiraine",
    "section": "\n1.6 Evaluating the integration results",
    "text": "1.6 Evaluating the integration results\nWith moiraine, it is possible to evaluate the results of a given integration tool against prior information that we have about the features (e.g. knowledge about biological functions or results from a single-omics analysis) or samples (e.g. to assess the success of samples clustering into meaningful groups). For example, we can compare the feature selection performed by DIABLO to results from differential expression analyses performed on the omics datasets:\n\nCodeevaluate_feature_selection_table(\n  diablo_output,                                # DIABLO standardised output\n  mo_data = mo_set,                             # MultiDataSet object\n  col_names = list(                             # Columns from features metadata\n    \"rnaseq\" = \"de_signif\",                     #   containing DE outcome\n    \"metabolome\" = \"de_signif\" \n  ),\n  latent_dimensions = \"Component 1\"             # Latent component to focus on\n)\n\n#> # A tibble: 4 × 6\n#>   method latent_dimension dataset    feature_label selected not_selected\n#>   <chr>  <fct>            <fct>      <chr>            <int>        <int>\n#> 1 DIABLO Component 1      rnaseq     DE                  23           52\n#> 2 DIABLO Component 1      rnaseq     Not DE               7          912\n#> 3 DIABLO Component 1      metabolome DE                  10           20\n#> 4 DIABLO Component 1      metabolome Not DE              NA           25\n\n\nIn addition, a number of functions are provided to help with features set enrichment (such as over-representation analysis or gene set enrichment analysis), e.g. by generating feature sets from features metadata through make_feature_sets_from_fm(), or by ensuring that a proper background set is used in the enrichment analysis, with reduce_feature_sets_data(). Information about evaluation of integration results is presented in Chapter 13."
  },
  {
    "objectID": "overview.html#comparison-different-integration-results",
    "href": "overview.html#comparison-different-integration-results",
    "title": "1  Overview of moiraine",
    "section": "\n1.7 Comparison different integration results",
    "text": "1.7 Comparison different integration results\nLastly, moiraine facilitates the comparison of the results from different integration methods, or from a same integration method but with different pre-processing options or parameter choices. It is possible to visualise the correlation between the results of different methods, in terms of the latent dimensions they constructed:\n\nCodecomparison_heatmap_corr(\n  output_list,              # List of integration results (standardised format)\n)\n\n\n\n\n\n\n\nOr compare the samples score or features weight from two latent dimensions created by two integration methods:\n\nCodeplot_features_weight_pair(\n  list(mofa_output, diablo_output),  # Integration results (stand. format)\n  list(                              # Latent dimensions to compare\n    \"MOFA\" = \"Factor 1\", \n    \"DIABLO\" = \"Component 1\"\n  ),\n  mo_data = mo_set,                 # MultiDataSet object\n  features_metric = \"importance\",   # Plot absolute or signed importance score\n  label_cols = list(                # Columns from features metadata to use\n    \"rnaseq\" = \"Name\",              #  as labels in plot\n    \"metabolome\" = \"name\"\n  )\n)\n\n\n\n\n\n\n\nIt is also possible to compute a consensus importance score for each feature, which summarises the contribution of the feature to different latent dimensions, and thus assess which features are highlighted across several integration methods. More details are provided in Chapter 14."
  },
  {
    "objectID": "example_dataset.html#the-study",
    "href": "example_dataset.html#the-study",
    "title": "2  The example dataset",
    "section": "2.1 The study",
    "text": "2.1 The study\nAnimals enrolled into four commercial beef cattle feedlots in Alberta, Canada in 2015 were used for this study. Animals were fed a specific diet during their stay in the feedlots. 80 animals were identified as BRD positive, and 63 healthy individuals were selected from pens that had infected animals. Out of the 143 animals, 87 were heifers and 56 were steers. Blood samples were collected from each selected individual, and the following omics measurements were collected:\n\nGenomics data (Illumina GGP Bovine 10K microarray SNP chip). Four samples were lost for this dataset;\nTranscriptomics data (paired-end RNAseq data on total RNA). The samples were processed in two batches, with a different sequencing platform used for each batch (Hiseq 4000 and Novaseq 6000);\nMetabolomics data (via NMR spectroscopy, using a 700 MHz Avance III spectrometer).\n\nThe genomics and metabolomics datasets were deposited in the borealis database (DOI: 10.5683/SP3/ZETWNY), and the transcriptomics dataset in the GEO database (accession GSE217317)."
  },
  {
    "objectID": "example_dataset.html#omics-analyses",
    "href": "example_dataset.html#omics-analyses",
    "title": "2  The example dataset",
    "section": "2.2 Omics analyses",
    "text": "2.2 Omics analyses\nThe genomics dataset was used to infer the genomic breed composition of the animals, using the ADMIXTURE software with ancestry value set to 3. Then, SNPs were called from the RNAseq data, and were combined with the genomics dataset for further analysis.\nA genome-wide association study (GWAS) was run to identify SNPs significantly associated with disease status; the latter was adjusted for feedlot, days on feed and genomic breed composition. 2 SNPs with a false discovery rate (FDR) < 0.05 were considered as significant quantitative trait loci (QTLs).\nThe transcriptomics data were used for a differential expression analysis, accounting for feedlot, genomic breed composition and sequencing batch. The group of healthy samples was used as the reference in the analysis; 101 genes with an FDR < 0.01, log2 fold-change > 2 and log-counts per million > 2 were considered as significantly differentially expressed (DE).\nAn expression-QTL (eQTL) study was performed on the DE genes to identify SNPs significantly associated with their expression, again correcting for feedlot, sequencing batch and genomic breed composition. 564 SNPs with an FDR < 0.05 were considered as significant eQTLs. The physical distance between an eQTL and the associated gene was used to classify the mode of action of the SNP: 420 SNPs located within 1Mbp of the gene transcription starting site were considered cis-eQTLs, those located further or on different chromosomes (144 SNPs) were instead classified as trans-eQTLs.\nA differential concentration analysis was performed on the metabolomics data using two-samples t-test, and adjusting for feedlot and sex. The group of healthy samples was used as reference; 35 metabolites with an FDR < 0.05 were considered as DE."
  },
  {
    "objectID": "example_dataset.html#data-processing",
    "href": "example_dataset.html#data-processing",
    "title": "2  The example dataset",
    "section": "2.3 Data processing",
    "text": "2.3 Data processing\nThe full script for the data processing can be found in the moiraine GitHub repository.\n\n2.3.1 Genomics dataset\nThe matrix of SNP dosage and table of SNP information were downloaded from the borealis database. The list of significant QTLs and eQTLs was extracted from the supplementary file made available on Figshare alongside the article and completed with information from Table 1 from Li et al. (2022). Note that some of the QTLs and eQTLs listed in the article and supplementary material were obtained from the RNAseq dataset, and so are not present in the version of the dataset used for the present tutorial. If a SNP was selected as both QTL and eQTL, only the results yielding the smallest FDR value were retained.\nSNPs with more than 10% of missing values, a minor allele frequency lower than 5%, or located on a sex chromosome were removed from the analysis (according to the paper’s methods, although filtering based on Hardy-Weinberg equilibrium was not performed). In addition, to keep the size of the dataset small (as this dataset is indented for demonstration only), 23,000 SNPs that were not found significant QTLs or eQTLs were randomly subsampled from the full set of non-significant SNPs. All SNPs detected as QTLs or eQTLs were also retained in the dataset; yielding a genomics dataset of 23,036 SNPs over 139 samples.\nAlso, k-means clustering was used to group samples into 3 clusters, based on their genomic breed composition values.\n\n\n2.3.2 Transcriptomics dataset\nThe matrix of RNAseq read counts, alongside information about the measured samples, was downloaded from the GEO database. Sample IDs were corrected when possible to match with the IDs found in the datasets from the borealis database, based on information about the samples. Genes with a read count of 0 for 90% or more samples were removed from the dataset. This resulted in a dataset of 20,335 genes over 143 samples.\nThe genome annotation file used for mapping the RNAseq reads (Bos taurus genome, version 110) was downloaded from the Ensembl database. A lighter version of the file was generated by only retaining information about the genes in the GFF3 file. In addition, the genes’ GO annotation was obtained through the biomaRt package using the Bos taurus Ensembl genome annotation (version 110).\nThe differential expression analysis was re-created according to the manuscript’s methods section, using the edgeR package. Due to difference in package version and missing information about two samples, the results are not completely identical, nevertheless, most of the DE genes overlapped with the ones reported in the manuscript.\n\n\n2.3.3 Metabolomics dataset\nThe table of metabolites concentrations was downloaded from the borealis database, containing measurements for 55 metabolites over 139 samples. Information about the measured metabolites was found in the HMDB dataset (https://hmdb.ca/). The contents of the database were downloaded and parsed to extract relevant properties of the measured metabolites.\nThe differential expression analysis on the compounds was re-created according to the manuscript’s methods section, using a two-sample t-test.\n\n\n2.3.4 Resulting files\nThe following files were generated, and are available through the moiraine package (can be retrieved via system.file(\"extdata/genomics_dataset.csv\", package = \"moiraine\")):\n\ngenomics_dataset.csv: contains the genomic variants’ dosage, with 23,036 genomic variants as rows and 139 samples as columns.\ngenomics_features_info.csv: contains information about the genomic variants (chromosome, genomic position, etc, as well as the results of a GWAS analysis), with 23,036 genomic variants as rows.\ntranscriptomics_dataset.csv: contains the genes’ raw read count, with 20,335 genes as rows and 143 samples as columns.\nbos_taurus_gene_model.gff3: the genome annotation file used to map the transcriptomics reads to gene models.\ntranscriptomics_de_results.csv: the results of a differential expression analysis run on the transcriptomics dataset to compare healthy and infected animals, with 20,335 genes as rows.\ntranscriptomics_go_annotation.csv: contains the correspondence between genes and GO terms in a long format (one row per gene/GO term pair).\nmetabolomics_dataset.csv: contains the area peak values, with 139 samples as rows, and 55 compounds as columns.\nmetabolomics_features_info.csv: contains information about the 55 compounds in rows (such as mass, retention time, and formula and name if the compounds has been identified) as well as the results of a differential expression analysis run on the metabolomics dataset to compare healthy and infected animals.\nsamples_info.csv: information about the samples, with 143 samples as rows.\n\n\n\n\n\nLi, Jiyuan, Robert Mukiibi, Janelle Jiminez, Zhiquan Wang, Everestus C. Akanno, Edouard Timsit, and Graham S. Plastow. 2022. “Applying Multi-Omics Data to Study the Genetic Background of Bovine Respiratory Disease Infection in Feedlot Crossbred Cattle.” Frontiers in Genetics 13. https://www.frontiersin.org/articles/10.3389/fgene.2022.1046192."
  },
  {
    "objectID": "data_import.html#the-example-dataset-files",
    "href": "data_import.html#the-example-dataset-files",
    "title": "3  Importing data",
    "section": "\n3.1 The example dataset files",
    "text": "3.1 The example dataset files\nThe dataset analysed this manual is presented in Chapter 2. The associated files that we will use here are:\n\n\nGenomics data:\n\ngenomics_dataset.csv: contains the genomic variants’ dosage, with genomic variants as rows and samples as columns.\ngenomics_features_info.csv: contains information about the genomic variants (chromosome, genomic position, etc, as well as the results of a GWAS analysis).\n\n\n\nTranscriptomics data:\n\ntranscriptomics_dataset.csv: contains the raw read counts for the measured genes – rows correspond to transcripts, and columns to samples.\nbos_taurus_gene_model.gff3: the genome annotation file used to map the transcriptomics reads to gene models.\ntranscriptomics_de_results.csv: the results of a differential expression analysis run on the transcriptomics dataset to compare healthy and diseased animals.\ntranscriptomics_go_annotation.csv: contains the correspondence between genes and GO terms in a long format (one row per gene/GO term pair).\n\n\n\nMetabolomics data:\n\nmetabolomics_dataset.csv: contains the area peak values – rows correspond to samples, and columns to compounds.\nmetabolomics_features_info.csv: contains information about the compounds (such as mass, retention time, and formula and name if the compounds has been identified) as well as the results of a differential expression analysis run on the metabolomics dataset to compare healthy and diseased animals.\n\n\nSamples information: stored in the samples_info.csv file, in which each row corresponds to a sample.\n\nEach of these files is available through the moiraine package, and can be retrieved via system.file(\"extdata/genomics_dataset.csv\", package = \"moiraine\")."
  },
  {
    "objectID": "data_import.html#importing-the-datasets",
    "href": "data_import.html#importing-the-datasets",
    "title": "3  Importing data",
    "section": "\n3.2 Importing the datasets",
    "text": "3.2 Importing the datasets\nWe will show how to import the datasets, first manually, and then in an automated way (using a target factory function).\n\n3.2.1 Manually\nWe can start by creating targets that track the different data files. This ensures that when a data file changes, the target is considered outdated and any analysis relying on this data file will be re-run (see here for more information). For example, for the genomics dataset, we write:\n\n\ntar_target(\n  dataset_file_geno,\n  system.file(\"extdata/genomics_dataset.csv\", package = \"moiraine\"),\n  format = \"file\"\n)\n\n\nThe created target, called dataset_file_geno, takes as value the path to the file:\n\ntar_read(dataset_file_geno)\n#> [1] \"/powerplant/workspace/hrpoab/RENV_CACHE/v5/R-4.2/x86_64-pc-linux-gnu/moiraine/1.0.0/96a479d4ef576d72d03d2a95378680bf/moiraine/extdata/genomics_dataset.csv\"\n\nThe next step is to import this dataset in R. We use the import_dataset_csv() function for that, rather than the readr::read_csv() or similar functions, as it ensures that the data is imported with the correct format for further use with the moiraine package. When importing a dataset, we need to specify the path to the file, as well as the name of the column in the csv file that contains the row names (through the col_id argument). In addition, we need to specify whether the features are represented in rows in the csv file, or in columns. This is done through the argument features_as_rows. For example, we can load the genomics dataset through:\n\n\ntar_target(\n  data_geno,\n  import_dataset_csv(\n    dataset_file_geno, \n    col_id = \"marker\", \n    features_as_rows = TRUE)\n)\n\n\nThe function returns a matrix in which the rows correspond to the features measured, and the columns correspond to the samples:\n\ntar_read(data_geno) |> dim()\n#> [1] 23036   139\ntar_read(data_geno)[1:5, 1:3]\n#>                             R21 Y3660 Y3243\n#> 1_41768691                    1     0     2\n#> 10-27008241-A-C-rs42918694    2     2     2\n#> 10-37505419-T-C-rs136559242   0     1     0\n#> 10-49904259-G-A-rs471723345   1     2     2\n#> 1-109550832-G-A-rs209732846   2     2     1\n\nNote that import_dataset_csv() uses readr::read_csv() to read in the data. It accepts arguments that will be passed on to read_csv(), which can be useful to control how the data file must be read, e.g. by specifying the columns’ type, or which characters must be considered as missing values.\n\n3.2.2 Using a target factory function\nCreating a target to track the raw file and using the import_dataset_csv() function to read it can be a bit cumbersome if we want to import several datasets. Luckily, this process can be automated with the import_dataset_csv_factory() function. It takes as an input a vector of files path, and for each file creates:\n\na target named dataset_file_XX (XX explained below), which tracks the raw data file;\na target named data_XX, which corresponds to the data matrix that has been imported through the import_dataset_csv function.\n\nFor each file, we need to specify the name of the column giving the row names (argument col_ids), and whether the features are stored as rows or as columns (argument features_as_rowss). Note that these arguments are the same as in the primary function import_dataset_csv(), except that they have an additional ‘s’ at the end of their name. This will be the case for most of the target factory functions from the package.\nIn addition, we have to provide a unique suffix which will be appended to the name of the targets created (i.e. the XX mentioned above) through the target_name_suffixes argument. This allows us to track which target corresponds to which dataset.\nSo the following code (note that it is not within a tar_target() call):\n\n\nimport_dataset_csv_factory(\n  files = c(\n    system.file(\"extdata/genomics_dataset.csv\", package = \"moiraine\"),\n    system.file(\"extdata/transcriptomics_dataset.csv\", package = \"moiraine\"),\n    system.file(\"extdata/metabolomics_dataset.csv\", package = \"moiraine\")\n  ),\n  col_ids = c(\"marker\", \"gene_id\", \"sample_id\"),\n  features_as_rowss = c(TRUE, TRUE, FALSE),\n  target_name_suffixes = c(\"geno\", \"transcripto\", \"metabo\")\n)\n\n\nwill create the following targets:\n\ndataset_file_geno, dataset_file_transcripto, dataset_file_metabo\ndata_geno, data_metabo, data_transcripto\n\n\ntar_read(data_geno) |> dim()\n#> [1] 23036   139\ntar_read(data_transcripto) |> dim()\n#> [1] 20335   143\ntar_read(data_metabo) |> dim()\n#> [1]  55 139\n\nWith this factory function, it is not possible to pass arguments to read_csv(). If you want to control how the files are read, please use the import_dataset_csv() function directly instead, as shown in Section 3.2.1.\n\nConverting targets factory to R script\nThere is no simple way to convert this target factory to regular R script using loops, so we can instead write the code separately for each omics dataset.\n\ndataset_file_geno <- system.file(\n  \"extdata/genomics_dataset.csv\",\n  package = \"moiraine\"\n)\ndata_geno <- import_dataset_csv(\n  dataset_file_geno,\n  col_id = \"marker\",\n  features_as_rows = TRUE\n)\n\ndataset_file_transcripto <- system.file(\n  \"extdata/transcriptomics_dataset.csv\", \n  package = \"moiraine\"\n)\ndata_transcripto <- import_dataset_csv(\n  dataset_file_transcripto,\n  col_id = \"gene_id\",\n  features_as_rows = TRUE\n)\n\ndataset_file_metabo <- system.file(\n  \"extdata/metabolomics_dataset.csv\", \n  package = \"moiraine\"\n)\ndata_metabo <- import_dataset_csv(\n  dataset_file_metabo,\n  col_id = \"sample_id\",\n  features_as_rows = FALSE\n)"
  },
  {
    "objectID": "data_import.html#importing-the-features-metadata",
    "href": "data_import.html#importing-the-features-metadata",
    "title": "3  Importing data",
    "section": "\n3.3 Importing the features metadata",
    "text": "3.3 Importing the features metadata\nSimilarly to how we imported the datasets, there are two ways of importing features metadata: either manually, or using a target factory function. The two options are illustrated below.\n\n3.3.1 Manually\nAs shown in the previous section, we can start by creating a target that tracks the raw features metadata file, then read the file into R using the import_fmetadata_csv() function. It has the similar arguments as the import_dataset_csv() function, but returns a data-frame (rather than a matrix); and does not have the options to read a csv where the features are columns (they must be in rows):\n\n\nlist(\n  tar_target(\n    fmetadata_file_geno,\n    system.file(\"extdata/genomics_features_info.csv\", package = \"moiraine\"),\n    format = \"file\"\n  ),\n  \n  tar_target(\n    fmetadata_geno,\n    import_fmetadata_csv(\n      fmetadata_file_geno,\n      col_id = \"marker\",\n      col_types = c(\"chromosome\" = \"c\")\n    )\n  )\n)\n\n\nNotice that in the import_fmetadata_csv() call, we’ve added an argument (col_types) which will be passed on to read_csv(). This is to ensure that the chromosome column will be read as character (even though the chromosomes are denoted with integers).\n\ntar_read(fmetadata_geno) |> head()\n#>                                                feature_id chromosome  position\n#> 1_41768691                                     1_41768691          1  42139849\n#> 10-27008241-A-C-rs42918694     10-27008241-A-C-rs42918694         10  26971270\n#> 10-37505419-T-C-rs136559242   10-37505419-T-C-rs136559242         10  37388728\n#> 10-49904259-G-A-rs471723345   10-49904259-G-A-rs471723345          0         0\n#> 1-109550832-G-A-rs209732846   1-109550832-G-A-rs209732846          1 108696486\n#> 11-104555023-A-G-rs109353933 11-104555023-A-G-rs109353933         11 104498929\n#>                              gen_train_score ref alt ilmn_strand\n#> 1_41768691                            0.6786   T   G         BOT\n#> 10-27008241-A-C-rs42918694            0.8050   A   C         TOP\n#> 10-37505419-T-C-rs136559242           0.7890   A   G         TOP\n#> 10-49904259-G-A-rs471723345           0.7970   A   G         TOP\n#> 1-109550832-G-A-rs209732846           0.8909   T   C         BOT\n#> 11-104555023-A-G-rs109353933          0.8673   T   C         BOT\n#>                              customer_strand norm_id    qtl_type qtl_effect\n#> 1_41768691                               BOT       2 non signif.         NA\n#> 10-27008241-A-C-rs42918694               TOP       1 non signif.         NA\n#> 10-37505419-T-C-rs136559242              BOT       1 non signif.         NA\n#> 10-49904259-G-A-rs471723345              TOP       2 non signif.         NA\n#> 1-109550832-G-A-rs209732846              TOP       3 non signif.         NA\n#> 11-104555023-A-G-rs109353933             TOP       1 non signif.         NA\n#>                              p_value fdr\n#> 1_41768691                        NA  NA\n#> 10-27008241-A-C-rs42918694        NA  NA\n#> 10-37505419-T-C-rs136559242       NA  NA\n#> 10-49904259-G-A-rs471723345       NA  NA\n#> 1-109550832-G-A-rs209732846       NA  NA\n#> 11-104555023-A-G-rs109353933      NA  NA\n\nYou can see that in the data-frame of features metadata, the feature IDs are present both as row names and in the feature_id column. This makes it easier to subset the datasets later on.\n\n3.3.2 Using a target factory function\nAlternatively, we can use a target factory function that automates the process when we have to read in several features metadata files. In our case, we have to do it for the genomics and metabolomics datasets only, as the transcriptomics dataset has a different features metadata format. However because we need to specify the column types for the genomics dataset, we will use the targets factory function to read in the metabolomics features metadata only. The arguments are almost the same as for import_dataset_csv_factory() (except for features_as_rowss):\n\n\nimport_fmetadata_csv_factory(\n  files = c(\n    system.file(\"extdata/metabolomics_features_info.csv\", package = \"moiraine\")\n  ),\n  col_ids = c(\"feature_id\"),\n  target_name_suffixes = c(\"metabo\")\n)\n\n\nThe targets created are:\n\nfmetadata_file_metabo\nfmetadata_metabo\n\n\ntar_read(fmetadata_metabo) |> head()\n#>           feature_id     hmdb_id                  name chemical_formula\n#> HMDB00001  HMDB00001 HMDB0000001     1-Methylhistidine        C7H11N3O2\n#> HMDB00008  HMDB00008 HMDB0000008 2-Hydroxybutyric acid           C4H8O3\n#> HMDB00357  HMDB00357 HMDB0000011 3-Hydroxybutyric acid           C4H8O3\n#> HMDB00042  HMDB00042 HMDB0000042           Acetic acid           C2H4O2\n#> HMDB00043  HMDB00043 HMDB0000043               Betaine         C5H12NO2\n#> HMDB00060  HMDB00060 HMDB0000060      Acetoacetic acid           C4H6O3\n#>           monisotopic_molecular_weight cas_registry_number\n#> HMDB00001                    169.08513            332-80-9\n#> HMDB00008                    104.04734           3347-90-8\n#> HMDB00357                    104.04734            625-72-9\n#> HMDB00042                     60.02113             64-19-7\n#> HMDB00043                    118.08680           6915-17-9\n#> HMDB00060                    102.03169            541-50-4\n#>                                smiles                    inchikey kegg_id\n#> HMDB00001 CN1C=NC(C[C@H](N)C(O)=O)=C1 BRMWTNUJHUMWMS-LURJTMIESA-N  C01152\n#> HMDB00008            CC[C@H](O)C(O)=O AFENDNXGAFYKQO-VKHMYHEASA-N  C05984\n#> HMDB00357           C[C@@H](O)CC(O)=O WHBMMWSBFZVSSR-GSVOUGTGSA-N  C01089\n#> HMDB00042                     CC(O)=O QTBSBXVTEAMEQO-UHFFFAOYSA-N  C00033\n#> HMDB00043          C[N+](C)(C)CC(O)=O KWIUHFFTVRNATP-UHFFFAOYSA-O    <NA>\n#> HMDB00060               CC(=O)CC(O)=O WDJHALXBUFZDSR-UHFFFAOYSA-N  C00164\n#>                                    direct_parent                   super_class\n#> HMDB00001              Histidine and derivatives Organic acids and derivatives\n#> HMDB00008    Alpha hydroxy acids and derivatives Organic acids and derivatives\n#> HMDB00357     Beta hydroxy acids and derivatives Organic acids and derivatives\n#> HMDB00042                       Carboxylic acids Organic acids and derivatives\n#> HMDB00043                      Alpha amino acids Organic acids and derivatives\n#> HMDB00060 Short-chain keto acids and derivatives Organic acids and derivatives\n#>               t_value      p_value         padj de_signif     de_status\n#> HMDB00001  -0.5557020 5.797635e-01 6.784466e-01    Not DE        Not DE\n#> HMDB00008   0.2181562 8.276321e-01 8.925444e-01    Not DE        Not DE\n#> HMDB00357  -9.7388879 2.353250e-17 2.157146e-16        DE downregulated\n#> HMDB00042 -12.5323491 1.753101e-24 4.821028e-23        DE downregulated\n#> HMDB00043  -7.9073179 7.827088e-13 3.913544e-12        DE downregulated\n#> HMDB00060  -0.4369834 6.628164e-01 7.439776e-01    Not DE        Not DE\n\nAgain, the targets factory function does not allow to pass arguments to read_csv() (if you need them, please use import_fmetadata_csv() directly as we have done in Section 3.3.1).\n\nConverting targets factory to R script\n\nfmetadata_file_metabo <- system.file(\n  \"extdata/metabolomics_features_info.csv\", \n  package = \"moiraine\"\n)\nfmetadata_metabo <- import_fmetadata_csv(\n  fmetadata_file_metabo,\n  col_id = \"feature_id\"\n)\n\n\n3.3.3 Importing features metadata from a GTF/GFF file\nThe moiraine package can also extract features metadata from a genome annotation file (.gtf or .gff). We’ll demonstrate that for the transcriptomics dataset, for which information about the position and name of the transcripts can be found in the genome annotation used to map the reads. The function is called import_fmetadata_gff() (it is also the function you would use to read in information from a .gtf file). The type of information to extract from the annotation file is specified through the feature_type argument, which can be either 'genes' or 'transcripts'. In addition, if the function does not extract certain fields from the annotation file, these can be explicitly called using the add_fields parameter.\nIn this example, we want to extract information about the genes from the gtf file. We also want to make sure that the Name and descriptionfield are imported, as they give the name and description of the genes. To read in this information “manually”, we create the following targets:\n\n\nlist(\n  tar_target(\n    fmetadata_file_transcripto,\n    system.file(\"extdata/bos_taurus_gene_model.gff3\", package = \"moiraine\"),\n    format = \"file\"\n  ),\n  \n  tar_target(\n    fmetadata_transcripto,\n    import_fmetadata_gff(\n      fmetadata_file_transcripto,\n      feature_type = \"genes\",\n      add_fields = c(\"Name\", \"description\")\n    )\n  )\n)\n\n\nAs for the other import functions, there exists a more succinct target factory version, called import_fmetadata_gff_factory():\n\n\nimport_fmetadata_gff_factory(\n  files = system.file(\"extdata/bos_taurus_gene_model.gff3\", package = \"moiraine\"),\n  feature_types = \"genes\",\n  add_fieldss = c(\"Name\", \"description\"),\n  target_name_suffixes = \"transcripto\"\n)\n\n\nThis will create two targets: fmetadata_file_transcripto and fmetadata_transcripto.\nAs with import_fmetadata, the function returns a data-frame of features information:\n\ntar_read(fmetadata_transcripto) |> head()\n#>                            feature_id chromosome    start      end  width\n#> ENSBTAG00000000005 ENSBTAG00000000005         17 65389743 65505336 115594\n#> ENSBTAG00000000008 ENSBTAG00000000008         29 32214439 32244810  30372\n#> ENSBTAG00000000009 ENSBTAG00000000009         18 12338037 12342272   4236\n#> ENSBTAG00000000010 ENSBTAG00000000010         21 34209956 34223394  13439\n#> ENSBTAG00000000011 ENSBTAG00000000011          8  7950815  7971600  20786\n#> ENSBTAG00000000012 ENSBTAG00000000012         20 33708626 33732944  24319\n#>                    strand  Name\n#> ENSBTAG00000000005      +  GRK3\n#> ENSBTAG00000000008      - KCNJ1\n#> ENSBTAG00000000009      + FOXF1\n#> ENSBTAG00000000010      +  UBL7\n#> ENSBTAG00000000011      -   TDH\n#> ENSBTAG00000000012      + TTC33\n#>                                                                                                       description\n#> ENSBTAG00000000005                        G protein-coupled receptor kinase 3 [Source:VGNC Symbol;Acc:VGNC:53904]\n#> ENSBTAG00000000008 potassium inwardly rectifying channel subfamily J member 1 [Source:VGNC Symbol;Acc:VGNC:30453]\n#> ENSBTAG00000000009                                            forkhead box F1 [Source:VGNC Symbol;Acc:VGNC:29084]\n#> ENSBTAG00000000010                                           ubiquitin like 7 [Source:VGNC Symbol;Acc:VGNC:50128]\n#> ENSBTAG00000000011                                 L-threonine dehydrogenase [Source:VGNC Symbol;Acc:VGNC:108945]\n#> ENSBTAG00000000012                         tetratricopeptide repeat domain 33 [Source:VGNC Symbol;Acc:VGNC:36471]\n\n\nConverting targets factory to R script\n\nfmetadata_file_transcripto <- system.file(\n  \"extdata/bos_taurus_gene_model.gff3\", \n  package = \"moiraine\"\n)\nfmetadata_transcripto <- import_fmetadata_gff(\n  fmetadata_file_transcripto,\n  feature_type = \"genes\",\n  add_fields = c(\"Name\", \"description\")\n)"
  },
  {
    "objectID": "data_import.html#importing-the-samples-metadata",
    "href": "data_import.html#importing-the-samples-metadata",
    "title": "3  Importing data",
    "section": "\n3.4 Importing the samples metadata",
    "text": "3.4 Importing the samples metadata\nAs for importing datasets or features metadata, the import_smetadata_csv() function reads in a csv file that contains information about the samples measured. Similarly to import_fmetadata_csv(), this function assumes that the csv file contains samples as rows. In this example, we have one samples information file for all of our omics datasets, but it is possible to have one separate samples metadata csv file for each omics dataset (if there are some omics-specific information such as batch, technology specifications, etc).\nWe can do this by manually creating the following targets:\n\n\nlist(\n  tar_target(\n    smetadata_file_all,\n    system.file(\"extdata/samples_info.csv\", package = \"moiraine\"),\n    format = \"file\"\n  ),\n\n  tar_target(\n    smetadata_all,\n    import_smetadata_csv(\n      smetadata_file_all,\n      col_id = \"animal_id\"\n    )\n  )\n)\n\n\nwhich is equivalent to the (more succinct) command:\n\n\nimport_smetadata_csv_factory(\n  files = system.file(\"extdata/samples_info.csv\", package = \"moiraine\"),\n  col_ids = \"animal_id\",\n  target_name_suffixes = \"all\"\n)\n\n\nThe latter command creates the targets smetadata_file_all and smetadata_all. smetadata_all stores the samples metadata imported as a data-frame:\n\ntar_read(smetadata_all) |> head()\n#>          id feedlot gender  status day_on_feed rnaseq_batch geno_comp_1\n#> R21     R21      F1 female Control          31           B2    0.007853\n#> Y3660 Y3660      F1   male Control          19           B2    0.852220\n#> Y3243 Y3243      F1   male Control          16           B2    0.044171\n#> R5764 R5764      F2   male Control          46           B1    0.213094\n#> P4669 P4669      F3   male     BRD          35           B2    0.389393\n#> R5452 R5452      F2   male Control          49           B1    0.265998\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster\n#> R21      0.820691    0.171456                K3\n#> Y3660    0.093585    0.054195                K2\n#> Y3243    0.190262    0.765567                K1\n#> R5764    0.676299    0.110607                K3\n#> P4669    0.503471    0.107136                K3\n#> R5452    0.733992    0.000010                K3\n\nNote that in the samples metadata data-frame, the sample IDs are present both as row names and in the id column. This makes it easier to subset the datasets later on.\nAs for the other import functions, import_smetadata_csv() accepts arguments that will be passed to read_csv() in order to specify how the file should be read. The targets factory version does not have this option.\n\nConverting targets factory to R script\n\nsmetadata_file_all <- system.file(\"extdata/samples_info.csv\", package = \"moiraine\")\nsmetadata_all <- import_smetadata_csv(\n  smetadata_file_all,\n  col_id = \"animal_id\"\n)"
  },
  {
    "objectID": "data_import.html#creating-the-omics-sets",
    "href": "data_import.html#creating-the-omics-sets",
    "title": "3  Importing data",
    "section": "\n3.5 Creating the omics sets",
    "text": "3.5 Creating the omics sets\nOnce each dataset and associated features and samples metadata have been imported, we need to combine them into omics sets. In practice, this means that for each omics dataset, we will create an R object that stores the actual dataset alongside its relevant metadata. moiraine relies on the Biobase containers derived from Biobase::eSet to store the different omics datasets; for example, Biobase::ExpressionSet objects are used to store transcriptomics measurements. Currently, moiraine support four types of omics containers:\n\ngenomics containers, which are Biobase::SnpSet objects. The particularity of this data type is that the features metadata data-frame must contain a column named chromosome and a column named position, which store the chromosome and genomic position within the chromosome (in base pairs) of a given genomic marker or variant.\ntranscriptomics containers, which are Biobase::ExpressionSet objects. The particularity of this data type is that the features metadata data-frame must contain the following columns: chromosome, start, end, giving the chromosome, start and end positions (in base pairs) of the genes or transcripts. Moreover, the values in start and end must be integers, and for each row the value in end must be higher than the value in start.\nmetabolomics containers, which are MetabolomeSet objects (implemented within moiraine). There are no restrictions on the features metadata table for this type of containers.\nphenotype containers, which are PhenotypeSet objects (implemented within moiraine). There are no restrictions on the features metadata table for this type of containers.\n\nIn practice, the nuances between these different containers are not very important, and the type of container used to store a particular dataset will have no impact on the downstream analysis apart from the name that will be given to the omics dataset. So in order to create a container for a transcriptomics dataset in the absence of features metadata, we have to create a dummy data-frame with the columns chromosome, start and end containing the values ch1, 1, and 10 (for example) and use that as features metadata. Alternately, or for other omics data (e.g. proteomics), it is possible to use a PhenotypeSet object instead.\n\n3.5.1 Creating a single omics set\nThe function create_omics_set() provides a convenient wrapper to create such container objects from the imported datasets and metadata. It has two mandatory arguments: the dataset, which should be in the form of a matrix where the rows correspond to features and the columns to samples; and the type of omics data that the dataset represents ('genomics', 'transcriptomics', 'metabolomics' or 'phenomics'). The latter determines which type of container will be generated. Optionally, a features metadata and/or a samples metadata data-frame can be passed on via the features_metadata and samples_metadata arguments, respectively. For example, let’s create a set for the genomics data:\n\n\ntar_target(\n  set_geno,\n  create_omics_set(\n    data_geno,\n    omics_type = \"genomics\",\n    features_metadata = fmetadata_geno,\n    samples_metadata = smetadata_all\n  )\n)\n\n\nIf executed, this command will return the following warning:\n\n#> Warning: 5 samples in samples metadata not in dataset, will be removed from\n#> metadata.\n\nThis is because, when providing features and samples metadata information, the function makes sure that the feature or sample IDs present in the metadata tables match those used in the dataset. In our case, 5 sample IDs from the metadata data-frame are not present in the dataset. We can confirm that by comparing the column names of the genomics dataset to the row names of the samples metadata:\n\nsetdiff(\n  tar_read(smetadata_all) |> rownames(),\n  tar_read(data_geno) |> colnames()\n)\n#> [1] \"P4744\" \"P4772\" \"R8953\" \"U5416\" \"R9909\"\n\nRather than throwing an error, the function will add a row for each missing sample ID to the metadata data-frame, with a NA in every column, and will remove from the metadata data-frame any sample not present in the dataset. The same applies for features metadata.\nThe resulting object is a SnpSet:\n\ntar_read(set_geno)\n#> SnpSet (storageMode: lockedEnvironment)\n#> assayData: 23036 features, 139 samples \n#>   element names: call, callProbability \n#> protocolData: none\n#> phenoData\n#>   rowNames: R21 Y3660 ... O5108 (139 total)\n#>   varLabels: id feedlot ... geno_comp_cluster (10 total)\n#>   varMetadata: labelDescription\n#> featureData\n#>   featureNames: 1_41768691 10-27008241-A-C-rs42918694 ... STAT5_13516_2\n#>     (23036 total)\n#>   fvarLabels: feature_id chromosome ... fdr (13 total)\n#>   fvarMetadata: labelDescription\n#> experimentData: use 'experimentData(object)'\n#> Annotation:\n\nwhich can be queried using specific methods from the Biobase package, e.g.:\n\ntar_load(set_geno)\n\ndim(set_geno)\n#> Features  Samples \n#>    23036      139\n\nfeatureNames(set_geno) |> head()\n#> [1] \"1_41768691\"                   \"10-27008241-A-C-rs42918694\"  \n#> [3] \"10-37505419-T-C-rs136559242\"  \"10-49904259-G-A-rs471723345\" \n#> [5] \"1-109550832-G-A-rs209732846\"  \"11-104555023-A-G-rs109353933\"\n\nsampleNames(set_geno) |> head()\n#> [1] \"R21\"   \"Y3660\" \"Y3243\" \"R5764\" \"P4669\" \"R5452\"\n\nfData(set_geno) |> head() ## extracts features metadata\n#>                                                feature_id chromosome  position\n#> 1_41768691                                     1_41768691          1  42139849\n#> 10-27008241-A-C-rs42918694     10-27008241-A-C-rs42918694         10  26971270\n#> 10-37505419-T-C-rs136559242   10-37505419-T-C-rs136559242         10  37388728\n#> 10-49904259-G-A-rs471723345   10-49904259-G-A-rs471723345          0         0\n#> 1-109550832-G-A-rs209732846   1-109550832-G-A-rs209732846          1 108696486\n#> 11-104555023-A-G-rs109353933 11-104555023-A-G-rs109353933         11 104498929\n#>                              gen_train_score ref alt ilmn_strand\n#> 1_41768691                            0.6786   T   G         BOT\n#> 10-27008241-A-C-rs42918694            0.8050   A   C         TOP\n#> 10-37505419-T-C-rs136559242           0.7890   A   G         TOP\n#> 10-49904259-G-A-rs471723345           0.7970   A   G         TOP\n#> 1-109550832-G-A-rs209732846           0.8909   T   C         BOT\n#> 11-104555023-A-G-rs109353933          0.8673   T   C         BOT\n#>                              customer_strand norm_id    qtl_type qtl_effect\n#> 1_41768691                               BOT       2 non signif.         NA\n#> 10-27008241-A-C-rs42918694               TOP       1 non signif.         NA\n#> 10-37505419-T-C-rs136559242              BOT       1 non signif.         NA\n#> 10-49904259-G-A-rs471723345              TOP       2 non signif.         NA\n#> 1-109550832-G-A-rs209732846              TOP       3 non signif.         NA\n#> 11-104555023-A-G-rs109353933             TOP       1 non signif.         NA\n#>                              p_value fdr\n#> 1_41768691                        NA  NA\n#> 10-27008241-A-C-rs42918694        NA  NA\n#> 10-37505419-T-C-rs136559242       NA  NA\n#> 10-49904259-G-A-rs471723345       NA  NA\n#> 1-109550832-G-A-rs209732846       NA  NA\n#> 11-104555023-A-G-rs109353933      NA  NA\n\npData(set_geno) |> head() ## extracts samples metadata\n#>          id feedlot gender  status day_on_feed rnaseq_batch geno_comp_1\n#> R21     R21      F1 female Control          31           B2    0.007853\n#> Y3660 Y3660      F1   male Control          19           B2    0.852220\n#> Y3243 Y3243      F1   male Control          16           B2    0.044171\n#> R5764 R5764      F2   male Control          46           B1    0.213094\n#> P4669 P4669      F3   male     BRD          35           B2    0.389393\n#> R5452 R5452      F2   male Control          49           B1    0.265998\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster\n#> R21      0.820691    0.171456                K3\n#> Y3660    0.093585    0.054195                K2\n#> Y3243    0.190262    0.765567                K1\n#> R5764    0.676299    0.110607                K3\n#> P4669    0.503471    0.107136                K3\n#> R5452    0.733992    0.000010                K3\n\nNote that these methods can also be applied to the other types of containers.\n\n3.5.2 Using a target factory for creating omics sets\nThe function create_omics_set_factory() allows us to create several omics sets at once. It returns a list of targets, each storing one of the created omics set container. It takes as input arguments vectors that give for each omics set the arguments required by create_omics_set().\n\n\ncreate_omics_set_factory(\n  datasets = c(data_geno, data_transcripto, data_metabo),\n  omics_types = c(\"genomics\", \"transcriptomics\", \"metabolomics\"),\n  features_metadatas = c(fmetadata_geno, fmetadata_transcripto, fmetadata_metabo),\n  samples_metadatas = c(smetadata_all, smetadata_all, smetadata_all)\n)\n\n\nAgain, the warnings raised by the function originate from discrepancies between the datasets and associated metadata. It is always good practice to double-check manually to make sure that it is not due to a typo in the IDs or similar error.\nIf one of the datasets has no associated features or samples metadata, use NULL in the corresponding input arguments, e.g.:\n\n\ncreate_omics_set_factory(\n  datasets = c(data_geno, data_transcripto, data_metabo),\n  omics_types = c(\"genomics\", \"transcriptomics\", \"metabolomics\"),\n  features_metadatas = c(NULL, fmetadata_transcripto, fmetadata_metabo),\n  samples_metadatas = c(smetadata_all, NULL, smetadata_all)\n)\n\n\nThe create_omics_set_factory() function has a target_name_suffixes argument to customise the name of the created targets. However, if this argument is not provided, the function will attempt to read the suffixes to use from the name of the dataset targets. So in this case, it knows that the suffixes to use are 'geno', 'transcripto' and 'metabo'. Consequently, the function creates the following targets: set_geno, set_transcripto, set_metabo.\n\ntar_read(set_geno)\n#> SnpSet (storageMode: lockedEnvironment)\n#> assayData: 23036 features, 139 samples \n#>   element names: call, callProbability \n#> protocolData: none\n#> phenoData\n#>   rowNames: R21 Y3660 ... O5108 (139 total)\n#>   varLabels: id feedlot ... geno_comp_cluster (10 total)\n#>   varMetadata: labelDescription\n#> featureData\n#>   featureNames: 1_41768691 10-27008241-A-C-rs42918694 ... STAT5_13516_2\n#>     (23036 total)\n#>   fvarLabels: feature_id chromosome ... fdr (13 total)\n#>   fvarMetadata: labelDescription\n#> experimentData: use 'experimentData(object)'\n#> Annotation:\n\n\ntar_read(set_transcripto)\n#> ExpressionSet (storageMode: lockedEnvironment)\n#> assayData: 20335 features, 143 samples \n#>   element names: exprs \n#> protocolData: none\n#> phenoData\n#>   rowNames: R9497 R5969 ... Y9816 (143 total)\n#>   varLabels: id feedlot ... geno_comp_cluster (10 total)\n#>   varMetadata: labelDescription\n#> featureData\n#>   featureNames: ENSBTAG00000000005 ENSBTAG00000000008 ...\n#>     ENSBTAG00000055314 (20335 total)\n#>   fvarLabels: feature_id chromosome ... description (8 total)\n#>   fvarMetadata: labelDescription\n#> experimentData: use 'experimentData(object)'\n#> Annotation:\n\n\ntar_read(set_metabo)\n#> MetabolomeSet (storageMode: lockedEnvironment)\n#> assayData: 55 features, 139 samples \n#>   element names: call \n#> protocolData: none\n#> phenoData\n#>   rowNames: R21 Y3660 ... U5416 (139 total)\n#>   varLabels: id feedlot ... geno_comp_cluster (10 total)\n#>   varMetadata: labelDescription\n#> featureData\n#>   featureNames: HMDB00001 HMDB00008 ... HMDB01881 (55 total)\n#>   fvarLabels: feature_id hmdb_id ... de_status (16 total)\n#>   fvarMetadata: labelDescription\n#> experimentData: use 'experimentData(object)'\n#> Annotation:\n\n\nConverting targets factory to R script\nAgain there not an easy way to use loops to convert this targets factory, so instead we’ll write the code for each omics dataset.\n\nset_geno <- create_omics_set(\n  data_geno,\n  omics_type = \"genomics\",\n  features_metadata = fmetadata_geno,\n  samples_metadata = smetadata_all\n)\n\nset_transcripto <- create_omics_set(\n  data_transcripto,\n  omics_type = \"transcriptomics\",\n  features_metadata = fmetadata_transcripto,\n  samples_metadata = smetadata_all\n)\n\nset_metabo <- create_omics_set(\n  data_metabo,\n  omics_type = \"metabolomics\",\n  features_metadata = fmetadata_metabo,\n  samples_metadata = smetadata_all\n)"
  },
  {
    "objectID": "data_import.html#creating-the-multi-omics-set",
    "href": "data_import.html#creating-the-multi-omics-set",
    "title": "3  Importing data",
    "section": "\n3.6 Creating the multi-omics set",
    "text": "3.6 Creating the multi-omics set\nFinally, we can combine the different omics sets into one multi-omics set object. moiraine makes use of the MultiDataSet package for that. MultiDataSet (Hernandez-Ferrer et al. 2017) implements a multi-omics data container that collects, in one R object, several omics datasets alongside their associated features and samples metadata. One of the main advantages of using a MultiDataSet container is that we can pass all of the information associated with a set of related omics datasets with only one R object. In addition, the MultiDataSet package implements a number of very useful functions. For example, it is possible to assess the samples that are common to several omics sets. This is particularly useful for data integration, as the moiraine package can automatically discard samples missing from one or more datasets prior to the integration step if needed. Note that sample matching between the different omics datasets is based on sample IDs, so they must be consistent between the different datasets.\nWe will create the multi-omics set with the create_multiomics_set() function. It requires a list of the omics sets (that we created via either create_omics_set() or create_omics_set_factory()) to include, and returns a MultiDataSet::MultiDataSet-class object.\n\n\ntar_target(\n  mo_set,\n  create_multiomics_set(\n    list(set_geno,\n         set_transcripto,\n         set_metabo)\n  )\n)\n\n\n\ntar_read(mo_set)\n#> Object of class 'MultiDataSet'\n#>  . assayData: 3 elements\n#>     . snps: 23036 features, 139 samples \n#>     . rnaseq: 20335 features, 143 samples \n#>     . metabolome: 55 features, 139 samples \n#>  . featureData:\n#>     . snps: 23036 rows, 13 cols (feature_id, ..., p_value)\n#>     . rnaseq: 20335 rows, 8 cols (feature_id, ..., Name)\n#>     . metabolome: 55 rows, 16 cols (feature_id, ..., de_signif)\n#>  . rowRanges:\n#>     . snps: YES\n#>     . rnaseq: YES\n#>     . metabolome: NO\n#>  . phenoData:\n#>     . snps: 139 samples, 10 cols (id, ..., geno_comp_3)\n#>     . rnaseq: 143 samples, 10 cols (id, ..., geno_comp_3)\n#>     . metabolome: 139 samples, 10 cols (id, ..., geno_comp_3)\n\nWithin the MultiDataSet object, each omics set is assigned a name. The name depends first on the omics container type: a SnpSet set will be named snps, an ExpressionSet set will be named rnaseq, a MetabolomeSet will be named metabolome and a PhenotypeSet will be called phenotypes. If several sets of the same type are provided, they will be assigned unique names, e.g. snps+1 and snps+2 (the + symbol used as separator is set in the MultiDataSet package and cannot be changed). Alternatively, we can provide custom names for the datasets, using the datasets_names argument. These will be added to the type name (e.g. snps+customname). For example:\n\n\ntar_target(\n  mo_set_with_names,\n  create_multiomics_set(\n    list(set_geno,\n         set_transcripto,\n         set_metabo),\n    datasets_names = c(\"CaptureSeq\", \"RNAseq\", \"LCMS\")\n  )\n)\n\n\nreturns:\n\ntar_read(mo_set_with_names)\n#> Object of class 'MultiDataSet'\n#>  . assayData: 3 elements\n#>     . snps+CaptureSeq: 23036 features, 139 samples \n#>     . rnaseq+RNAseq: 20335 features, 143 samples \n#>     . metabolome+LCMS: 55 features, 139 samples \n#>  . featureData:\n#>     . snps+CaptureSeq: 23036 rows, 13 cols (feature_id, ..., p_value)\n#>     . rnaseq+RNAseq: 20335 rows, 8 cols (feature_id, ..., Name)\n#>     . metabolome+LCMS: 55 rows, 16 cols (feature_id, ..., de_signif)\n#>  . rowRanges:\n#>     . snps+CaptureSeq: YES\n#>     . rnaseq+RNAseq: YES\n#>     . metabolome+LCMS: NO\n#>  . phenoData:\n#>     . snps+CaptureSeq: 139 samples, 10 cols (id, ..., geno_comp_3)\n#>     . rnaseq+RNAseq: 143 samples, 10 cols (id, ..., geno_comp_3)\n#>     . metabolome+LCMS: 139 samples, 10 cols (id, ..., geno_comp_3)\n\nImportantly, the create_multiomics_set() function makes sure that samples metadata is consistent across the datasets for common samples. That is, if the same column (i.e. with the same name) is present in the samples metadata of several omics datasets, the values in this column must match for each sample present in all datasets. Otherwise, the function returns an error.\nIn the following chapter on Inspecting the MultiDataSet object, we will see how to handle the MultiDataSet object we just created. Alternatively, the MultiDataSet package vignette provides examples of constructing, querying and subsetting MultiDataSet objects."
  },
  {
    "objectID": "data_import.html#recap-targets-list",
    "href": "data_import.html#recap-targets-list",
    "title": "3  Importing data",
    "section": "\n3.7 Recap – targets list",
    "text": "3.7 Recap – targets list\nFor convenience, here is the list of targets that we created in this section:\n\nTargets list for data import\n\n\nlist(\n  ## Data import using a target factory\n  import_dataset_csv_factory(\n    files = c(\n      system.file(\"extdata/genomics_dataset.csv\", package = \"moiraine\"),\n      system.file(\"extdata/transcriptomics_dataset.csv\", package = \"moiraine\"),\n      system.file(\"extdata/metabolomics_dataset.csv\", package = \"moiraine\")\n    ),\n    col_ids = c(\"marker\", \"gene_id\", \"sample_id\"),\n    features_as_rowss = c(TRUE, TRUE, FALSE),\n    target_name_suffixes = c(\"geno\", \"transcripto\", \"metabo\")\n  ),\n  \n  ## Genomics features metadata file\n  tar_target(\n    fmetadata_file_geno,\n    system.file(\"extdata/genomics_features_info.csv\", package = \"moiraine\"),\n    format = \"file\"\n  ),\n  \n  ## Genomics features metadata import\n  tar_target(\n    fmetadata_geno,\n    import_fmetadata_csv(\n      fmetadata_file_geno,\n      col_id = \"marker\",\n      col_types = c(\"chromosome\" = \"c\")\n    )\n  ),\n  \n  ## Metabolomics features metadata import\n  import_fmetadata_csv_factory(\n    files = c(\n      system.file(\"extdata/metabolomics_features_info.csv\", package = \"moiraine\")\n    ),\n    col_ids = c(\"feature_id\"),\n    target_name_suffixes = c(\"metabo\")\n  ),\n  \n  ## Transcriptomics features metadata import\n  import_fmetadata_gff_factory(\n    files = system.file(\"extdata/bos_taurus_gene_model.gff3\", package = \"moiraine\"),\n    feature_types = \"genes\",\n    add_fieldss = c(\"Name\", \"description\"),\n    target_name_suffixes = \"transcripto\"\n  ),\n  \n  ## Samples metadata import\n  import_smetadata_csv_factory(\n    files = system.file(\"extdata/samples_info.csv\", package = \"moiraine\"),\n    col_ids = \"animal_id\",\n    target_name_suffixes = \"all\"\n  ),\n  \n  ## Creating omics sets for each dataset\n  create_omics_set_factory(\n    datasets = c(data_geno, data_transcripto, data_metabo),\n    omics_types = c(\"genomics\", \"transcriptomics\", \"metabolomics\"),\n    features_metadatas = c(fmetadata_geno, fmetadata_transcripto, fmetadata_metabo),\n    samples_metadatas = c(smetadata_all, smetadata_all, smetadata_all)\n  ),\n  \n  ## Creating the MultiDataSet object\n  tar_target(\n    mo_set,\n    create_multiomics_set(\n      list(set_geno,\n           set_transcripto,\n           set_metabo)\n    )\n  )\n)\n\n\n\n\n\n\nHernandez-Ferrer, Carles, Carlos Ruiz-Arenas, Alba Beltran-Gomila, and Juan R. González. 2017. “MultiDataSet: An r Package for Encapsulating Multiple Data Sets with Application to Omic Data Integration.” BMC Bioinformatics 18 (1): 36. https://doi.org/10.1186/s12859-016-1455-1."
  },
  {
    "objectID": "inspecting_multidataset.html#querying-datasets-names-and-dimensions",
    "href": "inspecting_multidataset.html#querying-datasets-names-and-dimensions",
    "title": "4  Inspecting the MultiDataSet object",
    "section": "\n4.1 Querying datasets names and dimensions",
    "text": "4.1 Querying datasets names and dimensions\nThe names of the omics datasets stored in a MultiDataSet object can be obtained with:\n\nnames(mo_set)\n#> [1] \"snps\"       \"rnaseq\"     \"metabolome\"\n\nIt is also possible to query the number of features and samples in each dataset via n_features() and n_samples(). Both functions return a named integer vector:\n\nn_features(mo_set)\n#>       snps     rnaseq metabolome \n#>      23036      20335         55\n\n\nn_samples(mo_set)\n#>       snps     rnaseq metabolome \n#>        139        143        139\n\nThe feature and sample IDs for each dataset can be extracted with the get_features() and get_samples() functions. Both functions return a named list of features or samples ID for each omics dataset:\n\nget_features(mo_set) |> str()\n#> List of 3\n#>  $ snps      : chr [1:23036] \"1_41768691\" \"10-27008241-A-C-rs42918694\" \"10-37505419-T-C-rs136559242\" \"10-49904259-G-A-rs471723345\" ...\n#>  $ rnaseq    : chr [1:20335] \"ENSBTAG00000000005\" \"ENSBTAG00000000008\" \"ENSBTAG00000000009\" \"ENSBTAG00000000010\" ...\n#>  $ metabolome: chr [1:55] \"HMDB00001\" \"HMDB00008\" \"HMDB00042\" \"HMDB00043\" ...\n\n\nget_samples(mo_set) |> str()\n#> List of 3\n#>  $ snps      : chr [1:139] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n#>  $ rnaseq    : chr [1:143] \"R9497\" \"R5969\" \"R5327\" \"R5979\" ...\n#>  $ metabolome: chr [1:139] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ..."
  },
  {
    "objectID": "inspecting_multidataset.html#extracting-datasets-and-metadata",
    "href": "inspecting_multidataset.html#extracting-datasets-and-metadata",
    "title": "4  Inspecting the MultiDataSet object",
    "section": "\n4.2 Extracting datasets and metadata",
    "text": "4.2 Extracting datasets and metadata\nWe can extract the dataset matrices from a MultiDataSet object with the get_datasets() function, which returns a named list of matrices, each with features as rows and samples as columns:\n\nget_datasets(mo_set) |> str()\n#> List of 3\n#>  $ snps      : num [1:23036, 1:139] 1 2 0 1 2 0 1 2 1 1 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : chr [1:23036] \"1_41768691\" \"10-27008241-A-C-rs42918694\" \"10-37505419-T-C-rs136559242\" \"10-49904259-G-A-rs471723345\" ...\n#>   .. ..$ : chr [1:139] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n#>  $ rnaseq    : num [1:20335, 1:143] 733 6 0 2693 0 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : chr [1:20335] \"ENSBTAG00000000005\" \"ENSBTAG00000000008\" \"ENSBTAG00000000009\" \"ENSBTAG00000000010\" ...\n#>   .. ..$ : chr [1:143] \"R9497\" \"R5969\" \"R5327\" \"R5979\" ...\n#>  $ metabolome: num [1:55, 1:139] 9.1 58.2 403 172.6 0.7 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : chr [1:55] \"HMDB00001\" \"HMDB00008\" \"HMDB00042\" \"HMDB00043\" ...\n#>   .. ..$ : chr [1:139] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n\n\nget_datasets(mo_set)[[\"snps\"]][1:5, 1:5]\n#>                             R21 Y3660 Y3243 R5764 P4669\n#> 1_41768691                    1     0     2     2     1\n#> 10-27008241-A-C-rs42918694    2     2     2     1     2\n#> 10-37505419-T-C-rs136559242   0     1     0     2     0\n#> 10-49904259-G-A-rs471723345   1     2     2     2     2\n#> 1-109550832-G-A-rs209732846   2     2     1     2     2\n\nTo obtain the matrix for a single dataset from the MultiDataSet object, the get_dataset_matrix() function can be used instead:\n\nget_dataset_matrix(mo_set, \"snps\")[1:5, 1:5]\n#>                             R21 Y3660 Y3243 R5764 P4669\n#> 1_41768691                    1     0     2     2     1\n#> 10-27008241-A-C-rs42918694    2     2     2     1     2\n#> 10-37505419-T-C-rs136559242   0     1     0     2     0\n#> 10-49904259-G-A-rs471723345   1     2     2     2     2\n#> 1-109550832-G-A-rs209732846   2     2     1     2     2\n\nSimilarly, the functions get_features_metadata() and get_samples_metadata() each return a named list of feature or sample metadata data-frames, one per omics dataset:\n\nget_features_metadata(mo_set) |> str()\n#> List of 3\n#>  $ snps      :'data.frame':  23036 obs. of  13 variables:\n#>   ..$ feature_id     : chr [1:23036] \"1_41768691\" \"10-27008241-A-C-rs42918694\" \"10-37505419-T-C-rs136559242\" \"10-49904259-G-A-rs471723345\" ...\n#>   ..$ chromosome     : chr [1:23036] \"1\" \"10\" \"10\" \"0\" ...\n#>   ..$ position       : num [1:23036] 4.21e+07 2.70e+07 3.74e+07 0.00 1.09e+08 ...\n#>   ..$ gen_train_score: num [1:23036] 0.679 0.805 0.789 0.797 0.891 ...\n#>   ..$ ref            : chr [1:23036] \"T\" \"A\" \"A\" \"A\" ...\n#>   ..$ alt            : chr [1:23036] \"G\" \"C\" \"G\" \"G\" ...\n#>   ..$ ilmn_strand    : chr [1:23036] \"BOT\" \"TOP\" \"TOP\" \"TOP\" ...\n#>   ..$ customer_strand: chr [1:23036] \"BOT\" \"TOP\" \"BOT\" \"TOP\" ...\n#>   ..$ norm_id        : num [1:23036] 2 1 1 2 3 1 3 3 0 0 ...\n#>   ..$ qtl_type       : chr [1:23036] \"non signif.\" \"non signif.\" \"non signif.\" \"non signif.\" ...\n#>   ..$ qtl_effect     : num [1:23036] NA NA NA NA NA NA NA NA NA NA ...\n#>   ..$ p_value        : num [1:23036] NA NA NA NA NA NA NA NA NA NA ...\n#>   ..$ fdr            : num [1:23036] NA NA NA NA NA NA NA NA NA NA ...\n#>  $ rnaseq    :'data.frame':  20335 obs. of  8 variables:\n#>   ..$ feature_id : chr [1:20335] \"ENSBTAG00000000005\" \"ENSBTAG00000000008\" \"ENSBTAG00000000009\" \"ENSBTAG00000000010\" ...\n#>   ..$ chromosome : Factor w/ 178 levels \"1\",\"2\",\"3\",\"4\",..: 17 29 18 21 8 20 20 5 5 23 ...\n#>   ..$ start      : int [1:20335] 65389743 32214439 12338037 34209956 7950815 33708626 33674806 74883636 74905031 27720176 ...\n#>   ..$ end        : int [1:20335] 65505336 32244810 12342272 34223394 7971600 33732944 33703223 74893752 74919112 27721739 ...\n#>   ..$ width      : int [1:20335] 115594 30372 4236 13439 20786 24319 28418 10117 14082 1564 ...\n#>   ..$ strand     : Factor w/ 3 levels \"+\",\"-\",\"*\": 1 2 1 1 2 1 1 2 2 2 ...\n#>   ..$ Name       : chr [1:20335] \"GRK3\" \"KCNJ1\" \"FOXF1\" \"UBL7\" ...\n#>   ..$ description: chr [1:20335] \"G protein-coupled receptor kinase 3 [Source:VGNC Symbol;Acc:VGNC:53904]\" \"potassium inwardly rectifying channel subfamily J member 1 [Source:VGNC Symbol;Acc:VGNC:30453]\" \"forkhead box F1 [Source:VGNC Symbol;Acc:VGNC:29084]\" \"ubiquitin like 7 [Source:VGNC Symbol;Acc:VGNC:50128]\" ...\n#>  $ metabolome:'data.frame':  55 obs. of  16 variables:\n#>   ..$ feature_id                  : chr [1:55] \"HMDB00001\" \"HMDB00008\" \"HMDB00042\" \"HMDB00043\" ...\n#>   ..$ hmdb_id                     : chr [1:55] \"HMDB0000001\" \"HMDB0000008\" \"HMDB0000042\" \"HMDB0000043\" ...\n#>   ..$ name                        : chr [1:55] \"1-Methylhistidine\" \"2-Hydroxybutyric acid\" \"Acetic acid\" \"Betaine\" ...\n#>   ..$ chemical_formula            : chr [1:55] \"C7H11N3O2\" \"C4H8O3\" \"C2H4O2\" \"C5H12NO2\" ...\n#>   ..$ monisotopic_molecular_weight: num [1:55] 169 104 60 118 102 ...\n#>   ..$ cas_registry_number         : chr [1:55] \"332-80-9\" \"3347-90-8\" \"64-19-7\" \"6915-17-9\" ...\n#>   ..$ smiles                      : chr [1:55] \"CN1C=NC(C[C@H](N)C(O)=O)=C1\" \"CC[C@H](O)C(O)=O\" \"CC(O)=O\" \"C[N+](C)(C)CC(O)=O\" ...\n#>   ..$ inchikey                    : chr [1:55] \"BRMWTNUJHUMWMS-LURJTMIESA-N\" \"AFENDNXGAFYKQO-VKHMYHEASA-N\" \"QTBSBXVTEAMEQO-UHFFFAOYSA-N\" \"KWIUHFFTVRNATP-UHFFFAOYSA-O\" ...\n#>   ..$ kegg_id                     : chr [1:55] \"C01152\" \"C05984\" \"C00033\" NA ...\n#>   ..$ direct_parent               : chr [1:55] \"Histidine and derivatives\" \"Alpha hydroxy acids and derivatives\" \"Carboxylic acids\" \"Alpha amino acids\" ...\n#>   ..$ super_class                 : chr [1:55] \"Organic acids and derivatives\" \"Organic acids and derivatives\" \"Organic acids and derivatives\" \"Organic acids and derivatives\" ...\n#>   ..$ t_value                     : num [1:55] -0.556 0.218 -12.532 -7.907 -0.437 ...\n#>   ..$ p_value                     : num [1:55] 5.80e-01 8.28e-01 1.75e-24 7.83e-13 6.63e-01 ...\n#>   ..$ padj                        : num [1:55] 6.78e-01 8.93e-01 4.82e-23 3.91e-12 7.44e-01 ...\n#>   ..$ de_signif                   : chr [1:55] \"Not DE\" \"Not DE\" \"DE\" \"DE\" ...\n#>   ..$ de_status                   : chr [1:55] \"Not DE\" \"Not DE\" \"downregulated\" \"downregulated\" ...\n\n\nget_samples_metadata(mo_set) |> str()\n#> List of 3\n#>  $ snps      :'data.frame':  139 obs. of  10 variables:\n#>   ..$ id               : chr [1:139] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n#>   ..$ feedlot          : chr [1:139] \"F1\" \"F1\" \"F1\" \"F2\" ...\n#>   ..$ gender           : chr [1:139] \"female\" \"male\" \"male\" \"male\" ...\n#>   ..$ status           : chr [1:139] \"Control\" \"Control\" \"Control\" \"Control\" ...\n#>   ..$ day_on_feed      : num [1:139] 31 19 16 46 35 49 21 16 37 37 ...\n#>   ..$ rnaseq_batch     : chr [1:139] \"B2\" \"B2\" \"B2\" \"B1\" ...\n#>   ..$ geno_comp_1      : num [1:139] 0.00785 0.85222 0.04417 0.21309 0.38939 ...\n#>   ..$ geno_comp_2      : num [1:139] 0.8207 0.0936 0.1903 0.6763 0.5035 ...\n#>   ..$ geno_comp_3      : num [1:139] 0.1715 0.0542 0.7656 0.1106 0.1071 ...\n#>   ..$ geno_comp_cluster: chr [1:139] \"K3\" \"K2\" \"K1\" \"K3\" ...\n#>  $ rnaseq    :'data.frame':  143 obs. of  10 variables:\n#>   ..$ id               : chr [1:143] \"R9497\" \"R5969\" \"R5327\" \"R5979\" ...\n#>   ..$ feedlot          : chr [1:143] \"F2\" \"F2\" \"F2\" \"F2\" ...\n#>   ..$ gender           : chr [1:143] \"male\" \"male\" \"male\" \"male\" ...\n#>   ..$ status           : chr [1:143] \"BRD\" \"BRD\" \"BRD\" \"BRD\" ...\n#>   ..$ day_on_feed      : num [1:143] 35 24 38 30 31 24 26 18 13 32 ...\n#>   ..$ rnaseq_batch     : chr [1:143] \"B1\" \"B1\" \"B1\" \"B1\" ...\n#>   ..$ geno_comp_1      : num [1:143] 0.15372 0.11066 0.14073 0.28673 0.00001 ...\n#>   ..$ geno_comp_2      : num [1:143] 0.745 0.626 0.809 0.108 0.999 ...\n#>   ..$ geno_comp_3      : num [1:143] 0.10178 0.26351 0.04987 0.60547 0.00108 ...\n#>   ..$ geno_comp_cluster: chr [1:143] \"K3\" \"K3\" \"K3\" \"K1\" ...\n#>  $ metabolome:'data.frame':  139 obs. of  10 variables:\n#>   ..$ id               : chr [1:139] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n#>   ..$ feedlot          : chr [1:139] \"F1\" \"F1\" \"F1\" \"F2\" ...\n#>   ..$ gender           : chr [1:139] \"female\" \"male\" \"male\" \"male\" ...\n#>   ..$ status           : chr [1:139] \"Control\" \"Control\" \"Control\" \"Control\" ...\n#>   ..$ day_on_feed      : num [1:139] 31 19 16 46 35 49 21 16 37 37 ...\n#>   ..$ rnaseq_batch     : chr [1:139] \"B2\" \"B2\" \"B2\" \"B1\" ...\n#>   ..$ geno_comp_1      : num [1:139] 0.00785 0.85222 0.04417 0.21309 0.38939 ...\n#>   ..$ geno_comp_2      : num [1:139] 0.8207 0.0936 0.1903 0.6763 0.5035 ...\n#>   ..$ geno_comp_3      : num [1:139] 0.1715 0.0542 0.7656 0.1106 0.1071 ...\n#>   ..$ geno_comp_cluster: chr [1:139] \"K3\" \"K2\" \"K1\" \"K3\" ...\n\nFor the samples metadata, it is possible to extract a single data-frame that combines the metadata from the different datasets with the function get_samples_metadata_combined(). The only_common_cols argument controls whether only the columns that are common to the samples metadata of the different omics datasets should be returned. For this example, as the samples metadata is identical across the datasets, it makes no difference:\n\nget_samples_metadata_combined(mo_set) |> head()\n#>          id feedlot gender  status day_on_feed rnaseq_batch geno_comp_1\n#> R21     R21      F1 female Control          31           B2    0.007853\n#> Y3660 Y3660      F1   male Control          19           B2    0.852220\n#> Y3243 Y3243      F1   male Control          16           B2    0.044171\n#> R5764 R5764      F2   male Control          46           B1    0.213094\n#> P4669 P4669      F3   male     BRD          35           B2    0.389393\n#> R5452 R5452      F2   male Control          49           B1    0.265998\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster\n#> R21      0.820691    0.171456                K3\n#> Y3660    0.093585    0.054195                K2\n#> Y3243    0.190262    0.765567                K1\n#> R5764    0.676299    0.110607                K3\n#> P4669    0.503471    0.107136                K3\n#> R5452    0.733992    0.000010                K3"
  },
  {
    "objectID": "inspecting_multidataset.html#sec-inspecting-multidataset-summary-plots",
    "href": "inspecting_multidataset.html#sec-inspecting-multidataset-summary-plots",
    "title": "4  Inspecting the MultiDataSet object",
    "section": "\n4.3 Summary plots",
    "text": "4.3 Summary plots\nA number of plotting functions have been implemented to obtain a quick overview of the omics datasets in a MultiDataSet object.\n\n4.3.1 Samples upset plot\nFirst, the plot_samples_upset() function displays the number of common and unique samples across the datasets with an UpSet plot:\n\nplot_samples_upset(mo_set)\n\n\n\n\nAs can be seen in the upset plot above, 135 samples have measurements across all three omics datasets. In addition, 4 samples have both transcriptomics and metabolomics measurements, but no transcriptomics information; 3 samples are present in the genomics and metabolomics datasets but not the transcriptomics dataset, and the genomics and transcriptomics datasets each have a unique sample not present in the other omics datasets.\n\n4.3.2 Datasets density plots\nNext, we can show the density plot of each omics dataset with the plot_density_data() function. By default, all datasets are plotted onto the same axes, which is not very useful if they have very different scales. We can change that by setting the combined argument to FALSE, which splits the plot into one facet per dataset, and by setting scales to 'free' in order to give its own scale to each dataset:\n\nplot_density_data(mo_set, combined = FALSE, scales = \"free\")\n\n\n\n\nBy default, all datasets are represented in the density plot, but it is possible to focus on one or a subset of them via the datasets argument. This is useful here as the plots for the transcriptomics and metabolomics could benefit from a log10 transformation for the x-axis:\n\nplot_density_data(\n  mo_set,\n  datasets = c(\"rnaseq\", \"metabolome\"),\n  combined = FALSE,\n  scales = \"free\"\n) +\n  scale_x_log10()\n#> Warning: Transformation introduced infinite values in continuous x-axis\n#> Warning: Removed 338138 rows containing non-finite values (`stat_density()`).\n\n\n\n\nNote that as the plot_density_data() function returns a ggplot, it can be further customised with other ggplot2 functions as shown above.\n\n4.3.3 Datasets mean-sd plots\nIt is also possible to assess for each dataset whether there exists a relationship between the features mean and standard deviation, with the plot_meansd_data() function. The presence of such relationship indicates that the dataset should be transformed, via a log or variance-stabilising transformation. The function requires the hexbin package to be installed:\n\nplot_meansd_data(mo_set)\n\n\n\n\nIn our case, we can see a very strong relationship between features mean and standard deviation in both the transcriptomics and metabolomics datasets, which suggest that a log or variance-stabilising transformation will be necessary in both cases (datasets transformation are covered in Chapter 6).\nNote that the hexplots are only drawn for datasets with at least 30 features, and the trend curve (in pink) is only drawn for datasets with at least 10 features."
  },
  {
    "objectID": "inspecting_multidataset.html#assessing-missing-values",
    "href": "inspecting_multidataset.html#assessing-missing-values",
    "title": "4  Inspecting the MultiDataSet object",
    "section": "\n4.4 Assessing missing values",
    "text": "4.4 Assessing missing values\nFinally, one very important aspect to check is the presence of missing values in the datasets. The function check_missing_values() provide a summary of the number of missing values in each dataset:\n\ncheck_missing_values(mo_set)\n#> 9615 (0.3%) missing values in snps dataset, across 4093 features and 139 samples.\n#> No missing values in rnaseq dataset.\n#> 588 (7.69%) missing values in metabolome dataset, across 15 features and 45 samples.\n\nThe function returns an invisible character vector containing the messages printed above, which is useful for automatic reporting.\nIn Chapter 6, we will see how to impute missing values."
  },
  {
    "objectID": "inspecting_multidataset.html#sec-inspecting-plot-data",
    "href": "inspecting_multidataset.html#sec-inspecting-plot-data",
    "title": "4  Inspecting the MultiDataSet object",
    "section": "\n4.5 Visualising the datasets",
    "text": "4.5 Visualising the datasets\nOnce the omics datasets are stored in a MultiDataSet object, we can easily visualise the measurements for a set of features of interest. As an example, we will randomly select three features from each of the omics datasets:\n\nset.seed(32)\nrandom_features <- get_features(mo_set) |>\n  map(\\(x) sample(x, size = 3, replace = FALSE)) |>\n  unlist() |>\n  unname()\n\nrandom_features\n#> [1] \"ARS-BFGL-NGS-102169_dup\" \"BovineHD0300020059\"     \n#> [3] \"BTB-01546164\"            \"ENSBTAG00000038316\"     \n#> [5] \"ENSBTAG00000016902\"      \"ENSBTAG00000048333\"     \n#> [7] \"HMDB00214\"               \"HMDB00407\"              \n#> [9] \"HMDB00182\"\n\n\n4.5.1 As a heatmap\nThe function plot_data_heatmap() allows us to view the data for these features as a heatmap. It relies on the ComplexHeatmap::Heatmap() function, and can be customised by passing arguments to this function (for example to remove the column labels):\n\nplot_data_heatmap(\n  mo_set,\n  random_features,\n  center = TRUE,\n  scale = TRUE,\n  show_column_names = FALSE\n)\n#> Warning: Not enough data to calculate distance between samples, disabling\n#> clustering of columns.\n\n\n\n\nNote that we specified that the data should be centred and scaled before plotting, to represent features from different datasets on a similar scale.\nBy default, all samples all represented, including those that are only present in some of the omics datasets (hence the warning about columns clustering). We can instead restrict the plot to only samples that are present across all datasets (only_common_samples argument), or to specific samples by passing a list of samples ID to the samples argument:\n\nplot_data_heatmap(\n  mo_set,\n  random_features,\n  center = TRUE,\n  scale = TRUE,\n  show_column_names = FALSE,\n  samples = c(\"O4713\", \"Y3660\", \"R5979\")\n)\n\n\n\n\nWe can also add samples and/or features information to the sides of the heatmap through the samples_info and features_info arguments. These two arguments take a vector of column names from the samples or features metadata table, respectively. The ComplexHeatmap::Heatmap() picks random colours for these annotations, but we can set specific colour palettes by passing a list of colour palettes through the argument colours_list. For continuous annotations, the colour palette must be generated with circlize::colorRamp2().\n\nplot_data_heatmap(\n  mo_set,\n  random_features,\n  center = TRUE,\n  scale = TRUE,\n  show_column_names = FALSE,\n  only_common_samples = TRUE,\n  samples_info = c(\"status\", \"day_on_feed\"),\n  features_info = c(\"chromosome\"),\n  colours_list = list(\n    \"status\" = c(\"Control\" = \"gold\", \"BRD\" = \"lightblue\"),\n    \"day_on_feed\" = colorRamp2(c(5, 70), c(\"white\", \"pink3\"))\n  )\n)\n\n\n\n\nWe can also use information from the features metadata tables to give a more meaningful label to the features. For example, we can use the column Name from the transcriptomics features metadata and the column name from the metabolomics features metadata to label the features. This is done by passing a named list through the label_cols argument, where each element is the name of the column to use and the name of the element gives the name of the dataset in the MultiDataSet object. If these labels are too long, we can truncate them through the truncate argument (see the function help).\n\nplot_data_heatmap(\n  mo_set,\n  random_features,\n  center = TRUE,\n  scale = TRUE,\n  show_column_names = FALSE,\n  only_common_samples = TRUE,\n  samples_info = c(\"status\", \"day_on_feed\"),\n  features_info = c(\"chromosome\"),\n  colours_list = list(\n    \"status\" = c(\"Control\" = \"gold\", \"BRD\" = \"lightblue\"),\n    \"day_on_feed\" = colorRamp2(c(5, 70), c(\"white\", \"pink3\"))\n  ),\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  truncate = 20\n)\n\n\n\n\nNote that because we didn’t include the snps dataset in the list passed through label_cols, the ID of the features are used as labels.\n\n4.5.2 Against samples covariates\nAlternatively, we can display the features’ measurements against some samples covariate, with the plot_data_covariate() function. As for the plot_data_heatmap() function, the plot shows data from all samples, unless otherwise specified (through either the common_samples_only or samples arguments). The covariate is specified as a column name from the samples metadata (can be from any dataset’s samples metadata). If the covariate is categorical, the function generates violin plots. For example, we can represent the feature’s measurements against the animal disease status:\n\nplot_data_covariate(\n  mo_set,\n  \"status\",\n  random_features,\n  only_common_samples = TRUE\n)\n\n\n\n\nWe can use other columns from the samples metadata to customise the points colour and shape. For the colour, the constructed plot will depend on whether the corresponding in categorical or numeric:\n\nplot_data_covariate(\n  mo_set,\n  \"status\",\n  random_features,\n  only_common_samples = TRUE,\n  colour_by = \"gender\",\n  shape_by = \"feedlot\"\n)\n\n\n\n\nplot_data_covariate(\n  mo_set,\n  \"status\",\n  random_features,\n  only_common_samples = TRUE,\n  colour_by = \"day_on_feed\",\n  shape_by = \"feedlot\"\n)\n\n\n\n\nIf instead the covariate is numerical, the function produces scatterplots with a loess curve for each feature:\n\nplot_data_covariate(\n  mo_set,\n  \"day_on_feed\",\n  random_features,\n  only_common_samples = TRUE\n)\n\n\n\n\nAgain, we can use other samples information to specify the colour or shapes of the samples. Note that if the covariate used for points colour is discrete, a loess curve will be fitted for each category. If the covariate is continuous, or if changing the shape of the points, only one loess curve will be fitted for all data points.\n\nplot_data_covariate(\n  mo_set,\n  \"day_on_feed\",\n  random_features,\n  only_common_samples = TRUE,\n  colour_by = \"status\",\n  shape_by = \"status\"\n)\n\n\n\n\nplot_data_covariate(\n  mo_set,\n  \"day_on_feed\",\n  random_features,\n  only_common_samples = TRUE,\n  colour_by = \"day_on_feed\",\n  shape_by = \"feedlot\"\n)\n\n\n\n\nThe features can be renamed using features metadata through the label_cols argument in the same way that with the plot_data_heatmap() function:\n\nplot_data_covariate(\n  mo_set,\n  \"day_on_feed\",\n  random_features,\n  only_common_samples = TRUE,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  )\n)"
  },
  {
    "objectID": "inspecting_multidataset.html#recap-targets-list",
    "href": "inspecting_multidataset.html#recap-targets-list",
    "title": "4  Inspecting the MultiDataSet object",
    "section": "\n4.6 Recap – targets list",
    "text": "4.6 Recap – targets list\nAlthough we didn’t create any new target in this section, we can turn some plots into targets.\n\nTargets list for inspecting a MultiDataSet object\n\n\nlist(\n  ## Creating a density plot for each dataset\n  tar_target(\n    density_plots,\n    plot_density_data(\n      mo_set,\n      combined = FALSE,\n      scales = \"free\"\n    )\n  ),\n\n  ## Plotting the relationship between features mean and standard deviation\n  ## for each dataset\n  tar_target(\n    mean_sd_plots,\n    plot_meansd_data(mo_set)\n  ),\n  \n  ## Assessing missing values\n  tar_target(\n    n_missing_values,\n    check_missing_values(mo_set)\n  )\n)"
  },
  {
    "objectID": "modifying_multidataset.html#modifying-a-dataset-matrix",
    "href": "modifying_multidataset.html#modifying-a-dataset-matrix",
    "title": "5  Modifying the MultiDataSet object",
    "section": "\n5.1 Modifying a dataset matrix",
    "text": "5.1 Modifying a dataset matrix\nLet us imagine that, prior to performing the data transformation step (which we will see in Chapter 6), we want to replace all zero values in the transcriptomics dataset with a small value, to avoid issues during the log-transformation process (note that this is only to illustrate this functionality, for the actual analysis we will use a different transformation that handles zero values). We will pick this small value as half of the non-null minimum value in the dataset (which will be 0.5, since we are working with count data). We can compute the new matrix of RNAseq counts:\n\nrnaseq_mat <- get_dataset_matrix(mo_set, \"rnaseq\")\nrnaseq_mat[1:5, 1:5]\n#>                    R9497 R5969 R5327 R5979 R9504\n#> ENSBTAG00000000005   733  1407  2919   872   740\n#> ENSBTAG00000000008     6     7     3    10    20\n#> ENSBTAG00000000009     0     1     9     0     0\n#> ENSBTAG00000000010  2693  2212  2937  2000  2345\n#> ENSBTAG00000000011     0     1     1     1     0\n\nsmall_val <- (1/2) * min(rnaseq_mat[rnaseq_mat != 0])\nsmall_val\n#> [1] 0.5\n\nnew_mat <- rnaseq_mat\nnew_mat[new_mat == 0] <- small_val\n\nnew_mat[1:5, 1:5]\n#>                     R9497 R5969 R5327  R5979  R9504\n#> ENSBTAG00000000005  733.0  1407  2919  872.0  740.0\n#> ENSBTAG00000000008    6.0     7     3   10.0   20.0\n#> ENSBTAG00000000009    0.5     1     9    0.5    0.5\n#> ENSBTAG00000000010 2693.0  2212  2937 2000.0 2345.0\n#> ENSBTAG00000000011    0.5     1     1    1.0    0.5\n\nIn order to replace the rnaseq dataset stored in the MultiDataSet object with this new matrix, we pass both the object and the new matrix to the replace_dataset() function, along with the name of the omics dataset whose matrix should be replaced:\n\nmo_set_modif <- replace_dataset(mo_set, \"rnaseq\", new_mat)\n\n## Checking that the replacement has been done\nget_dataset_matrix(mo_set_modif, \"rnaseq\")[1:5, 1:5]\n#>                     R9497 R5969 R5327  R5979  R9504\n#> ENSBTAG00000000005  733.0  1407  2919  872.0  740.0\n#> ENSBTAG00000000008    6.0     7     3   10.0   20.0\n#> ENSBTAG00000000009    0.5     1     9    0.5    0.5\n#> ENSBTAG00000000010 2693.0  2212  2937 2000.0 2345.0\n#> ENSBTAG00000000011    0.5     1     1    1.0    0.5\n\nNote that this only works for modifying the values within an omics dataset, and not for filtering, since both features and samples number and IDs in the new dataset matrix should match the ones in the original matrix:\n\nmo_set_modif <- replace_dataset(mo_set, \"rnaseq\", new_mat[1:10, 1:10])\n#> Error in replace_dataset(mo_set, \"rnaseq\", new_mat[1:10, 1:10]): 'new_data' argument has incorrect dimensions. Should have 20335 rows (features) and 143 columns (samples).\n\n\nClick here to see a targets version of the code.\n\n\nlist(\n  ## Replacing zero values in RNAseq dataset\n  ## (note that it is more tidy to write a function for that and call it here)\n  tar_target(\n    rnaseq_mat_nozero,\n    {\n      rnaseq_mat <- get_dataset_matrix(mo_set, \"rnaseq\")\n      small_val <- (1/2) * min(rnaseq_mat[rnaseq_mat != 0])\n      new_mat <- rnaseq_mat\n      new_mat[new_mat == 0] <- small_val\n\n      new_mat\n    }\n  ),\n\n  ## Replacing RNAseq dataset in MultiDataSet object\n  tar_target(\n    mo_set_rnaseq_nozero,\n    replace_dataset(mo_set, \"rnaseq\", rnaseq_mat_nozero)\n  )\n)"
  },
  {
    "objectID": "modifying_multidataset.html#adding-information-to-features-metadata",
    "href": "modifying_multidataset.html#adding-information-to-features-metadata",
    "title": "5  Modifying the MultiDataSet object",
    "section": "\n5.2 Adding information to features metadata",
    "text": "5.2 Adding information to features metadata\nIn the case of the transcriptomics dataset, we extracted the features metadata directly from a GFF file, which provides information about the genome annotation used. However, we might want to add information about the genes from a different source. We could add this information to the data-frame generated with import_fmetadata_gff() (see Section 3.3.3) before creating theMultiDataSet object, but we will demonstrate here how to add information once we’ve already created the object. Note that we will use targets for this example, as we will incorporate these changes in our analysis pipeline.\nLet’s start by reading in the differential expression results:\n\n\nlist(\n  tar_target(\n    rnaseq_de_res_file,\n    system.file(\n      \"extdata/transcriptomics_de_results.csv\",\n      package = \"moiraine\"\n    ),\n    format = \"file\"\n  ),\n\n  tar_target(\n    rnaseq_de_res_df,\n    read_csv(rnaseq_de_res_file) |>\n      rename(feature_id = gene_id) |>\n      mutate(dataset = \"rnaseq\")\n  )\n)\n\n\nNotice that in the results file, the gene IDs are stored in the gene_id column. Here, we rename this column as feature_id, which is required for adding it to the features metadata. In addition, we create a dataset column which contains the name of the dataset in the MultiDataSet object to which the features belong. This is also necessary.\nThe differential results look like this:\n\ntar_read(rnaseq_de_res_df) |>\n  head()\n#> # A tibble: 6 × 9\n#>   feature_id  log_fc log_cpm     f  p_value      fdr de_signif de_status dataset\n#>   <chr>        <dbl>   <dbl> <dbl>    <dbl>    <dbl> <chr>     <chr>     <chr>  \n#> 1 ENSBTAG000…   4.61    4.19  358. 5.32e-40 5.93e-36 DE        upregula… rnaseq \n#> 2 ENSBTAG000…   3.80    6.83  356. 6.33e-40 5.93e-36 DE        upregula… rnaseq \n#> 3 ENSBTAG000…   5.41    2.24  347. 2.41e-39 1.50e-35 DE        upregula… rnaseq \n#> 4 ENSBTAG000…   4.34    3.52  344. 3.40e-39 1.59e-35 DE        upregula… rnaseq \n#> 5 ENSBTAG000…   2.18    6.74  327. 4.05e-38 1.52e-34 DE        upregula… rnaseq \n#> 6 ENSBTAG000…  -1.31    2.64  316. 2.39e-37 7.48e-34 Not DE    Not DE    rnaseq\n\nWe can now use the add_features_metadata() function to add this table to the features metadata of the transcriptomics dataset. The new MultiDataSet object that includes information about the differential expression results will be saved in the mo_set_de target:\n\n\ntar_target(\n  mo_set_de,\n  add_features_metadata(mo_set, rnaseq_de_res_df)\n)\n\n\nThe new information has been added to the features metadata of the transcriptomics dataset.\n\ntar_read(mo_set_de) |>\n  get_features_metadata() |>\n  pluck(\"rnaseq\") |>\n  head()\n#>                            feature_id chromosome    start      end  width\n#> ENSBTAG00000000005 ENSBTAG00000000005         17 65389743 65505336 115594\n#> ENSBTAG00000000008 ENSBTAG00000000008         29 32214439 32244810  30372\n#> ENSBTAG00000000009 ENSBTAG00000000009         18 12338037 12342272   4236\n#> ENSBTAG00000000010 ENSBTAG00000000010         21 34209956 34223394  13439\n#> ENSBTAG00000000011 ENSBTAG00000000011          8  7950815  7971600  20786\n#> ENSBTAG00000000012 ENSBTAG00000000012         20 33708626 33732944  24319\n#>                    strand  Name\n#> ENSBTAG00000000005      +  GRK3\n#> ENSBTAG00000000008      - KCNJ1\n#> ENSBTAG00000000009      + FOXF1\n#> ENSBTAG00000000010      +  UBL7\n#> ENSBTAG00000000011      -   TDH\n#> ENSBTAG00000000012      + TTC33\n#>                                                                                                       description\n#> ENSBTAG00000000005                        G protein-coupled receptor kinase 3 [Source:VGNC Symbol;Acc:VGNC:53904]\n#> ENSBTAG00000000008 potassium inwardly rectifying channel subfamily J member 1 [Source:VGNC Symbol;Acc:VGNC:30453]\n#> ENSBTAG00000000009                                            forkhead box F1 [Source:VGNC Symbol;Acc:VGNC:29084]\n#> ENSBTAG00000000010                                           ubiquitin like 7 [Source:VGNC Symbol;Acc:VGNC:50128]\n#> ENSBTAG00000000011                                 L-threonine dehydrogenase [Source:VGNC Symbol;Acc:VGNC:108945]\n#> ENSBTAG00000000012                         tetratricopeptide repeat domain 33 [Source:VGNC Symbol;Acc:VGNC:36471]\n#>                         log_fc    log_cpm          f      p_value          fdr\n#> ENSBTAG00000000005  0.13603041  5.9051177  4.1626465 4.324808e-02 7.170137e-02\n#> ENSBTAG00000000008 -0.12965356 -0.7437052  1.0676845 3.032916e-01 3.938643e-01\n#> ENSBTAG00000000009  1.27141158 -2.5627934 23.9562951 2.731328e-06 9.665375e-06\n#> ENSBTAG00000000010  0.39567729  6.2563594 60.5303416 1.581955e-12 1.521160e-11\n#> ENSBTAG00000000011  0.07766873 -2.7608361  0.1418457 7.070363e-01 7.773874e-01\n#> ENSBTAG00000000012  0.15756169  3.6628775 11.0448775 1.141125e-03 2.623062e-03\n#>                    de_signif de_status\n#> ENSBTAG00000000005    Not DE    Not DE\n#> ENSBTAG00000000008    Not DE    Not DE\n#> ENSBTAG00000000009    Not DE    Not DE\n#> ENSBTAG00000000010    Not DE    Not DE\n#> ENSBTAG00000000011    Not DE    Not DE\n#> ENSBTAG00000000012    Not DE    Not DE\n\nNote that with this function, we can add information about features from different datasets at once, which is why there needs to be a dataset column in the data-frame to add, indicating the dataset to which each feature belongs. Also, not all features from a given dataset need to be present in this new data-frame; it is possible to add information for only a subset of them. In that case, the function will throw a warning giving the number of features from the corresponding dataset missing from the new data-frame, and the new columns in the corresponding features metadata will be filled with NA for features not present. However, it is only possible to add columns that do not already exist in the corresponding features metadata."
  },
  {
    "objectID": "modifying_multidataset.html#adding-information-to-samples-metadata",
    "href": "modifying_multidataset.html#adding-information-to-samples-metadata",
    "title": "5  Modifying the MultiDataSet object",
    "section": "\n5.3 Adding information to samples metadata",
    "text": "5.3 Adding information to samples metadata\nSimilarly, we can add a data-frame of information to the samples metadata. Here, we will create a table that contains “new” simulated information about the samples that we want to incorporate in our MultiDataSet object.\n\n## Getting the list of samples ID across the datasets\nsamples_list <- get_samples(mo_set) |>\n  unlist() |>\n  unname() |>\n  unique()\n\n## Simulating new information table, with new samples grouping\nnew_samples_df <- tibble(id = samples_list) |>\n  mutate(new_group = sample(letters[1:3], n(), replace = TRUE))\n\nhead(new_samples_df)\n#> # A tibble: 6 × 2\n#>   id    new_group\n#>   <chr> <chr>    \n#> 1 R21   c        \n#> 2 Y3660 b        \n#> 3 Y3243 b        \n#> 4 R5764 c        \n#> 5 P4669 a        \n#> 6 R5452 c\n\nNote that the sample IDs must be stored in a column named id. We will use the add_samples_metadata() function to add this new data-frame to the samples metadata in our MultiDataSet object. There are several options for which samples metadata tables should be modified; this is controlled through the datasets argument of the function. By default, the information is added to the samples metadata table of all omics datasets (case when datasets = NULL):\n\nmo_set_new_samples_info <- add_samples_metadata(mo_set, new_samples_df)\n#> Warning: snps dataset: 5 sample IDs not in 'mo_data', will be removed from\n#> samples metadata.\n#> Warning: rnaseq dataset: 1 sample IDs not in 'mo_data', will be removed from\n#> samples metadata.\n#> Warning: metabolome dataset: 5 sample IDs not in 'mo_data', will be removed\n#> from samples metadata.\n\nmo_set_new_samples_info |>\n  get_samples_metadata() |>\n  map(head)\n#> $snps\n#>          id feedlot gender  status day_on_feed rnaseq_batch geno_comp_1\n#> R21     R21      F1 female Control          31           B2    0.007853\n#> Y3660 Y3660      F1   male Control          19           B2    0.852220\n#> Y3243 Y3243      F1   male Control          16           B2    0.044171\n#> R5764 R5764      F2   male Control          46           B1    0.213094\n#> P4669 P4669      F3   male     BRD          35           B2    0.389393\n#> R5452 R5452      F2   male Control          49           B1    0.265998\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster new_group\n#> R21      0.820691    0.171456                K3         c\n#> Y3660    0.093585    0.054195                K2         b\n#> Y3243    0.190262    0.765567                K1         b\n#> R5764    0.676299    0.110607                K3         c\n#> P4669    0.503471    0.107136                K3         a\n#> R5452    0.733992    0.000010                K3         c\n#> \n#> $rnaseq\n#>          id feedlot gender status day_on_feed rnaseq_batch geno_comp_1\n#> R9497 R9497      F2   male    BRD          35           B1    0.153716\n#> R5969 R5969      F2   male    BRD          24           B1    0.110663\n#> R5327 R5327      F2   male    BRD          38           B1    0.140730\n#> R5979 R5979      F2   male    BRD          30           B1    0.286733\n#> R9504 R9504      F2   male    BRD          31           B1    0.000010\n#> R5994 R5994      F2   male    BRD          24           B1    0.129271\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster new_group\n#> R9497    0.744505    0.101779                K3         b\n#> R5969    0.625823    0.263514                K3         c\n#> R5327    0.809396    0.049874                K3         b\n#> R5979    0.107794    0.605473                K1         a\n#> R9504    0.998913    0.001077                K3         b\n#> R5994    0.034351    0.836377                K1         a\n#> \n#> $metabolome\n#>          id feedlot gender  status day_on_feed rnaseq_batch geno_comp_1\n#> R21     R21      F1 female Control          31           B2    0.007853\n#> Y3660 Y3660      F1   male Control          19           B2    0.852220\n#> Y3243 Y3243      F1   male Control          16           B2    0.044171\n#> R5764 R5764      F2   male Control          46           B1    0.213094\n#> P4669 P4669      F3   male     BRD          35           B2    0.389393\n#> R5452 R5452      F2   male Control          49           B1    0.265998\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster new_group\n#> R21      0.820691    0.171456                K3         c\n#> Y3660    0.093585    0.054195                K2         b\n#> Y3243    0.190262    0.765567                K1         b\n#> R5764    0.676299    0.110607                K3         c\n#> P4669    0.503471    0.107136                K3         a\n#> R5452    0.733992    0.000010                K3         c\n\nHowever, it is also possible to specify for which dataset(s) the changes should be made, by passing their name to the datasets argument.\n\nmo_set_new_samples_info <- add_samples_metadata(\n  mo_set, \n  new_samples_df, \n  datasets = c(\"rnaseq\", \"metabolome\")\n)\n#> Warning: rnaseq dataset: 1 sample IDs not in 'mo_data', will be removed from\n#> samples metadata.\n#> Warning: metabolome dataset: 5 sample IDs not in 'mo_data', will be removed\n#> from samples metadata.\n\nmo_set_new_samples_info |>\n  get_samples_metadata() |>\n  map(head)\n#> $snps\n#>          id feedlot gender  status day_on_feed rnaseq_batch geno_comp_1\n#> R21     R21      F1 female Control          31           B2    0.007853\n#> Y3660 Y3660      F1   male Control          19           B2    0.852220\n#> Y3243 Y3243      F1   male Control          16           B2    0.044171\n#> R5764 R5764      F2   male Control          46           B1    0.213094\n#> P4669 P4669      F3   male     BRD          35           B2    0.389393\n#> R5452 R5452      F2   male Control          49           B1    0.265998\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster\n#> R21      0.820691    0.171456                K3\n#> Y3660    0.093585    0.054195                K2\n#> Y3243    0.190262    0.765567                K1\n#> R5764    0.676299    0.110607                K3\n#> P4669    0.503471    0.107136                K3\n#> R5452    0.733992    0.000010                K3\n#> \n#> $rnaseq\n#>          id feedlot gender status day_on_feed rnaseq_batch geno_comp_1\n#> R9497 R9497      F2   male    BRD          35           B1    0.153716\n#> R5969 R5969      F2   male    BRD          24           B1    0.110663\n#> R5327 R5327      F2   male    BRD          38           B1    0.140730\n#> R5979 R5979      F2   male    BRD          30           B1    0.286733\n#> R9504 R9504      F2   male    BRD          31           B1    0.000010\n#> R5994 R5994      F2   male    BRD          24           B1    0.129271\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster new_group\n#> R9497    0.744505    0.101779                K3         b\n#> R5969    0.625823    0.263514                K3         c\n#> R5327    0.809396    0.049874                K3         b\n#> R5979    0.107794    0.605473                K1         a\n#> R9504    0.998913    0.001077                K3         b\n#> R5994    0.034351    0.836377                K1         a\n#> \n#> $metabolome\n#>          id feedlot gender  status day_on_feed rnaseq_batch geno_comp_1\n#> R21     R21      F1 female Control          31           B2    0.007853\n#> Y3660 Y3660      F1   male Control          19           B2    0.852220\n#> Y3243 Y3243      F1   male Control          16           B2    0.044171\n#> R5764 R5764      F2   male Control          46           B1    0.213094\n#> P4669 P4669      F3   male     BRD          35           B2    0.389393\n#> R5452 R5452      F2   male Control          49           B1    0.265998\n#>       geno_comp_2 geno_comp_3 geno_comp_cluster new_group\n#> R21      0.820691    0.171456                K3         c\n#> Y3660    0.093585    0.054195                K2         b\n#> Y3243    0.190262    0.765567                K1         b\n#> R5764    0.676299    0.110607                K3         c\n#> P4669    0.503471    0.107136                K3         a\n#> R5452    0.733992    0.000010                K3         c\n\nIn both cases, the function throws some warnings to alert about samples missing from this new table, or samples that are not present in the original samples metadata table. These warnings should be checked to avoid issues due to typos, etc.\nAs with the add_features_metadata() function, it is possible to add information about only a subset of the samples; however the columns in the new data-frame must not already be present in the features metadata tables to which it will be added."
  },
  {
    "objectID": "modifying_multidataset.html#recap-targets-list",
    "href": "modifying_multidataset.html#recap-targets-list",
    "title": "5  Modifying the MultiDataSet object",
    "section": "\n5.4 Recap – targets list",
    "text": "5.4 Recap – targets list\nFor convenience, here is the list of targets that we created in this section:\n\nTargets list for modifying a MultiDataSet object\n\n\nlist(\n  ## RNAseq differential expression results file\n  tar_target(\n    rnaseq_de_res_file,\n    system.file(\n      \"extdata/transcriptomics_de_results.csv\",\n      package = \"moiraine\"\n    ),\n    format = \"file\"\n  ),\n\n  ## Reading the RNAseq differential expression results\n  tar_target(\n    rnaseq_de_res_df,\n    read_csv(rnaseq_de_res_file) |>\n      rename(feature_id = gene_id) |>\n      mutate(dataset = \"rnaseq\")\n  ),\n\n  ## Adding the differential expression results to the MultiDataSet object\n  tar_target(\n    mo_set_de,\n    add_features_metadata(mo_set, rnaseq_de_res_df)\n  )\n)"
  },
  {
    "objectID": "preprocessing.html#datasets-transformations",
    "href": "preprocessing.html#datasets-transformations",
    "title": "6  Data pre-processing",
    "section": "\n6.1 Datasets transformations",
    "text": "6.1 Datasets transformations\nAfter inspection of the density plots for the different datasets (see Section 4.3), it might be necessary to normalise or transform some or all datasets. This is necessary to mitigate the mean-variance trend that occurs in RNAseq data, for example, or simply to bring the different features to a comparable scale. Transformation here refers to applying a function to each feature (i.e. each row) within a dataset that will transform the measurement values for the feature.\nmoiraine implements several options to transform an omics dataset:\n\nVariance Stabilising Normalisation (VSN) through the vsn package – recommended for metabolomics datasets or other continuous datasets with a strong mean-variance trend;\nVariance Stabilising Transformation (VST) through the DESeq2 package – recommended for RNAseq data or any raw read count-type data;\nAutomatic selection of the best normalisation method for each feature through the bestNormalize package – recommended for phenotype data, and when the number of features is small (note that the selection of the normalisation method is done independently for each feature, so the same transformation might not be applied to all features);\nA selection of common normalisation methods through the bestNormalize package, including center/scale, log, exponential, square-root, arcsinh, Box Cox, Yeo-Johnson and ordered quantile transformations (see details in the bestNormalize vignette) – recommended when applying the same transformation to all features, e.g. log2 transformation or centering.\n\n\n6.1.1 Transforming a single dataset\nThe transformation of one dataset is done through the transform_dataset() function, which takes as input a MultiDataSet object, the name of the dataset to transform, and the name of the transformation to be applied, which should be one of vsn, vst-deseq2, logx, best-normalize-auto or best-normalize-manual. For the latter, the name of the normalisation method from the BestNormalize package to use must also be supplied through the method argument.\nThe return_multidataset argument determines whether a MultiDataSet object with the corresponding dataset transformed should be returned. If it is set to FALSE, the function will instead return a list with the transformed dataset as a matrix as well as other useful information returned by the transformation function applied. It is possible to only return the transformed matrix, by setting return_matrix_only to TRUE. This can be useful to quickly assess the effects of the transformation outside of the analysis pipeline.\nFor example, we can apply the Variance Stabilising Transformation to the transcriptomics dataset:\n\ntar_load(mo_set_de)\n\nrnaseq_vst <- transform_dataset(\n  mo_set_de,\n  \"rnaseq\",\n  \"vst-deseq2\",\n  return_multidataset = FALSE\n)\n#> Applying Variance Stabilising Transformation (DESeq2) to rnaseq dataset.\n#> converting counts to integer mode\n\nThe function returns a list, with the transformed dataset as matrix in the transformed_data element. Information generated during the transformation by the DESeq2 package is stored in the info_transformation element. The name of the transformation applied is stored in the transformation element:\n\nnames(rnaseq_vst)\n#> [1] \"transformed_data\"    \"info_transformation\" \"transformation\"\n\nrnaseq_vst$transformed_data[1:5, 1:5]\n#>                        R9497     R5969     R5327     R5979     R9504\n#> ENSBTAG00000000005 10.357314 11.289047 12.070536 10.201227 10.251942\n#> ENSBTAG00000000008  4.836495  4.937948  4.375764  4.986154  5.710581\n#> ENSBTAG00000000009  3.486141  4.054636  4.983434  3.486141  3.486141\n#> ENSBTAG00000000010 12.216690 11.937084 12.079359 11.383360 11.897780\n#> ENSBTAG00000000011  3.486141  4.054636  4.005139  3.979732  3.486141\n\nrnaseq_vst$info_transformation\n#> class: DESeqTransform \n#> dim: 20335 143 \n#> metadata(1): version\n#> assays(1): ''\n#> rownames(20335): ENSBTAG00000000005 ENSBTAG00000000008 ...\n#>   ENSBTAG00000055312 ENSBTAG00000055314\n#> rowData names(6): baseMean baseVar ... dispGeneIter dispFit\n#> colnames(143): R9497 R5969 ... Y9747 Y9816\n#> colData names(1): sizeFactor\n\nrnaseq_vst$transformation\n#> [1] \"vst-deseq2\"\n\nIf we instead want to apply a log2 transformation to the dataset, we will use the logx transformation option. In that case, we have to specify the log base to use (here 2) through the log_base argument, as well as the function that should be applied to the matrix prior to the log-transformation through the pre_log_function argument. This function is here mostly to take care of zero values that could cause an issue during the log transformation. By default, the zero_to_half_min() function is used, which replaces zero values in the dataset with half of the minimum non-null value found in the dataset. However, it is possible to pass any custom function instead, for example function(x) x would not make any change to the dataset before the log-transformation:\n\nrnaseq_log2 <- transform_dataset(\n  mo_set_de,\n  \"rnaseq\",\n  \"logx\",\n  base_log = 2,\n  pre_log_function = function(x) x,\n  return_multidataset = TRUE\n)\n#> Applying Log Transformation to rnaseq dataset.\n#> Warning in transform_logx(mat, return_matrix_only = return_matrix_only, : The\n#> matrix contains zero values; log-transformation will yield `-Inf`.\n\nIn that case, we asked the function to return a MultiDataSet object, in which the rnaseq dataset has been transformed:\n\nrnaseq_log2\n#> Object of class 'MultiDataSet'\n#>  . assayData: 3 elements\n#>     . snps: 23036 features, 139 samples \n#>     . rnaseq: 20335 features, 143 samples \n#>     . metabolome: 55 features, 139 samples \n#>  . featureData:\n#>     . snps: 23036 rows, 13 cols (feature_id, ..., p_value)\n#>     . rnaseq: 20335 rows, 15 cols (feature_id, ..., de_signif)\n#>     . metabolome: 55 rows, 16 cols (feature_id, ..., de_signif)\n#>  . rowRanges:\n#>     . snps: YES\n#>     . rnaseq: YES\n#>     . metabolome: NO\n#>  . phenoData:\n#>     . snps: 139 samples, 10 cols (id, ..., geno_comp_3)\n#>     . rnaseq: 143 samples, 10 cols (id, ..., geno_comp_3)\n#>     . metabolome: 139 samples, 10 cols (id, ..., geno_comp_3)\n\nget_dataset_matrix(rnaseq_log2, \"rnaseq\")[1:5, 1:5]\n#>                        R9497     R5969     R5327     R5979     R9504\n#> ENSBTAG00000000005  9.517669 10.458407 11.511258  9.768184  9.531381\n#> ENSBTAG00000000008  2.584963  2.807355  1.584963  3.321928  4.321928\n#> ENSBTAG00000000009      -Inf  0.000000  3.169925      -Inf      -Inf\n#> ENSBTAG00000000010 11.394999 11.111136 11.520128 10.965784 11.195372\n#> ENSBTAG00000000011      -Inf  0.000000  0.000000  0.000000      -Inf\n\nThe two other transformation options are best-normalize-auto and best-normalize-manual. Both rely on the bestNormalize package to apply a transformation independently to each feature in the dataset. With best-normalize-auto, the bestNormalize::bestNormalize() function automatically selects for each feature the transformation that results in a distribution of values closest to Gaussian as possible. Note that as the function is applied independently to each feature, a different distribution may be chosen for different features. With the best-normalize-manual option, the same transformation is applied to each feature. The transformation to use must be specified through the method argument, and should be the name of one of the transformation implemented in bestNormalize: \"arcsinh_x\", \"boxcox\", \"center_scale\", \"exp_x\", \"log_x\", \"orderNorm\", \"sqrt_x\" or \"yeojohnson\". Note that with this option, even if the same transformation is applied to each feature, the parameters for the transformation, if not specified, will be independently estimated for each feature. For example, with the log_x method, the function automatically adds a small offset (a) to the feature’s measurements if there are any zero values. The value used for this offset might be different for each feature. We can instead set a value for a to be used for all features, as follows:\n\ntransform_dataset(\n  mo_set_de,\n  \"rnaseq\",\n  \"best-normalize-manual\",\n  method = \"log_x\",\n  a = 0.1,\n  return_multidataset = TRUE\n)\n\n\n\n\n\n\n\nNote\n\n\n\nBefore using the best-normalize-manual option, it is strongly recommended to have a look at the documentation of the corresponding function from the bestNormalize package, as they might have behaviours that are not expected. For example, by default the bestNormalize::log_x() function uses a log base 10, and centers and scales the transformed values, which not be what we want.\n\n\n\n6.1.2 Transformation target factory\nThe target factory function transformation_datasets_factory() provides a wrapper to apply (potentially different) transformations to several datasets at once. The function takes as input the MultiDataSet object as well as a named character vector, in which each element corresponds to a transformation that should be applied to a specific dataset. If a dataset is not present in the transformation vector, it will not be transformed (but it will still be present in the resulting MultiDataSet object).\nHere, we would like to apply Variance Stabilising Transformation to the transcriptomics dataset, and a log2 transformation to the metabolomics dataset. Note that the VST and VSN transformations are very close to the log2 transformation, especially for features with high means.\n\n\ntransformation_datasets_factory(\n  mo_set_de,\n  c(\"rnaseq\" = \"vst-deseq2\",\n    \"metabolome\" = \"logx\"),\n  log_bases = 2,\n  pre_log_functions = zero_to_half_min,\n  transformed_data_name = \"mo_set_transformed\"\n)\n\n\nThe transformation_datasets_factory() function works as follows:\n\nIt creates a grouped tibble listing the transformation to apply to each dataset, stored in the transformations_spec target;\n\n\ntar_read(transformations_spec)\n#> # A tibble: 2 × 6\n#>   dsn        transf     meth   log_b     prelog_f tar_group\n#>   <chr>      <chr>      <list> <list>    <list>       <int>\n#> 1 rnaseq     vst-deseq2 <NULL> <NULL>    <NULL>           2\n#> 2 metabolome logx       <NULL> <dbl [1]> <fn>             1\n\n\nIt performs the required transformation on each dataset via dynamic branching. This is done through a call to the transform_dataset() function. The transformed datasets are stored in a list, in the transformations_runs_list target. Note that by default the function will store all details of the transformations, which can be useful for later inspection, but can be memory-intensive. It is possible to only store the transformed datasets instead, by setting the return_matrix_only argument to TRUE in the transformation_datasets_factory() call.\n\n\ntar_load(transformations_runs_list)\n\nnames(transformations_runs_list)\n#> [1] \"transformations_runs_list_e68c2d99\" \"transformations_runs_list_46986372\"\n\nmap_chr(transformations_runs_list, attr, \"dataset_name\")\n#> transformations_runs_list_e68c2d99 transformations_runs_list_46986372 \n#>                       \"metabolome\"                           \"rnaseq\"\n\ntransformations_runs_list[[\"transformations_runs_list_a1c8db41\"]] |> names()\n#> NULL\n\n\nIt creates a new MultiDataSet object, with the transformed version of the datasets. By default, this new MultiDataSet object is stored in a target called transformed_set, but a different name can be specified via the transformed_data_name argument (here we called it mo_set_transformed).\n\n\ntar_load(mo_set_transformed)\n\nmo_set_transformed\n#> Object of class 'MultiDataSet'\n#>  . assayData: 3 elements\n#>     . snps: 23036 features, 139 samples \n#>     . rnaseq: 20335 features, 143 samples \n#>     . metabolome: 55 features, 139 samples \n#>  . featureData:\n#>     . snps: 23036 rows, 13 cols (feature_id, ..., p_value)\n#>     . rnaseq: 20335 rows, 15 cols (feature_id, ..., de_signif)\n#>     . metabolome: 55 rows, 16 cols (feature_id, ..., de_signif)\n#>  . rowRanges:\n#>     . snps: YES\n#>     . rnaseq: YES\n#>     . metabolome: NO\n#>  . phenoData:\n#>     . snps: 139 samples, 10 cols (id, ..., geno_comp_3)\n#>     . rnaseq: 143 samples, 10 cols (id, ..., geno_comp_3)\n#>     . metabolome: 139 samples, 10 cols (id, ..., geno_comp_3)\n\nget_dataset_matrix(mo_set_de, \"metabolome\")[1:5, 1:3]\n#>             R21 Y3660 Y3243\n#> HMDB00001   9.1   9.7   9.3\n#> HMDB00008  58.2  22.8   9.1\n#> HMDB00042 403.0 392.0 606.0\n#> HMDB00043 172.6 163.1 165.2\n#> HMDB00060   0.7   1.5   1.4\n\nget_dataset_matrix(mo_set_de, \"metabolome\")[1:5, 1:3]\n#>             R21 Y3660 Y3243\n#> HMDB00001   9.1   9.7   9.3\n#> HMDB00008  58.2  22.8   9.1\n#> HMDB00042 403.0 392.0 606.0\n#> HMDB00043 172.6 163.1 165.2\n#> HMDB00060   0.7   1.5   1.4\n\n\nConverting targets factory to R script\n\ntransformations_runs_list <- c(\n  \"rnaseq\" = \"vst-deseq2\", \n  \"metabolome\" = \"logx\"\n) |>  imap(\\(x, y) {\n    transform_dataset(\n      mo_set_de,\n      dataset = y,\n      transformation = x,\n      log_base = 2,\n      pre_log_function = zero_to_half_min\n    )\n  }\n)\n\nmo_set_transformed <- get_transformed_data(mo_set_de, transformations_runs_list)\n\nWe can assess the effect of the transformations by generating density and mean-sd plots for the transformed datasets:\n\nplot_density_data(\n  mo_set_transformed,\n  combined = FALSE,\n  scales = \"free\"\n)\n\n\n\n\nNote how the relationship between features mean and standard deviation has been reduced in both transformed datasets:\n\nplot_meansd_data(mo_set_transformed)\n\n\n\n\nFinally, it can be useful to summarise which transformations have been applied to the datasets, for example when creating a report. The function get_table_transformation() is here for that. It takes as an input the transformations_runs_list target generated by transformation_datasets_factory(), and returns a tibble indicating the transformation applied to each dataset:\n\nget_table_transformations(transformations_runs_list)\n#> # A tibble: 2 × 2\n#>   Dataset    Transformation                              \n#>   <chr>      <chr>                                       \n#> 1 metabolome Log-2 transformation                        \n#> 2 rnaseq     Variance Stabilising Transformation (DESeq2)"
  },
  {
    "objectID": "preprocessing.html#running-a-pca-on-each-dataset",
    "href": "preprocessing.html#running-a-pca-on-each-dataset",
    "title": "6  Data pre-processing",
    "section": "\n6.2 Running a PCA on each dataset",
    "text": "6.2 Running a PCA on each dataset\nIt is always best practice to run some exploratory analysis on a dataset prior to running analyses. This is largely outside the scope of this package, and we assume that any input dataset has been properly assessed before turning to the integration pipeline. However, running a Principal Component Analysis (PCA) on each of the omics datasets within the integration pipeline serves two purposes:\n\nas a last check to ensure that there are no obvious batch effects or problematic samples that should be addressed,\nas a missing data imputation method.\n\nThe moiraine package relies on the Bioconductor pcaMethods package to perform the PCA. In particular, the pcaMethods package implements a NIPALS (non-linear iterative partial least squares) method for PCA, which allows for missing values in the input dataset, and imputes missing values based on the results of the PCA.\n\n6.2.1 Running the PCAs\nThe pca_complete_data_factory() function uses dynamic branching to perform a PCA on each omics dataset within a MultiDataSet object. It takes as input the MultiDataSet object (in our case, mo_set_transformed), and, optionally, the names of the datasets on which a PCA should be run. This is useful if one dataset is very large and has no missing values, and we want to avoid running a PCA on it. It then proceeds as follows:\n\nIt creates a target called dataset_names_pca, which stores a vector of dataset names on which a PCA should be applied;\nFor each value in dataset_names_pca, it extracts the omics dataset as a matrix with features as rows and samples as columns, using the get_dataset_matrix() function. This is done via dynamic branching, and the results are stored as a list in the pca_mats_list target. Note that the names of this list are not meaningful; to check which element of the list corresponds to which dataset, you can run map_chr(pca_mats_list, attr, \"dataset_name\");\nFor each matrix in pca_mats_list, it applies the run_pca_matrix() function to the corresponding dataset. This is done via dynamic branching; it results in a list where each element is the PCA result (i.e. a pcaMethods::pcaRes object) for a given dataset. This list is stored in the pca_runs_list target. Note that the names of this list are not meaningful; to check which element of the list corresponds to which dataset, you can run map_chr(pca_runs_list, attr, \"dataset_name\");\nIt extracts from the result of each PCA the complete dataset, i.e. with missing values imputed, and uses this information to construct a new MultiDataSet object, in which the datasets are complete (i.e. no missing value). This is done by calling the get_complete_data() function. If no PCA was run on a dataset, the dataset will still be present in the new MultiDataSet object, but its missing values will not be imputed. The resulting complete MultiDataSet object is stored by default in a target called complete_set; this name can be changed via the complete_data_name argument.\n\nLet’s apply this to our multi-omics dataset:\n\n\npca_complete_data_factory(\n  mo_set_transformed,\n  complete_data_name = \"mo_set_complete\"\n)\n\n\nWe can have a look at the different targets constructed. By default, a PCA was run on all datasets:\n\ntar_read(dataset_names_pca)\n#> [1] \"snps\"       \"rnaseq\"     \"metabolome\"\n\n\ntar_load(pca_mats_list)\n\nmap_chr(pca_mats_list, attr, \"dataset_name\")\n#> pca_mats_list_302d7473 pca_mats_list_84d36937 pca_mats_list_64d37e6c \n#>                 \"snps\"               \"rnaseq\"           \"metabolome\"\nmap(pca_mats_list, ~.x[1:5, 1:5])\n#> $pca_mats_list_302d7473\n#>                             R21 Y3660 Y3243 R5764 P4669\n#> 1_41768691                    1     0     2     2     1\n#> 10-27008241-A-C-rs42918694    2     2     2     1     2\n#> 10-37505419-T-C-rs136559242   0     1     0     2     0\n#> 10-49904259-G-A-rs471723345   1     2     2     2     2\n#> 1-109550832-G-A-rs209732846   2     2     1     2     2\n#> \n#> $pca_mats_list_84d36937\n#>                        R9497     R5969     R5327     R5979     R9504\n#> ENSBTAG00000000005 10.357314 11.289047 12.070536 10.201227 10.251942\n#> ENSBTAG00000000008  4.836495  4.937948  4.375764  4.986154  5.710581\n#> ENSBTAG00000000009  3.486141  4.054636  4.983434  3.486141  3.486141\n#> ENSBTAG00000000010 12.216690 11.937084 12.079359 11.383360 11.897780\n#> ENSBTAG00000000011  3.486141  4.054636  4.005139  3.979732  3.486141\n#> \n#> $pca_mats_list_64d37e6c\n#>                  R21     Y3660     Y3243    R5764     P4669\n#> HMDB00001  3.1858665 3.2779847 3.2172307       NA 3.6322682\n#> HMDB00008  5.8629472 4.5109619 3.1858665 2.655352 4.1618877\n#> HMDB00042  8.6546360 8.6147098 9.2431740 8.655352 7.9008668\n#> HMDB00043  7.4312887 7.3496130 7.3680699 7.707359 6.4025858\n#> HMDB00060 -0.5145732 0.5849625 0.4854268 2.906891 0.6780719\n\n\ntar_load(pca_runs_list)\n\nnames(pca_runs_list)\n#> [1] \"pca_runs_list_74d71ae8\" \"pca_runs_list_71fd94b4\" \"pca_runs_list_559272f0\"\n\nmap_chr(pca_runs_list, attr, \"dataset_name\")\n#> pca_runs_list_74d71ae8 pca_runs_list_71fd94b4 pca_runs_list_559272f0 \n#>                 \"snps\"               \"rnaseq\"           \"metabolome\"\n\nThe result of the PCA run on the genomics dataset looks like this:\n\ntar_read(pca_runs_list_74d71ae8)\n#> nipals calculated PCA\n#> Importance of component(s):\n#>                   PC1     PC2     PC3     PC4     PC5     PC6      PC7      PC8\n#> R2            0.05578 0.02881 0.01305 0.01196 0.01168 0.01005 0.009848 0.009565\n#> Cumulative R2 0.05578 0.08459 0.09765 0.10960 0.12128 0.13133 0.141175 0.150739\n#>                    PC9     PC10\n#> R2            0.009286 0.008915\n#> Cumulative R2 0.160026 0.168941\n#> 23036    Variables\n#> 139  Samples\n#> 9615     NAs ( 0.3 %)\n#> 10   Calculated component(s)\n#> Data was mean centered before running PCA \n#> Data was NOT scaled before running PCA \n#> Scores structure:\n#> [1] 139  10\n#> Loadings structure:\n#> [1] 23036    10\n\nYou can notice that there is some information about the number of principal components computed, and whether the dataset was centred and scaled before applying the PCA. This is handled by the default arguments of run_pca_matrix(), but can be specified by passing the corresponding arguments to pca_complete_data_factory(). For example, to scale the datasets before performing a PCA, we could use:\n\n\npca_complete_data_factory(\n  mo_set_transformed,\n  complete_data_name = \"mo_set_complete\",\n  scale = TRUE\n)\n\n\nFor convenience, the run_pca() function can be used to run a PCA on one of the omics datasets directly from a MultiDataSet object. It is a wrapper around the run_pca_matrix() function, and takes as input a MultiDataSet object as well as the name of the omics dataset on which a PCA should be run, e.g.:\n\nrun_pca(mo_set_de, \"rnaseq\")\n\n\nConverting targets factory to R script\n\npca_mats_list <- names(mo_set_transformed) |> \n  set_names() |> \n  map(\\(x) get_dataset_matrix(mo_set_transformed, x, keep_dataset_name = TRUE))\n\npca_runs_list <- pca_mats_list |> \n  map(run_pca_matrix)\n\nmo_set_complete <- get_complete_data(mo_set_transformed, pca_runs_list)\n\n\n6.2.2 Visualising the PCA results\nIt is possible to get an overview of the results of each PCA. First, the function plot_screeplot_pca() displays the percentage of variance explained by the principal components computed for each dataset. It takes as input the pca_runs_list target constructed in the previous step. Note that by default, 10 components are computed for each dataset.\n\nplot_screeplot_pca(pca_runs_list)\n\n\n\n\nIn addition, the plot_samples_coordinates_pca allows us to display the samples in the reduced principal components space (the common PCA sample plot). The function returns a list of plots (one plot per dataset). By default, it shows all principal components computed for each dataset, but for clarity we will only look at the first three:\n\nplot_samples_coordinates_pca(\n  pca_runs_list,\n  pcs = 1:3\n)\n#> $snps\n\n\n\n#> \n#> $rnaseq\n\n\n\n#> \n#> $metabolome\n\n\n\n\nNote that it is possible to look at a different set of principal components for each dataset. For that, the index of the principal components should be passed to the pcs argument as a named list (where the name of each element corresponds to a dataset name), e.g.:\n\nplot_samples_coordinates_pca(\n  pca_runs_list,\n  pcs = list(\n    \"snps\" = 1:4,\n    \"rnaseq\" = 1:2,\n    \"metabolome\" = 1:3\n  )\n)\n\nBy default, the points in the sample plots are not coloured. It is however possible to colour the samples according to the information contained in the sample metadata tables available through the MultiDataset object. We can set different colours and shapes for the upper and lower plots in the scatterplot matrix, see the plot_samples_score() function for more information. For example, we can assess whether the first three principal components show any clustering of the samples according to their cluster computed from genomics similarity, disease status or feedlot (we’ll only show the results for the SNPs dataset here):\n\nplot_samples_coordinates_pca(\n  pca_runs_list,\n  datasets = \"snps\",\n  pcs = 1:3,\n  mo_data = mo_set_de,\n  colour_upper = \"geno_comp_cluster\",\n  shape_upper = \"status\",\n  colour_lower = \"feedlot\"\n) +\n  theme(legend.box = \"vertical\")\n\n\n\n\n\n6.2.3 Missing values imputation\nWe can check that the complete multi-omics set constructed has no more missing values:\n\ntar_load(mo_set_complete)\n\nmo_set_complete\n#> Object of class 'MultiDataSet'\n#>  . assayData: 3 elements\n#>     . snps: 23036 features, 139 samples \n#>     . rnaseq: 20335 features, 143 samples \n#>     . metabolome: 55 features, 139 samples \n#>  . featureData:\n#>     . snps: 23036 rows, 13 cols (feature_id, ..., p_value)\n#>     . rnaseq: 20335 rows, 15 cols (feature_id, ..., de_signif)\n#>     . metabolome: 55 rows, 16 cols (feature_id, ..., de_signif)\n#>  . rowRanges:\n#>     . snps: YES\n#>     . rnaseq: YES\n#>     . metabolome: NO\n#>  . phenoData:\n#>     . snps: 139 samples, 10 cols (id, ..., geno_comp_3)\n#>     . rnaseq: 143 samples, 10 cols (id, ..., geno_comp_3)\n#>     . metabolome: 139 samples, 10 cols (id, ..., geno_comp_3)\n\n\ncheck_missing_values(mo_set_complete)\n#> No missing values in snps dataset.\n#> No missing values in rnaseq dataset.\n#> No missing values in metabolome dataset."
  },
  {
    "objectID": "preprocessing.html#recap-targets-list",
    "href": "preprocessing.html#recap-targets-list",
    "title": "6  Data pre-processing",
    "section": "\n6.3 Recap – targets list",
    "text": "6.3 Recap – targets list\nFor convenience, here is the list of targets that we created in this section:\n\nTargets list for datasets preprocessing\n\n\nlist(\n  ## Applying transformations to the datasets\n  transformation_datasets_factory(\n    mo_set_de,\n    c(\"rnaseq\" = \"vst-deseq2\",\n      \"metabolome\" = \"logx\"),\n    log_bases = 2,\n    pre_log_functions = zero_to_half_min,\n    transformed_data_name = \"mo_set_transformed\"\n  ),\n  \n  ## Density plot for each transformed dataset\n  tar_target(\n    density_plots_transformed,\n    plot_density_data(\n      mo_set_transformed,\n      combined = FALSE,\n      scales = \"free\"\n    )\n  ),\n  \n  ## Plotting the mean-SD trend for transformed each dataset\n  tar_target(\n    mean_sd_plots_transformed,\n    plot_meansd_data(mo_set_transformed)\n  ),\n  \n  ## Summary table of the transformations applied\n  tar_target(\n    transformation_summary,\n    get_table_transformations(transformations_runs_list)\n  ),\n  \n  ## Running a PCA on each dataset\n  pca_complete_data_factory(\n    mo_set_transformed,\n    complete_data_name = \"mo_set_complete\"\n  ),\n  \n  ## PCA screeplots\n  tar_target(\n    pca_screeplots,\n    plot_screeplot_pca(pca_runs_list)\n  ),\n  \n  ## PCA sample plots\n  tar_target(\n    pca_sample_plots,\n    plot_samples_coordinates_pca(\n      pca_runs_list,\n      datasets = \"snps\",\n      pcs = 1:3,\n      mo_data = mo_set_de,\n      colour_upper = \"geno_comp_cluster\",\n      shape_upper = \"status\",\n      colour_lower = \"feedlot\"\n    )\n  )\n)"
  },
  {
    "objectID": "prefiltering.html#subsetting-samples-of-interest",
    "href": "prefiltering.html#subsetting-samples-of-interest",
    "title": "7  Dataset pre-filtering",
    "section": "\n7.1 Subsetting samples of interest",
    "text": "7.1 Subsetting samples of interest\nIt is possible that for the integration analysis, we might want to retain only a subset of samples of interest; for example to focus on a specific phenotypic group. In this section, we will see a number of ways to subset samples of interest from a MultiDataSet object.\n\n7.1.1 Based on sample IDs\nThe MultiDataSet package allows to subset a MultiDataSet object based on a vector of sample IDs. For example, here we generate a list of 10 samples to which we would like to restrict the MultiDataSet object:\n\n## Randomly selecting 10 samples\nset.seed(47)\nsamples_list <- get_samples(mo_set_complete) |>\n  unlist() |>\n  unname() |>\n  unique() |>\n  sample(10, replace = FALSE)\n\nhead(samples_list)\n#> [1] \"U5523\" \"R8953\" \"R21\"   \"G3594\" \"R107\"  \"O5245\"\n\nWe can restrict the MultiDataSet object to only these samples as follows:\n\nmo_samples_filtered <- mo_set_complete[samples_list, ]\n\nn_samples(mo_samples_filtered)\n#>       snps     rnaseq metabolome \n#>          9         10         10\n\nThe MultiDataSet object returned only contains the 10 samples of interest. One of the selected samples was not present in the genomics dataset, which is why this dataset has only 9 samples.\n\n7.1.2 Based on metadata\nAlternatively, we might want to select samples based on some information contained in the samples metadata associated with the omics datasets. Again, this option is implemented in the MultiDataSet package through the subset() function (see their vignette for more information). For this example, we want to retain only animals from feedlot 1. This information is encoded in the feedlot column from the samples metadata of the datasets:\n\nget_samples_metadata_combined(mo_set_complete) |> str()\n#> 'data.frame':    144 obs. of  10 variables:\n#>  $ id               : chr  \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n#>  $ feedlot          : chr  \"F1\" \"F1\" \"F1\" \"F2\" ...\n#>  $ gender           : chr  \"female\" \"male\" \"male\" \"male\" ...\n#>  $ status           : chr  \"Control\" \"Control\" \"Control\" \"Control\" ...\n#>  $ day_on_feed      : num  31 19 16 46 35 49 21 16 37 37 ...\n#>  $ rnaseq_batch     : chr  \"B2\" \"B2\" \"B2\" \"B1\" ...\n#>  $ geno_comp_1      : num  0.00785 0.85222 0.04417 0.21309 0.38939 ...\n#>  $ geno_comp_2      : num  0.8207 0.0936 0.1903 0.6763 0.5035 ...\n#>  $ geno_comp_3      : num  0.1715 0.0542 0.7656 0.1106 0.1071 ...\n#>  $ geno_comp_cluster: chr  \"K3\" \"K2\" \"K1\" \"K3\" ...\n\nIn the subset function, the first argument is the MultiDataSet object to subset, the second argument slot is for subsetting features based on their metadata (which we will see in the next section), and the third slot is for samples subsetting. We perform the subsetting by passing an expression, similar to what we would use with the dplyr::filter() function, i.e. we treat the column name on which to perform the subsetting as a variable name.\n\nmo_samples_filtered <- subset(mo_set_complete, , feedlot == \"F1\")\n\nn_samples(mo_samples_filtered)\n#>       snps     rnaseq metabolome \n#>         22         23         23\n\nThe MultiDataSet object returned contains only samples corresponding to animals from feedlot 1.\n\n7.1.3 Retaining common samples\nMost data integration tools only accept samples that are present in all omics datasets. When that is the case, the moiraine package will automatically remove samples that are absent from some datasets when preparing the input data for the corresponding integration tool. However, for convenience, we show here how to restrict a MultiDataSet object to only samples that are common to all datasets.\nThis is done through the commonSamples() function from the MultiDataSet package, which returns a filtered MultiDataSet object:\n\nmo_samples_filtered <- commonSamples(mo_set_complete)\n\nn_samples(mo_samples_filtered)\n#>       snps     rnaseq metabolome \n#>        135        135        135\n\nThe returned MultiDataSet object contains 135 samples which are present in all three omics datasets (which we can confirm with the Upset plot generated in Section 4.3)."
  },
  {
    "objectID": "prefiltering.html#subsetting-features-of-interest",
    "href": "prefiltering.html#subsetting-features-of-interest",
    "title": "7  Dataset pre-filtering",
    "section": "\n7.2 Subsetting features of interest",
    "text": "7.2 Subsetting features of interest\n\n7.2.1 Based on feature IDs\nAs with samples, we might want to filter a MultiDataSet object to only specific features of interest. We will randomly select feature IDs from each omics dataset:\n\nset.seed(36)\nfeatures_list <- get_features(mo_set_complete) |>\n  map(\\(x) sample(x, size = 5, replace = FALSE))\n\nstr(features_list)\n#> List of 3\n#>  $ snps      : chr [1:5] \"BovineHD0600012019\" \"BovineHD1200015003\" \"BTB-01046082\" \"BovineHD2600010539\" ...\n#>  $ rnaseq    : chr [1:5] \"ENSBTAG00000002154\" \"ENSBTAG00000009915\" \"ENSBTAG00000052111\" \"ENSBTAG00000012274\" ...\n#>  $ metabolome: chr [1:5] \"HMDB00201\" \"HMDB00641\" \"HMDB00123\" \"HMDB00294\" ...\n\nThe subset() method implemented in the MultiDataSet package can be used to restrict the omics datasets to specific features based on a list of IDs. However, this only works by directly passing the features ID in the command, as follows:\n\nmo_features_filtered <- subset(\n  mo_set_complete, \n  feature_id %in% c(\"BovineHD0600012019\", \"ENSBTAG00000002154\")\n)\n\nn_features(mo_features_filtered)\n#>       snps     rnaseq metabolome \n#>          1          1          0\n\nWhile passing a vector of feature IDs doesn’t work:\n\nfeatures_vec <- c(\"BovineHD0600012019\", \"ENSBTAG00000002154\")\nsubset(mo_set_complete, feature_id %in% features_vec)\n#> Error in .local(x, ...): feat expression could not be applied to any of the sets.\n\nThis type of subsetting is made possible with the subset_features() function in moiraine:\n\nmo_features_filtered <- subset_features(mo_set_complete, features_vec)\n\nn_features(mo_features_filtered)\n#>       snps     rnaseq metabolome \n#>          1          1          0\n\nThe subset_features() function accepts the features ID either as a vector, or as a list of vectors (typically one per dataset):\n\nmo_features_filtered <- subset_features(mo_set_complete, features_list)\nn_features(mo_features_filtered)\n#>       snps     rnaseq metabolome \n#>          5          5          5\n\n## Getting the selected IDs as a vector\nfeatures_vec <- features_list |>\n  unlist() |>\n  unname()\n\nhead(features_vec)\n#> [1] \"BovineHD0600012019\" \"BovineHD1200015003\" \"BTB-01046082\"      \n#> [4] \"BovineHD2600010539\" \"BovineHD2600008282\" \"ENSBTAG00000002154\"\n\nmo_features_filtered <- subset_features(mo_set_complete, features_vec)\nn_features(mo_features_filtered)\n#>       snps     rnaseq metabolome \n#>          5          5          5\n\n\n7.2.2 Based on metadata\nIt is also possible to subset features based on their metadata. For that, we can use the subset() function from the MultiDataSet package, as we did for samples subsetting. For example, for the transcriptomics and metabolomics dataset, we have in the features metadata a column (de_signif) that recaps the results of a differential abundance analysis on the corresponding dataset. We could decide to select only the differentially abundant compounds from this dataset. Note that it only performs the filtering for datasets that have this column in their features metadata.\n\nmo_features_filtered <- subset(mo_set_complete, de_signif == \"DE\")\n#> Warning in .local(x, ...): The following sets could not be filtered by feature\n#> id: snps\n\nn_features(mo_features_filtered)\n#>       snps     rnaseq metabolome \n#>      23036        111         30"
  },
  {
    "objectID": "prefiltering.html#features-preselection",
    "href": "prefiltering.html#features-preselection",
    "title": "7  Dataset pre-filtering",
    "section": "\n7.3 Features preselection",
    "text": "7.3 Features preselection\nIn the previous section, we saw how to restrict the MultiDataSet object to a set of features of interest. However, in a typical integration workflow, we instead want to reduce the dimensions of the omics datasets through a data-centric method that discards features least relevant to the biological problem of interest. Here, we present two approaches for features preselection: an unsupervised approach, which relies only on the omics measurements, and a supervised approach, which accounts for information we have about the samples. The choice between these two approaches will depend on the research question being investigated. Note that this preselection step is distinct from the data cleaning process that should be applied to each omics dataset, in which features with low expression or high missing values are removed. This ideally should be done before the multi-omics integration workflow constructed with moiraine, although it can be integrated in the analysis pipeline.\n\n7.3.1 Unsupervised features preselection\nIn order to reduce the number of features in the omics datasets, one option is to only retain the most variable features from each dataset. We refer to this approach as unsupervised preselection, as it only relies on the omics measurements to discard irrelevant features. In the package, two metrics of feature variability are implemented: the coefficient of variation (COV), and the Median Absolute Deviation (MAD). Careful consideration is required when determining which of these metrics should be used to select the most variable features, as each has some drawbacks. In particular:\n\nFiltering based on COV will retain features that are only present in very few samples. This might be problematic for noisy datasets in which some features are technical artefacts, or if we are looking for biomarkers that are expressed across all observations.\nFiltering based on MAD will discard any feature that is absent in more than half of the observations. This might be problematic if for example we are comparing two groups with unbalanced size, and we are looking for group-specific biomarkers.\n\nTherefore, a first step of data cleaning to remove artefact features, as well as consideration of the biological research question, is needed before proceeding.\nThe feature_preselection_cov_factory() and feature_preselection_mad_factory() functions allow us to perform unsupervised COV- or MAD-based preselection for some or all datasets within a MultiDataSet object. It provides two options to set the desired size of the filtered datasets: we can either specify the number of features to retain in each dataset (via the to_keep_ns argument), or the proportion of features that should be kept in each dataset (via the to_keep_props argument). For example, let’s say that we want to retain 1,000 features with the highest MAD score in both the genomics and transcriptomics datasets (as the metabolomics dataset contains only 55 compounds, no preselection will be applied to it):\n\n\nfeature_preselection_mad_factory(\n  mo_set_complete,\n  to_keep_ns = c(\"snps\" = 1000, \"rnaseq\" = 1000),\n  with_ties = TRUE,\n  filtered_set_target_name = \"mo_presel_unsupervised\"\n)\n\n\nThe feature_preselection_mad_factory works as follows:\n\nit creates a grouped tibble in which each row is one of the datasets to be filtered, with the number or proportion of features to retain. It is stored in the mad_spec target:\n\n\ntar_read(mad_spec)\n#> # A tibble: 2 × 4\n#>   dsn      tkn wt    tar_group\n#>   <chr>  <dbl> <lgl>     <int>\n#> 1 snps    1000 TRUE          2\n#> 2 rnaseq  1000 TRUE          1\n\n\nit uses dynamic branching over the grouped tibble to extract each omics dataset as a matrix via the get_dataset_matrix() function. The result of this target, called mad_mat, is a list where each element is a matrix of omics measurements. The names of this list are specific to the dynamic branching, but the name of the omics dataset to which each matrix belongs is stored in their 'dataset_name' attribute:\n\n\ntar_load(mad_mat)\n\nmap_chr(mad_mat, attr, \"dataset_name\")\n#> mad_mat_e428ef62 mad_mat_d5a0e3cc \n#>         \"rnaseq\"           \"snps\"\nmap(mad_mat, \\(x) x[1:5, 1:5])\n#> $mad_mat_e428ef62\n#>                        R9497     R5969     R5327     R5979     R9504\n#> ENSBTAG00000000005 10.357314 11.289047 12.070536 10.201227 10.251942\n#> ENSBTAG00000000008  4.836495  4.937948  4.375764  4.986154  5.710581\n#> ENSBTAG00000000009  3.486141  4.054636  4.983434  3.486141  3.486141\n#> ENSBTAG00000000010 12.216690 11.937084 12.079359 11.383360 11.897780\n#> ENSBTAG00000000011  3.486141  4.054636  4.005139  3.979732  3.486141\n#> \n#> $mad_mat_d5a0e3cc\n#>                             R21 Y3660 Y3243 R5764 P4669\n#> 1_41768691                    1     0     2     2     1\n#> 10-27008241-A-C-rs42918694    2     2     2     1     2\n#> 10-37505419-T-C-rs136559242   0     1     0     2     0\n#> 10-49904259-G-A-rs471723345   1     2     2     2     2\n#> 1-109550832-G-A-rs209732846   2     2     1     2     2\n\n\nit uses dynamic branching over the list of matrices to perform the prefiltering for each dataset, by calling the select_features_mad_matrix() function. The function computes the MAD coefficient of each feature, then selects the features with the highest absolute MAD values. The with_ties argument determines whether more features than requested by to_keep_ns or to_keep_props should be kept if several features at the limit of selection have identical MAD values. The select_features_mad_matrix() function returns a tibble with the MAD coefficient of each feature in the dataset, as well as an indicator of whether the feature was retained or not. This is useful to produce some diagnostic plots, for example with the plot_feature_preselection_mad() function. The results of the prefiltering are stored as a list in the target called individual_mad_values.\n\n\ntar_load(individual_mad_values)\n\nmap_chr(individual_mad_values, attr, \"dataset_name\")\n#> individual_mad_values_0bdea42a individual_mad_values_19c0eba7 \n#>                       \"rnaseq\"                         \"snps\"\n\nmap(individual_mad_values, head, 3)\n#> $individual_mad_values_0bdea42a\n#> # A tibble: 3 × 3\n#>   feature_id           mad selected\n#>   <chr>              <dbl> <lgl>   \n#> 1 ENSBTAG00000049569  3.55 TRUE    \n#> 2 ENSBTAG00000048835  3.53 TRUE    \n#> 3 ENSBTAG00000051412  3.48 TRUE    \n#> \n#> $individual_mad_values_19c0eba7\n#> # A tibble: 3 × 3\n#>   feature_id                    mad selected\n#>   <chr>                       <dbl> <lgl>   \n#> 1 1_41768691                   1.48 TRUE    \n#> 2 10-27008241-A-C-rs42918694   1.48 TRUE    \n#> 3 10-37505419-T-C-rs136559242  1.48 TRUE\n\n\nIt creates a new MultiDataSet object in which the relevant datasets have been filtered to only contain the selected features, via get_filtered_dataset_variability(). By default, the target used to store this object is called filtered_set_mad, but this can be changed via the filtered_set_target_name argument (here we called it mo_presel_unsupervised instead).\n\n\ntar_read(mo_presel_unsupervised)\n#> Object of class 'MultiDataSet'\n#>  . assayData: 3 elements\n#>     . snps: 12618 features, 139 samples \n#>     . rnaseq: 1000 features, 143 samples \n#>     . metabolome: 55 features, 139 samples \n#>  . featureData:\n#>     . snps: 12618 rows, 13 cols (feature_id, ..., p_value)\n#>     . rnaseq: 1000 rows, 15 cols (feature_id, ..., de_signif)\n#>     . metabolome: 55 rows, 16 cols (feature_id, ..., de_signif)\n#>  . rowRanges:\n#>     . snps: YES\n#>     . rnaseq: YES\n#>     . metabolome: NO\n#>  . phenoData:\n#>     . snps: 139 samples, 10 cols (id, ..., geno_comp_3)\n#>     . rnaseq: 143 samples, 10 cols (id, ..., geno_comp_3)\n#>     . metabolome: 139 samples, 10 cols (id, ..., geno_comp_3)\n\n\nConverting targets factory to R script\n\nmad_spec <- c(\"snps\" = 1000, \"rnaseq\" = 1000)\n\nmad_mat <- mad_spec |> \n  imap(\\(x, y) get_dataset_matrix(mo_set_complete, y,keep_dataset_name = TRUE))\n\nindividual_mad_values <- mad_spec |>\n  imap(\\(x, y) {\n    select_features_mad_matrix(mad_mat[[y]], to_keep_n = x, with_ties = TRUE)\n  })\n\nmo_presel_unsupervised <- get_filtered_dataset_variability(\n  mo_set_complete,\n  individual_mad_values\n)\n\nThe plot_feature_preselection_mad() function can be used to visualise the distribution of MAD values across each (non-filtered) dataset and the minimum MAD value retained in the filtered datasets:\n\nplot_feature_preselection_mad(individual_mad_values)\n\n\n\n\nIf we instead wanted to retain 50% of all features both the genomics and transcriptomics datasets, we would write:\n\n\nfeature_preselection_mad_factory(\n  mo_set_complete,\n  to_keep_props = c(\"rnaseq\" = 0.5, \"metabolome\" = 0.5),\n  with_ties = TRUE,\n  filtered_set_target_name = \"mo_presel_unsupervised\"\n)\n\n\nNote that the feature_preselection_cov_factory() function works in exactly the same way, but calls the select_features_cov_matrix() function, and the results can be visualised with the plot_feature_preselection_cov() function.\nFor convenience, the select_features_mad() and select_features_cov() functions can be used to perform a MAD- or COV-based prefiltering on one of the omics datasets directly from a MultiDataSet object. These are wrappers around the select_features_mad_matrix() and select_features_cov_matrix() functions, respectively, and take as input a MultiDataSet object as well as the name of the omics dataset on which the preselection should be run, as well as either the number or proportion of features to retain, e.g.:\n\nselect_features_mad(mo_set_complete, \"rnaseq\", to_keep_n = 1000)\nselect_features_mad(mo_set_complete, \"rnaseq\", to_keep_prop = 0.5)\n\n\n7.3.2 Supervised features preselection\nAnother approach to features preselection can be preferred when we are trying to assess the features most relevant to an outcome of interest or to differences between sample groups. In this scenario, prior to integrating the datasets, it could be useful to reduce the size of the datasets by filtering out the features that are least associated with the outcome of interest. In this case, we can use some single-omics feature selection method to perform a first “crude” prefiltering.\nmoiraine relies on the sPLS-DA algorithm implemented in the mixOmics package for this. sparse Partial Least-Squares Discriminant Analysis (or sPLS-DA for short) is a feature selection method that aims to detect, in a multivariate dataset, the variables or features that best discriminate a categorical outcome of interest in the observations. The advantages of sPLS-DA is that it can handle datasets in which there are more features than samples, which is typically the case in omics datasets. More information can be found in Lê Cao, Boitard, and Besse (2011) or in the mixOmics vignette. By running an sPLS-DA analysis on each dataset separately, we can remove the features that are least informative with respect to the trait or outcome of interest. We refer to this approach as supervised preselection, as it relies on information about the samples to select the features of interest.\nThe feature_preselection_splsda_factory() function allows us to perform this supervised preselection for some or all datasets within a MultiDataSet object. It provides the option to set either the number or proportion of features to retain in each dataset, via the to_keep_ns and to_keep_props arguments. One additional argument that needs to be passed to the function is group, which gives the name of the column in the samples metadata information to be used as categorical outcome for the sPLS-DA run. This column must be present in the sample metadata of at least one of the datasets to be filtered. For this example, we will retain in each dataset 1,000 features that best discriminate the control and diseased animals. Warning: this function can take several minutes to run.\n\n\nfeature_preselection_splsda_factory(\n  mo_set_complete,\n  group = \"status\",\n  to_keep_ns = c(\"snps\" = 1000, \"rnaseq\" = 1000),\n  filtered_set_target_name = \"mo_presel_supervised\"\n)\n\n\nThe function works as follows:\n\nit creates a grouped tibble in which each row is one of the datasets to be filtered, with the number or proportion of features to retain. It is stored in the splda_spec target:\n\n\ntar_read(splsda_spec)\n#> # A tibble: 2 × 3\n#>   dsn      tkn tar_group\n#>   <chr>  <dbl>     <int>\n#> 1 snps    1000         2\n#> 2 rnaseq  1000         1\n\n\nit uses dynamic branching over the grouped tibble to generate for each omics dataset the necessary input for the mixOmics package, via the get_input_splsda() function. The result, stored in the individual_splsda_input target, is a list of sPLS-DA inputs, i.e. a list itself containing the omics dataset as a matrix (with samples as rows and features as columns) and a vector indicating the grouping of the samples:\n\n\ntar_load(individual_splsda_input)\n\nmap(individual_splsda_input, names)\n#> $individual_splsda_input_a82e0f4d\n#> [1] \"rnaseq\" \"Y\"     \n#> \n#> $individual_splsda_input_de775b91\n#> [1] \"snps\" \"Y\"\nmap(individual_splsda_input, \\(x) head(x[[\"Y\"]]))\n#> $individual_splsda_input_a82e0f4d\n#> R9497 R5969 R5327 R5979 R9504 R5994 \n#>   BRD   BRD   BRD   BRD   BRD   BRD \n#> Levels: BRD Control\n#> \n#> $individual_splsda_input_de775b91\n#>     R21   Y3660   Y3243   R5764   P4669   R5452 \n#> Control Control Control Control     BRD Control \n#> Levels: BRD Control\n\n\nit uses dynamic branching to run a performance cross-validation analysis on each dataset, via the function perf_splsda() (which is essentially a wrapper for the mixOmics::perf() function). This cross-validation step selects the optimal number of components to compute for each dataset during the sPLS-DA analysis. The results of this cross-validation step are saved in a list, stored in the individual_splsda_perf target. It can take a bit of time (for this example, around 6 minutes per dataset).\n\n\ntar_load(individual_splsda_perf)\n\nmap_chr(individual_splsda_perf, attr, \"dataset_name\")\n#> individual_splsda_perf_68d22d74 individual_splsda_perf_746586a5 \n#>                        \"rnaseq\"                          \"snps\"\n\nThe cross-validation results be visualised with the plot_feature_preselection_splsda() function, in which the chosen value for the number of components to compute for each dataset is highlighted in grey:\n\nplot_feature_preselection_splsda(individual_splsda_perf)\n\n\n\n\n\nit uses dynamic branching to run sPLS-DA on each dataset, via the run_splsda() function. The results are stored as a list in the individual_splsda_run target.\n\n\nmap_chr(tar_read(individual_splsda_run), attr, \"dataset_name\")\n#> individual_splsda_run_fe6f99fe individual_splsda_run_4a7ecf19 \n#>                       \"rnaseq\"                         \"snps\"\n\n\nit creates a new MultiDataSet object in which the relevant datasets have been filtered to only contain the selected features. By default, the target used to store this object is called filtered_set_slpsda, but this can be changed via the filtered_set_target_name argument.\n\n\ntar_read(mo_presel_supervised)\n#> Object of class 'MultiDataSet'\n#>  . assayData: 3 elements\n#>     . snps: 1000 features, 139 samples \n#>     . rnaseq: 994 features, 143 samples \n#>     . metabolome: 55 features, 139 samples \n#>  . featureData:\n#>     . snps: 1000 rows, 13 cols (feature_id, ..., p_value)\n#>     . rnaseq: 994 rows, 15 cols (feature_id, ..., de_signif)\n#>     . metabolome: 55 rows, 16 cols (feature_id, ..., de_signif)\n#>  . rowRanges:\n#>     . snps: YES\n#>     . rnaseq: YES\n#>     . metabolome: NO\n#>  . phenoData:\n#>     . snps: 139 samples, 10 cols (id, ..., geno_comp_3)\n#>     . rnaseq: 143 samples, 10 cols (id, ..., geno_comp_3)\n#>     . metabolome: 139 samples, 10 cols (id, ..., geno_comp_3)\n\nYou can notice that with this approach, we are not guaranteed to retain exactly 1,000 features per dataset. This is because, in an sPLS-DA run, a same feature can be selected for more than one latent component, and so the number of features retained will be slightly smaller than the one requested.\n\nConverting targets factory to R script\n\nsplsda_spec <- c(\"snps\" = 1000, \"rnaseq\" = 1000)\n\nindividual_splsda_input <- splsda_spec |> \n  imap(\\(x, y) get_input_splsda(mo_set_complete, y, group = \"status\"))\n\nindividual_splsda_perf <- individual_splsda_input |>\n  map(perf_splsda)\n\nindividual_splsda_run <- splsda_spec |> \n  imap(\\(x, y) {\n    run_splsda(\n      individual_splsda_input[[y]],\n      individual_splsda_perf[[y]],\n      to_keep_n = x\n    )\n  })\n\nmo_presel_supervised <- get_filtered_dataset_splsda(\n  mo_set_complete,\n  individual_splsda_run\n)"
  },
  {
    "objectID": "prefiltering.html#recap-targets-list",
    "href": "prefiltering.html#recap-targets-list",
    "title": "7  Dataset pre-filtering",
    "section": "\n7.4 Recap – targets list",
    "text": "7.4 Recap – targets list\nFor convenience, here is the list of targets that we created in this section:\n\nTargets list for datasets prefiltering\n\n\nlist(\n  ## Unsupervised feature selection based on MAD score\n  feature_preselection_mad_factory(\n    mo_set_complete,\n    to_keep_ns = c(\"snps\" = 1000, \"rnaseq\" = 1000),\n    with_ties = TRUE,\n    filtered_set_target_name = \"mo_presel_unsupervised\"\n  ),\n  \n  ## Diagnostic plot for MAD-based feature selection\n  tar_target(\n    preselection_mad_plot,\n    plot_feature_preselection_mad(individual_mad_values)\n  ),\n  \n  ## Supervised feature selection based on bruising groups\n  feature_preselection_splsda_factory(\n    mo_set_complete,\n    group = \"status\",\n    to_keep_ns = c(\"snps\" = 1000, \"rnaseq\" = 1000),\n    filtered_set_target_name = \"mo_presel_supervised\"\n  ),\n  \n  ## Diagnostic plot for sPLS-DA based feature selection\n  tar_target(\n    preselection_splsda_plot,\n    plot_feature_preselection_splsda(individual_splsda_perf)\n  )\n)\n\n\n\n\n\n\nLê Cao, Kim-Anh, Simon Boitard, and Philippe Besse. 2011. “Sparse PLS Discriminant Analysis: Biologically Relevant Feature Selection and Graphical Displays for Multiclass Problems.” BMC Bioinformatics 12 (1): 253. https://doi.org/10.1186/1471-2105-12-253."
  },
  {
    "objectID": "spls.html#what-is-spls",
    "href": "spls.html#what-is-spls",
    "title": "8  Integration with sPLS",
    "section": "\n8.1 What is sPLS?",
    "text": "8.1 What is sPLS?\nsPLS (for sparse Partial Least Squares) is a method for the unsupervised integration of two omics datasets. Given two omics datasets for which measurements are taken on the same samples, sPLS aims at investigating the shared variation between the datasets, and the selection of correlated features driving this shared variation.\nsPLS works by constructing linear combinations of the omics features, called latent components. These latent components are constructed such that the covariance between each omics dataset’ component is maximised. They are constructed iteratively, and different matrix deflation modes can be used after the construction of each component. The selected mode defines the role that the two datasets play in the analysis, i.e. whether there is a predictor and a response dataset, or whether the two datasets play symmetrical roles. In addition, \\(L1\\)-regularisation (also called LASSO) is applied to the latent components in order to select the most important features from each dataset. Note that within the mixOmics package, the (s)PLS algorithm has two types: the univariate type denoted PLS1, which refers to the case where one of the datasets contains a single feature or variable, and the multivariate type, PLS2, which is for the integration of two datasets each with multiple features. This chapter is focused on the PLS2 type.\nsPLS requires as input matrices of omics measurements obtained on the same samples. While the omics datasets are automatically centred and scaled by the algorithm, proper preprocessing and normalisation is assumed to be carried out by the user. Although the sPLS algorithm can handle the presence of missing features, it will prohibit the use of cross-validation, so it is recommended to perform data imputation prior to running an sPLS analysis."
  },
  {
    "objectID": "spls.html#creating-the-spls-input",
    "href": "spls.html#creating-the-spls-input",
    "title": "8  Integration with sPLS",
    "section": "\n8.2 Creating the sPLS input",
    "text": "8.2 Creating the sPLS input\nThe first step is to transform the MultiDataSet object into a suitable format for the mixOmics package. This can be done through the get_input_spls() function. The function restricts the datasets to only common samples, and returns a named list, where each element is an omics dataset matrix with samples as rows and features as columns. The names of the two datasets to analyse are passed on through the datasets argument. In addition, the analysis mode must be specified through the mode argument, and optionally the multilevel option to handle repeated measurements can be set through the multilevel argument. Both concepts are explained below.\n\n8.2.1 The four sPLS modes\nThere are four possible modes that can be used for an sPLS analysis. These modes define the role that each of the datasets play, and differ by the type of matrix deflation used in the analysis. These four modes are:\n\nThe regression mode (mode = \"regression\"): the first dataset (first name in datasets argument) is considered as the ‘predictor’ dataset, and the second as the ‘response’ dataset. With this mode, the order in which the datasets appear in the datasets argument matters.\nThe canonical mode (mode = \"canonical\"): the two datasets play a symmetrical role, and the order in which they appear in the datasets argument does not matter. This mode is used when there is no a priori relationship between the two datasets. This is similar to a canonical correlation analysis (CCA).\nThe invariant mode (mode = \"invariant\"): similar to the regression mode with the first dataset being considered as the predictor dataset, and the second as the response dataset. However no matrix deflation is performed, which allows to perform a redundancy analysis. Again, the order in which the datasets appear in the datasets argument matters.\nThe classic mode (mode = \"classic\"): similar to the regression mode with the first dataset being considered as the predictor dataset, and the second as the response dataset; however this mode uses a different normalisation method for the loading vectors in accordance to another version of the sPLS method. Again, the order in which the datasets appear in the datasets argument matters.\n\nThe difference between these four modes lies in the type of matrix deflation used after computing each latent component. Therefore, the first latent components constructed will be identical between modes, but the subsequent ones will differ.\n\n8.2.2 The multilevel option\nThe mixOmics package includes an option to deal with repeated measurements (see the mixOmics multilevel article). This corresponds to the case where several samples in the omics datasets come from the same biological individual (patient, animal, plant) that has been measured several times (e.g. before and after a treatment, or across several body sites). In such case, it is possible that the measurements obtained are more similar within an individual than within a treatment group, which reduces our ability to detect differences between the treatment groups.\nTo mitigate this effect, the mixOmics package can decompose the datasets to extract their within-individual variation part, which is then used as input for the sPLS run (Liquet et al. (2012) ). As noted by the authors of the package, this methodology is applicable to balanced as well as unbalanced designs. Before selecting this option, is it recommended to explore the datasets with some unsupervised dimension reduction method (e.g. a PCA), in order to assess whether the between-individual variation should be removed to enable the detection of any between-treatment effect.\nThe multilevel option can accommodate one- or two-factor decomposition, which refers to the number of treatment covariates whose effect we are studying. For example, if we have repeated measurements on the same subjects for three time-points after the application of a treatment, we will use a one-factor decomposition with time being the factor of interest. If instead we have repeated measurements on the same subjects for three time-points after the application of two different treatments (so 6 measurements for a same subject), we will use a two-factor decomposition with time and treatment as the factors of interest.\nWith the get_input_spls() function, in order to use the multilevel option with one factor, the multilevel argument should be populated with the name of the column in the samples metadata of the omics datasets containing the ID of the biological individuals. For example, if we have measured different plants once after the application of two different treatments, the samples metadata table might look like this:\n\n\n\n\n\nid\nplant_id\ntreatment\n\n\n\nsample_1\nsample_1\nplant_1\nA\n\n\nsample_2\nsample_2\nplant_1\nB\n\n\nsample_3\nsample_3\nplant_2\nA\n\n\nsample_4\nsample_4\nplant_2\nB\n\n\nsample_5\nsample_5\nplant_3\nA\n\n\nsample_6\nsample_6\nplant_3\nB\n\n\nsample_7\nsample_7\nplant_4\nA\n\n\nsample_8\nsample_8\nplant_4\nB\n\n\nsample_9\nsample_9\nplant_5\nA\n\n\nsample_10\nsample_10\nplant_5\nB\n\n\n\n\n\nwhere the id column contains the unique ID for each observation (these are the IDs present in the omics datasets), plant_id records the ID of the plant measured (our biological individuals) on which repeated measurements have been taken, and treatment contains the treatment that has been applied before each observation. In that case, we will set multilevel = \"plant_id\" to use the multilevel option:\n\nspls_input_multilevel1 <- get_input_spls(\n  mo_set_multilevel1, \n  mode = \"canonical\",\n  datasets = c(\"rnaseq\", \"metabolome\"),\n  multilevel = \"plant_id\"\n)\n\nThe resulting design table that will be used by the mixOmics package is stored in the multilevel argument of the object returned by the get_input_spls() function. It consists of a data-frame with observations as rows, and an integer ID for the corresponding biological individual in the first column:\n\nattr(spls_input_multilevel1, \"multilevel\")\n\n\n#>           plant_id\n#> sample_1         1\n#> sample_2         1\n#> sample_3         2\n#> sample_4         2\n#> sample_5         3\n#> sample_6         3\n#> sample_7         4\n#> sample_8         4\n#> sample_9         5\n#> sample_10        5\n\nIn order to use the multilevel option with two factors, the multilevel argument should instead be populated with a vector of three column names from the samples metadata table. The first value, similarly to a one-factor decomposition, should be the name of the column containing the ID of the biological individuals. The second and third values should be the name of the columns containing the levels of the two factors of interest. Continuing on the previous example, supposing that in a similar study, we take measurements on the plants at three different time-points after the application of each treatment. The samples metadata table might look like this:\n\n\n\n\n\nid\nplant_id\ntreatment\ntime\n\n\n\nsample_1\nsample_1\nplant_1\nA\n1\n\n\nsample_2\nsample_2\nplant_1\nA\n2\n\n\nsample_3\nsample_3\nplant_1\nA\n3\n\n\nsample_4\nsample_4\nplant_1\nB\n1\n\n\nsample_5\nsample_5\nplant_1\nB\n2\n\n\nsample_6\nsample_6\nplant_1\nB\n3\n\n\nsample_7\nsample_7\nplant_2\nA\n1\n\n\nsample_8\nsample_8\nplant_2\nA\n2\n\n\nsample_9\nsample_9\nplant_2\nA\n3\n\n\nsample_10\nsample_10\nplant_2\nB\n1\n\n\nsample_11\nsample_11\nplant_2\nB\n2\n\n\nsample_12\nsample_12\nplant_2\nB\n3\n\n\n\n\n\nwith similar columns to the previous example, and an additional time column indicating the time-point at which the measurement was taken. In that case, we should set multilevel = c(\"plant_id\", \"treatment\", \"time\") to use the multilevel option, as follows:\n\nspls_input_multilevel2 <- get_input_spls(\n  mo_set_multilevel2, \n  mode = \"canonical\",\n  datasets = c(\"rnaseq\", \"metabolome\"),\n  multilevel = c(\"plant_id\", \"treatment\", \"time\")\n)\n\nAs for the one-factor example, the resulting design table that will be used by the mixOmics package is stored in the multilevel argument of the object returned by the get_input_spls() function. It consists of a data-frame with observations as rows, and an integer ID for the corresponding biological individual in the first column, and the two factors with their original levels in the following columns:\n\nattr(spls_input_multilevel2, \"multilevel\")\n\n\n#>           plant_id treatment time\n#> sample_1         1         A    1\n#> sample_2         1         A    2\n#> sample_3         1         A    3\n#> sample_4         1         B    1\n#> sample_5         1         B    2\n#> sample_6         1         B    3\n#> sample_7         2         A    1\n#> sample_8         2         A    2\n#> sample_9         2         A    3\n#> sample_10        2         B    1\n#> sample_11        2         B    2\n#> sample_12        2         B    3\n\n\n8.2.3 The sPLS input object\nFor our example dataset, we will integrate the transcriptomics and metabolomics datasets using the canonical mode (since we don’t have any a priori on the relationship between the two datasets). In this case we do not have a repeated measurements design.\n\n\ntar_target(\n  spls_input,\n  get_input_spls(\n    mo_presel_supervised,\n    mode = \"canonical\",\n    datasets = c(\"rnaseq\", \"metabolome\")\n  )\n)\n\n\nThe result of the function is a named list of length 2, where each element is a matrix of omics measurements, which have been restricted to samples that are common to the two datasets. The sPLS mode to be used is stored in the mode attribute of the object.\n\ntar_read(spls_input) |> str()\n#> List of 2\n#>  $ rnaseq    : num [1:139, 1:994] 3.49 3.49 4.01 3.49 4.25 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : chr [1:139] \"R9497\" \"R5969\" \"R5327\" \"R5979\" ...\n#>   .. ..$ : chr [1:994] \"ENSBTAG00000000020\" \"ENSBTAG00000000046\" \"ENSBTAG00000000056\" \"ENSBTAG00000000061\" ...\n#>   ..- attr(*, \"datatype\")= chr \"ExpressionSet\"\n#>   .. ..- attr(*, \"package\")= chr \"Biobase\"\n#>  $ metabolome: num [1:139, 1:55] 3.4 3.32 3.72 3.33 3.6 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : chr [1:139] \"R9497\" \"R5969\" \"R5327\" \"R5979\" ...\n#>   .. ..$ : chr [1:55] \"HMDB00001\" \"HMDB00008\" \"HMDB00042\" \"HMDB00043\" ...\n#>   ..- attr(*, \"datatype\")= chr \"MetabolomeSet\"\n#>   .. ..- attr(*, \"package\")= chr \"moiraine\"\n#>  - attr(*, \"mode\")= chr \"canonical\""
  },
  {
    "objectID": "spls.html#choosing-the-number-of-latent-components",
    "href": "spls.html#choosing-the-number-of-latent-components",
    "title": "8  Integration with sPLS",
    "section": "\n8.3 Choosing the number of latent components",
    "text": "8.3 Choosing the number of latent components\nThe first step when running an sPLS analysis is to determine the number of latent components to construct, which can be chosen using cross-validation. This is done by running an initial sPLS analysis on the datasets with no feature selection and a large number of latent components; for example we want to test up to four latent components. We use for this the spls_run() function, which is a wrapper for the mixOmics::spls() function.\n\n\ntar_target(\n  spls_novarsel,\n  spls_run(\n    spls_input,\n    ncomp = 4\n  )\n)\n\n\nWe then apply the mixOmics::perf() function on the result of this initial run. There are several parameters to set:\n\nvalidation: the type of cross-validation to perform, M-fold (\"Mfold\") or leave-one-out (\"loo\"). We recommend to use M-fold validation, except when the number of samples is very small.\nfolds: for M-fold cross-validation, the number of folds to construct, i.e. the number of groups in which to split the samples. Each group in turn will be considered as test set while the remaining groups are used to make the training set. The value to use depends on the number of samples in the datasets. By default, 10 is a reasonable number. For leave-one-out cross-validation, this parameter is set to the number of samples (that is the principle of leave-one-out cross-validation).\nnrepeat: the number of times the cross-validation will be repeated. This is important for M-fold cross-validation, as the way the samples are split into groups affects the results. Therefore, by repeating the cross-validation scheme we are averaging the results over different splits, thus reducing the impact of samples splitting. We recommend at least 10 repeats. Irrelevant for leave-one-out cross-validation, so can be left to 1.\ncpus: number of CPUs to use for the computation. Useful if folds \\(\\times\\) repeats is large, as this can be computationally intensive.\n\nHere we’ll perform a 10-fold cross validation with 10 repeats.\n\n\ntar_target(\n  spls_perf_res,\n  mixOmics::perf(\n    spls_novarsel,\n    validation = \"Mfold\",\n    folds = 10,\n    nrepeat = 10,\n    cpus = 3\n  )\n)\n\n\nWe can visualise the results of the cross-validation with the mixOmics::plot.tune.spls() function, setting the criterion to Q2.total, which corresponds to the \\(Q^2\\) criterion reflecting the predictive power of the model (other possible values include cor.tpred, cor.upred, RSS.tpred, RSS.upred):\n\nplot(tar_read(spls_perf_res), criterion = \"Q2.total\")\n\n\n\n\nThe plot generated displays the average \\(Q^2_{total}\\) criterion across the different cross-validation folds obtained with different number of latent components. The authors of the mixOmics package recommend to select the number of latent components above which the Q2 criterion becomes smaller than 0.0975 (depicted as a black horizontal line in the plot). However, there are cases in which the Q2 values instead increases with the number of latent components. In these cases, it is recommended to select the number of latent components above which the Q2 values exceed the threshold of 0.0975. To facilitate the selection, the spls_get_optim_ncomp() function can automatically select the optimal number of latent components to use based on the cross-validation results. However, its results should always be checked against the graphical representation of the \\(Q^2_{total}\\) criterion. In our case, the function selects the optimal number of latent components to construct to be 1:\n\nspls_get_optim_ncomp(tar_read(spls_perf_res))\n#> [1] 1\n\nNote that with this function, it is possible to set a minimum number of latent components to construct. This is useful if we want to be able to generate sample plots, even though technically only one latent component is necessary. This minimum number can be set through the min_ncomp argument. For the example, we will set it to two, to be able to showcase some of the plotting functionalities. We will save the chosen value in a target, for reuse in the rest of the pipeline:\n\n\ntar_target(\n  spls_optim_ncomp,\n  spls_get_optim_ncomp(spls_perf_res, min_ncomp = 2)\n)\n\n\n\ntar_read(spls_optim_ncomp)\n#> [1] 2"
  },
  {
    "objectID": "spls.html#choosing-the-number-of-features-to-retain",
    "href": "spls.html#choosing-the-number-of-features-to-retain",
    "title": "8  Integration with sPLS",
    "section": "\n8.4 Choosing the number of features to retain",
    "text": "8.4 Choosing the number of features to retain\nThe next parameter to set is the number of features to retain from each of the omics datasets, for each latent component. Again, we can use cross-validation to select optimal values amongst a grid of values to test. The range of values to test depends on the type of question we are trying to answer: selecting a larger number of features might lead to a higher degree of agreement between the latent components of the two datasets, but will be hard to manually inspect for further characterisation.\nThe function spls_tune() provides a wrapper around the mixOmics::tune() function that performs this cross-validation. Some of the arguments are similar to the mixOmics::perf() function, e.g. validation, folds, nrepeats or cpus. In addition, we recommend setting the measure argument, which corresponds to the metric used for performance assessment, to \"cor\" (i.e. the correlation between the latent components constructed). Alternatively, it is possible to set the measure argument to \"RSS\".\nThe keepX and keepY arguments control the grid of values to be tested as possible number of features to retain from the first and second dataset, respectively. Both arguments should be in the form of an integer vector of values to test. If no value is provided for either of these arguments, six values ranging from 5 to 30 (by increments of 5) are tested for the corresponding dataset. Here we will increase the maximum number of features that can be retained from each dataset to 100. Note that the metabolomics dataset has only 55 features, so the spls_tune function will remove all values to test above this number.\n\n\ntar_target(\n  spls_tune_res,\n  spls_tune(\n    spls_input,\n    ncomp = spls_optim_ncomp,\n    keepX = seq(10, 100, 10),\n    keepY = seq(10, 100, 10),\n    validation = \"Mfold\",\n    folds = 10,\n    nrepeat = 5,\n    measure = \"cor\",\n    cpus = 3\n  )\n)\n\n\nThe cross-validation results can be inspected with the spls_plot_tune() function:\n\ntar_load(spls_tune_res)\nspls_plot_tune(spls_tune_res)\n\n\n\n\nIn the plot, each point corresponds to a pair of values (keepX, keepY) tested. The colour of each point indicates the average correlation obtained across the cross-validation folds between the latent components constructed for the first dataset (left panel) or second dataset (right panel). The grey shadow around each point indicates the Coefficient of Variation (i.e. standard deviation divided by mean) of this correlation across the cross-validation folds (so a larger shadow indicates a larger relative variation across the folds). The point corresponding to the optimal pair of values for keepX and keepY is highlighted in red. It corresponds to the pair of values that maximises this average correlation for both datasets (according to a t-test of significance).\nThe optimal number of features to retain from each dataset for the different latent components is stored in the cross-validation results object, and can be accessed with:\n\nspls_tune_res$choice.keepX\n#> comp1 comp2 \n#>    40    10\nspls_tune_res$choice.keepY\n#> comp1 comp2 \n#>    20    50"
  },
  {
    "objectID": "spls.html#final-spls-run",
    "href": "spls.html#final-spls-run",
    "title": "8  Integration with sPLS",
    "section": "\n8.5 Final sPLS run",
    "text": "8.5 Final sPLS run\nOnce a value has been selected for all parameters, we can perform the final sPLS run.\n\n\ntar_target(\n  spls_final_run,\n  spls_run(\n    spls_input,\n    ncomp = spls_optim_ncomp,\n    keepX = spls_tune_res$choice.keepX,\n    keepY = spls_tune_res$choice.keepY\n  )\n)\n\n\nWe will load the results of this final run for interpretation.\n\ntar_load(spls_final_run)\n\nTo facilitate reporting, the spls_get_params() function extracts from the sPLS result the parameters used (i.e. number of latent components computed and number of features retained from each dataset for each latent component):\n\nspls_get_params(spls_final_run)\n#> # A tibble: 3 × 3\n#>   Parameter Description                                                    Value\n#>   <chr>     <chr>                                                          <chr>\n#> 1 ncomp     Number of latent component                                     2    \n#> 2 keepX     Number of features retained in dataset rnaseq for each latent… 40, …\n#> 3 keepY     Number of features retained in dataset metabolome for each la… 20, …"
  },
  {
    "objectID": "spls.html#results-interpretation",
    "href": "spls.html#results-interpretation",
    "title": "8  Integration with sPLS",
    "section": "\n8.6 Results interpretation",
    "text": "8.6 Results interpretation\nIn Chapter 12, we show the different functionalities implemented in the moiraine package that facilitate the interpretation of the results from an integration tool. In this section, we show some of the sPLS-specific plots that can be generated to help interpret the results of an sPLS run.\n\n8.6.1 Samples plots\nWe can represent the samples in the subspace spanned by the latent components for each dataset, using the mixOmics::plotIndiv() function.\n\nplotIndiv(\n  spls_final_run,\n  ind.names = TRUE,\n  overlap = FALSE,\n  comp = 1:2\n)\n\n\n\n\nHere, ‘Block X’ refers to the first dataset (i.e. the transcriptomics dataset in our case), and ‘Block Y’ to the second dataset (the metabolomics dataset). The agreement between the latent components computed for each dataset can be more easily visualised using an arrow plot, using the mixOmics::plotArrow() function:\n\nplotArrow(\n  spls_final_run,\n  ind.names = TRUE,\n  comp = 1:2\n)\n\n\n\n\nIn the arrow plot, each sample is represented with two points, which are linked by an arrow. The point at the start of the arrow corresponds to the sample in the projection space of the first dataset (i.e. transcriptomics dataset), while the point at the end of the arrow shows the location of the sample in the projection space of the second dataset (i.e. the metabolomics dataset). In this plot, most of the arrows are large, which indicates that there is not a good agreement between the latent components of the two datasets.\n\n8.6.2 Correlation circle plots\nThe correlation circle plots produced by the mixOmics::plotVar() function allows to visualise the correlation between each of the selected features and the different latent components:\n\nplotVar(\n  spls_final_run,\n  comp = 1:2,\n  var.names = TRUE,\n  overlap = FALSE,\n  cex = c(3, 3)\n)\n\n\n\n\nThe plotVar() function offers the option to show the label of the features rather than representing them as points. However, it can be more informative to use information from the feature metadata as labels, rather than using the feature IDs. For example in the transcriptomics dataset, it would be more interesting to use the name of the genes. This information is available in the datasets’ features metadata:\n\ntar_load(mo_set_de)\nget_features_metadata(mo_set_de)[[\"rnaseq\"]] |>\n  str()\n#> 'data.frame':    20335 obs. of  15 variables:\n#>  $ feature_id : chr  \"ENSBTAG00000000005\" \"ENSBTAG00000000008\" \"ENSBTAG00000000009\" \"ENSBTAG00000000010\" ...\n#>  $ chromosome : Factor w/ 178 levels \"1\",\"2\",\"3\",\"4\",..: 17 29 18 21 8 20 20 5 5 23 ...\n#>  $ start      : int  65389743 32214439 12338037 34209956 7950815 33708626 33674806 74883636 74905031 27720176 ...\n#>  $ end        : int  65505336 32244810 12342272 34223394 7971600 33732944 33703223 74893752 74919112 27721739 ...\n#>  $ width      : int  115594 30372 4236 13439 20786 24319 28418 10117 14082 1564 ...\n#>  $ strand     : Factor w/ 3 levels \"+\",\"-\",\"*\": 1 2 1 1 2 1 1 2 2 2 ...\n#>  $ Name       : chr  \"GRK3\" \"KCNJ1\" \"FOXF1\" \"UBL7\" ...\n#>  $ description: chr  \"G protein-coupled receptor kinase 3 [Source:VGNC Symbol;Acc:VGNC:53904]\" \"potassium inwardly rectifying channel subfamily J member 1 [Source:VGNC Symbol;Acc:VGNC:30453]\" \"forkhead box F1 [Source:VGNC Symbol;Acc:VGNC:29084]\" \"ubiquitin like 7 [Source:VGNC Symbol;Acc:VGNC:50128]\" ...\n#>  $ log_fc     : num  0.136 -0.1297 1.2714 0.3957 0.0777 ...\n#>  $ log_cpm    : num  5.905 -0.744 -2.563 6.256 -2.761 ...\n#>  $ f          : num  4.163 1.068 23.956 60.53 0.142 ...\n#>  $ p_value    : num  4.32e-02 3.03e-01 2.73e-06 1.58e-12 7.07e-01 ...\n#>  $ fdr        : num  7.17e-02 3.94e-01 9.67e-06 1.52e-11 7.77e-01 ...\n#>  $ de_signif  : chr  \"Not DE\" \"Not DE\" \"Not DE\" \"Not DE\" ...\n#>  $ de_status  : chr  \"Not DE\" \"Not DE\" \"Not DE\" \"Not DE\" ...\n\nThe spls_plot_var() function is a variant of plotVar(), which uses columns from the features metadata to label features plot. It takes as an input the sPLS result object as well as the MultiDataSet object, and a named list providing for each dataset the name of the column in the feature metadata data-frame to use as features label:\n\nspls_plot_var(\n  spls_final_run,\n  mo_set_de,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  overlap = FALSE,\n  cex = c(3, 3),\n  comp = 1:2\n)\n\n\n\n\nNote that if a dataset is not present in the list passed to label_cols, the feature IDs will be used as labels."
  },
  {
    "objectID": "spls.html#recap---targets-list",
    "href": "spls.html#recap---targets-list",
    "title": "8  Integration with sPLS",
    "section": "\n8.7 Recap - targets list",
    "text": "8.7 Recap - targets list\nFor convenience, here is the list of targets that we created in this section:\n\nTargets list for sPLS analysis\n\n\nlist(\n  ## Creating sPLS input\n  tar_target(\n    spls_input,\n    get_input_spls(\n      mo_presel_supervised,\n      mode = \"canonical\",\n      datasets = c(\"rnaseq\", \"metabolome\")\n    )\n  ),\n  \n  ## Initial PLS run with no feature selection and large number of components\n  tar_target(\n    spls_novarsel,\n    spls_run(\n      spls_input,\n      ncomp = 4\n    )\n  ),\n  \n  ## Cross-validation for number of components\n  tar_target(\n    spls_perf_res,\n    mixOmics::perf(\n      spls_novarsel,\n      validation = \"Mfold\",\n      folds = 10,\n      nrepeat = 10,\n      cpus = 3\n    )\n  ),\n  \n  ## Plotting cross-validation results (for number of components)\n  ## Can try criterion = 'Q2.total', 'cor.tpred', 'cor.upred', 'RSS.tpred',\n  ## 'RSS.upred' (but avoid 'RSS' and 'PRESS')\n  tar_target(\n    spls_perf_plot,\n    plot(spls_perf_res, criterion = \"Q2.total\")\n  ),\n  \n  ## Selected value for ncomp\n  tar_target(\n    spls_optim_ncomp,\n    spls_get_optim_ncomp(spls_perf_res, min_ncomp = 2)\n  ),\n  \n  ## Cross-validation for number of features to retain\n  tar_target(\n    spls_tune_res,\n    spls_tune(\n      spls_input,\n      ncomp = spls_optim_ncomp,\n      keepX = seq(10, 100, 10),\n      keepY = seq(10, 100, 10),\n      validation = \"Mfold\",\n      folds = 10,\n      nrepeat = 5,\n      measure = \"cor\",\n      cpus = 3\n    )\n  ),\n  \n  ## Plotting cross-validation results (for number of features)\n  tar_target(\n    spls_tune_plot,\n    spls_plot_tune(spls_tune_res)\n  ),\n  \n  ## Final sPLS run\n  tar_target(\n    spls_final_run,\n    spls_run(\n      spls_input,\n      ncomp = spls_optim_ncomp,\n      keepX = spls_tune_res$choice.keepX,\n      keepY = spls_tune_res$choice.keepY\n    )\n  )\n)\n\n\n\n\n\n\nLiquet, Benoit, Kim-Anh Lê Cao, Hakim Hocini, and Rodolphe Thiébaut. 2012. “A Novel Approach for Biomarker Selection and the Integration of Repeated Measures Experiments from Two Assays.” BMC Bioinformatics 13 (1): 325. https://doi.org/10.1186/1471-2105-13-325."
  },
  {
    "objectID": "so2pls.html#what-is-so2pls",
    "href": "so2pls.html#what-is-so2pls",
    "title": "9  Integration with sO2PLS",
    "section": "\n9.1 What is sO2PLS?",
    "text": "9.1 What is sO2PLS?\nsO2PLS (for Sparse Orthogonal two-way Partial Least Squares) is a method for the unsupervised integration of two omics datasets. It aims at decomposing each of the two datasets into a joint part, which reflects covariation shared by the datasets, an orthogonal or specific part, which represents variation unique to each dataset, and a residual part. To this end, sets of joint and specific latent components are constructed for each dataset; these components are constructed as a linear combination of the features from the corresponding dataset. Feature selection is performed on the joint components of each dataset.\nThe joint latent components are constructed by maximising the covariance between the projection of each dataset onto their respective joint part. Sparsity is obtained by applying \\(L_1\\) regularisation (LASSO) to the feature joint loadings (i.e. their contribution to the joint components). However, no sparsity constraint is used on the feature loadings for the specific components. Joint and specific components are iteratively updated, with the datasets being corrected by removing the specific part before re-calculating the joint components. While the number of joint components is the same for the two datasets, each dataset can have a different number of specific components, including no specific component at all.\nsO2PLS requires as input matrices of omics measurements obtained on the same samples. In addition, it assumes that the features have been centred. The method cannot handle missing values, so these should be imputed prior to using sO2PLS."
  },
  {
    "objectID": "so2pls.html#creating-the-so2pls-input",
    "href": "so2pls.html#creating-the-so2pls-input",
    "title": "9  Integration with sO2PLS",
    "section": "\n9.2 Creating the sO2PLs input",
    "text": "9.2 Creating the sO2PLs input\nThe first step is to transform the MultiDataSet object into a suitable format for the OmicsPLS package. This is done through the get_input_omicspls() function. The names of the two datasets to integrate are passed to the function through the datasets argument (in our case, we want to integrate the transcriptomics and metabolomics datasets). In the OmicsPLS terminology, the first dataset will be the X dataset, and the second will be the Y dataset. The function filters out samples that are not present in both datasets, and centres the features in each dataset. There is also the option to scale the datasets, through the scale_data argument (default behaviour is to not scale the data).\n\n\ntar_target(\n  omicspls_input,\n  get_input_omicspls(\n    mo_presel_supervised,\n    datasets = c(\"rnaseq\", \"metabolome\")\n  )\n)\n\n\nThe function returns a named list, where each element of the list is a matrix of measurements corresponding to one of the datasets to integrate, with samples as rows and features as columns:\n\ntar_read(omicspls_input) |> str()\n#> List of 2\n#>  $ rnaseq    : num [1:139, 1:994] -0.39 -0.39 0.129 -0.39 0.376 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : chr [1:139] \"R9497\" \"R5969\" \"R5327\" \"R5979\" ...\n#>   .. ..$ : chr [1:994] \"ENSBTAG00000000020\" \"ENSBTAG00000000046\" \"ENSBTAG00000000056\" \"ENSBTAG00000000061\" ...\n#>   ..- attr(*, \"scaled:center\")= Named num [1:994] 3.88 7.44 10.14 4.75 12.64 ...\n#>   .. ..- attr(*, \"names\")= chr [1:994] \"ENSBTAG00000000020\" \"ENSBTAG00000000046\" \"ENSBTAG00000000056\" \"ENSBTAG00000000061\" ...\n#>  $ metabolome: num [1:139, 1:55] -0.142 -0.2204 0.1819 -0.2126 0.0643 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : chr [1:139] \"R9497\" \"R5969\" \"R5327\" \"R5979\" ...\n#>   .. ..$ : chr [1:55] \"HMDB00001\" \"HMDB00008\" \"HMDB00042\" \"HMDB00043\" ...\n#>   ..- attr(*, \"scaled:center\")= Named num [1:55] 3.539 4.68 8.468 6.998 0.918 ...\n#>   .. ..- attr(*, \"names\")= chr [1:55] \"HMDB00001\" \"HMDB00008\" \"HMDB00042\" \"HMDB00043\" ...\n\nNote that there are 139 samples in each matrix, which are the samples that are present in both datasets."
  },
  {
    "objectID": "so2pls.html#choosing-the-number-of-latent-components",
    "href": "so2pls.html#choosing-the-number-of-latent-components",
    "title": "9  Integration with sO2PLS",
    "section": "\n9.3 Choosing the number of latent components",
    "text": "9.3 Choosing the number of latent components\nIn order to integrate the datasets with sO2PLS, it is necessary to set the number of joint and specific components that will be computed for each dataset. Within the sO2PLS framework, the number of joint components is denoted as \\(n\\) (it is the same value for both datasets), while \\(n_x\\) and \\(n_y\\) represent the number of specific components for the first and second dataset, respectively. \\(n\\) must be a positive integer (i.e. at least 1), but \\(n_x\\) and \\(n_y\\) can also be set to 0. Values for the number of joint and specific components can be estimated using cross-validation. The authors of the OmicsPLS package recommend a two-step approach, which is detailed below.\n\n9.3.1 Adjusted cross-validation\nIn a first step, an adjusted cross-validation procedure is used to compute the optimal values for \\(n\\), \\(n_x\\) and \\(n_y\\). This is done through the so2pls_crossval_o2m_adjR2() function, which is a wrapper around the OmicsPLS::crossval_o2m_adjR2() function. Briefly, the function estimates, for each possible value of \\(n\\), the values of \\(n_x\\) and \\(n_y\\) that minimise the prediction error for the joint part of each dataset1. Using these values, it then computes the prediction error for the full dataset decomposition and uses it to select the optimal value of \\(n\\). Compared with the traditional cross-validation approach where the “full decomposition” prediction error is calculated for each possible combination of the tested parameter values, this adjusted procedure can be much faster, while often giving a very similar result. The authors recommend using it as a first pass to reduce the number of values to test for \\(n\\), \\(n_x\\) and \\(n_y\\).\nIn this example, we will test 1 to 5 joint components, and 0 to 10 specific components for each dataset (testing only even values). We use a 10-fold cross validation (nr_folds parameter specifying the number of folds to use for the cross-validation), and distribute the computation over 6 cores to reduce the running time (through the nr_cores argument). We will also set the seed to ensure the reproducibility of the results, through the seed argument.\n\n\ntar_target(\n  so2pls_cv_adj,\n  so2pls_crossval_o2m_adjR2(\n    omicspls_input,\n    a = 1:5,\n    ax = seq(0, 10, by = 2),\n    ay = seq(0, 10, by = 2),\n    nr_folds = 10,\n    nr_cores = 6,\n    seed = 127\n  )\n)\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn order to use the seed argument for the so2pls_crossval_o2m_adjR2, you need to be using the latest version of the OmicsPLS package from GitHub, which can be installed with devtools::install_github(\"selbouhaddani/OmicsPLS\").\n\n\nDespite using multiple cores, this function can take a while to run (this example took around 8 minutes to execute). The function returns a data-frame giving, for each tested value for \\(n\\), the values of \\(n_x\\) and \\(n_y\\) that yielded the lowest prediction error, as well as the prediction error obtained for these values of the parameters:\n\ntar_load(so2pls_cv_adj)\n\nso2pls_cv_adj\n#>        MSE n nx ny\n#> 1 1.289030 1  0  4\n#> 2 1.295734 2  2 10\n#> 3 1.302705 3  2 10\n#> 4 1.295478 4  4 10\n#> 5 1.293570 5  4 10\n\nThe prediction error obtained with each tested value of \\(n\\) can be visualised with the so2pls_plot_cv_adj() function, which takes as input the result from so2pls_crossval_o2m_adjR2():\n\nso2pls_plot_cv_adj(so2pls_cv_adj)\n\n\n\n\nIn the plot, The values of \\(n_x\\) and \\(n_y\\) chosen for each value of \\(n\\) are displayed next to each point. We can see that the smallest prediction error is obtained with one joint component.\nIn addition, the so2pls_get_optim_ncomp_adj() function returns the optimal values of \\(n\\), \\(n_x\\) and \\(n_y\\) from the output of the cross-validation step as a vector:\n\nso2pls_get_optim_ncomp_adj(so2pls_cv_adj)\n#>  n nx ny \n#>  1  0  4\n\n\n9.3.2 Standard cross-validation\nIn a second step, a standard cross-validation approach is used to refine the results from the adjusted cross-validation step, by testing values around the selected \\(n\\), \\(n_x\\) and \\(n_y\\) values. Standard cross-validation is performed within the OmicsPLS package by the OmicsPLS::crossval_o2m() function. The function so2pls_crossval_o2m() is a convenient wrapper that takes as input the result from the adjusted cross-validation step, in order to automatically select which values should be tested for \\(n\\), \\(n_x\\) and \\(n_y\\).\nOnce again, we perform a 10-fold cross-validation, distributed over 6 cores:\n\n\ntar_target(\n  so2pls_cv,\n  so2pls_crossval_o2m(\n    omicspls_input,\n    so2pls_cv_adj, ## result from the adjusted cross-validation\n    nr_folds = 10,\n    nr_cores = 6,\n    seed = 356\n  )\n)\n\n\nThis standard cross-validation step takes around 6 minutes to run, which makes sense as we are testing less values than in the previous step.\nThe result is a cvo2m object, which is a list containing the results of the cross-validation step as well as further information about the run. It can be visualised with the so2pls_plot_cv() function:\n\ntar_load(so2pls_cv)\n\nso2pls_plot_cv(so2pls_cv)\n\n\n\n\nThe plot displays, for each tested value of \\(n\\) (facets), the prediction error (MSE – colour) obtained for the tested values of \\(n_x\\) (x-axis) and \\(n_y\\) (y-axis). The combination of values yielding the smallest prediction error is highlighted in red. This optimal combination can be extracted from the results with the so2pls_get_optim_ncomp() function:\n\nso2pls_get_optim_ncomp(so2pls_cv)\n#>  n nx ny \n#>  1  1  5\n\nFor convenience for the next steps of the analysis, we can store these values as a target:\n\n\ntar_target(\n  so2pls_cv_res,\n  so2pls_get_optim_ncomp(so2pls_cv)\n)"
  },
  {
    "objectID": "so2pls.html#choosing-the-number-of-features-to-retain-for-the-joint-components",
    "href": "so2pls.html#choosing-the-number-of-features-to-retain-for-the-joint-components",
    "title": "9  Integration with sO2PLS",
    "section": "\n9.4 Choosing the number of features to retain for the joint components",
    "text": "9.4 Choosing the number of features to retain for the joint components\nOnce the number of joint and specific components to compute has been decided, we need to estimate the optimal number of features to retain from each dataset for each of the joint components (no feature selection is performed for the specific components). This is done through cross-validation, where the aim is to maximise the covariance between the joint components of the two datasets. This step is performed via the so2pls_crossval_sparsity() function (which is identical to the OmicsPLS::crossval_sparsity() function, except that all results from the cross-validation are returned, which is necessary for plotting purposes). The function takes as input the number of joint and specific components (n, nx and ny arguments), the number of folds to use for the cross-validation (nr_folds), and the values to test for each dataset (keepx_seq and keepy_seq arguments). For this example, we will test values between 5 and 100 for the rnaseq dataset, and between 5 and 40 for the metabolomics dataset:\n\n\ntar_target(\n  so2pls_cv_sparsity,\n  so2pls_crossval_sparsity(\n    omicspls_input,\n    n = so2pls_cv_res['n'],\n    nx = so2pls_cv_res['nx'],\n    ny = so2pls_cv_res['ny'],\n    nr_folds = 10,\n    keepx_seq = c(seq(5, 30, 5), seq(40, 100, 10)),\n    keepy_seq = c(seq(5, 40, 5))\n  )\n)\n\n\nThe function returns a list containing the results of the cross-validation. They can be visualised with the so2pls_plot_cv_sparsity() function:\n\ntar_load(so2pls_cv_sparsity)\n\nso2pls_plot_cv_sparsity(so2pls_cv_sparsity)\n\n\n\n\nThe plot depicts, for each joint component (facets – in this case there is only one), the average (colour) and standard deviation (gray area) of the covariance between the datasets’ joint components obtained for different number of features retained from the first (x-axis) and second (y-axis) dataset. The OmicsPLS package offers two options to select the optimal values to select for each latent component:\n\nthe maximum rule: the values that maximise the covariance between the datasets’ joint components are selected;\nthe 1 standard deviation rule: the smallest values (i.e. number of features) yielding a covariance within 1SD of the maximum covariance obtained for this latent component are selected.\n\nIn the plot, the values selected with the maximum rule are highlighted in orange, and the ones selected with the 1SD rule in red.\nThese optimal values can be extracted from the results of the cross-validation step with the so2pls_get_optim_keep() function. By default, the function uses the 1SD rule, but this can be disabled by setting the use_1sd_rule parameter to FALSE:\n\nso2pls_get_optim_keep(so2pls_cv_sparsity)\n#> $keepx\n#> x_1sd \n#>   100 \n#> \n#> $keepy\n#> y_1sd \n#>    25 \n#> \n#> attr(,\"datasets_name\")\n#> [1] \"rnaseq\"     \"metabolome\"\n\nso2pls_get_optim_keep(so2pls_cv_sparsity, use_1sd_rule = FALSE)\n#> $keepx\n#>   x \n#> 100 \n#> \n#> $keepy\n#>  y \n#> 40 \n#> \n#> attr(,\"datasets_name\")\n#> [1] \"rnaseq\"     \"metabolome\"\n\nThe function returns a list of vectors, which are needed for the next step of the analysis. We will save these values as a target:\n\n\ntar_target(\n  so2pls_cv_sparsity_res,\n  so2pls_get_optim_keep(so2pls_cv_sparsity)\n)\n\n\nThis list can be printed in a more reader-friendly way through the so2pls_print_cv_sparsity() function (which has been created mainly for reporting purposes), which returns a tibble containing the number of features to retain from each dataset for the different joint components:\n\nso2pls_print_cv_sparsity(tar_read(so2pls_cv_sparsity_res))\n#> # A tibble: 2 × 3\n#>   dataset    `Joint component 1` Total\n#>   <chr>                    <dbl> <dbl>\n#> 1 rnaseq                     100   100\n#> 2 metabolome                  25    25"
  },
  {
    "objectID": "so2pls.html#final-so2pls-run",
    "href": "so2pls.html#final-so2pls-run",
    "title": "9  Integration with sO2PLS",
    "section": "\n9.5 Final sO2PLS run",
    "text": "9.5 Final sO2PLS run\nOnce a value has been selected for all parameters, we can perform the final sO2PLS run. This can be done through the so2pls_o2m() function, which is a wrapper around the OmicsPLS::o2m() function. We’ll use the values selected from the different cross-validation steps to inform the parameter values:\n\n\ntar_target(\n  so2pls_final_run,\n  so2pls_o2m(\n    omicspls_input,\n    so2pls_cv_res,\n    so2pls_cv_sparsity_res\n  )\n)\n\n\nThis function returns an o2m object, which, when printed, provides a summary of the sO2PLS results:\n\ntar_load(so2pls_final_run)\n\nso2pls_final_run\n#> SO2PLS fit \n#> with 1 joint components  \n#> and  1 orthogonal components in X \n#> and  5 orthogonal components in Y \n#> Elapsed time: 0.106 sec"
  },
  {
    "objectID": "so2pls.html#results-interpretation",
    "href": "so2pls.html#results-interpretation",
    "title": "9  Integration with sO2PLS",
    "section": "\n9.6 Results interpretation",
    "text": "9.6 Results interpretation\nIn Chapter 12, we show the different functionalities implemented in the moiraine package that facilitate the interpretation of the results from an integration tool. In this section, we show some of the sO2PLS-specific plots that can be generated to help interpret the results of an sO2PLS run.\n\n9.6.1 Variance explained\nThe summary() function, when applied to an sO2PLS output, provides an overview of the variance explained by the different latent components, as well as other summary statistics:\n\nsummary(so2pls_final_run)\n#> \n#> *** Summary of the SO2PLS fit *** \n#> \n#> -  Call: OmicsPLS::o2m(X = omicspls_input[[\"rnaseq\"]], Y = omicspls_input[[\"metabolome\"]],      n = 1, nx = 1, ny = 5, sparse = TRUE, keepx = c(100), keepy = c(25)) \n#> \n#> -  Modeled variation\n#> -- Total variation:\n#> in X: 72197.01 \n#> in Y: 4566.838 \n#> \n#> -- Joint, Orthogonal and Noise as proportions:\n#> \n#>            data X data Y\n#> Joint       0.327   0.15\n#> Orthogonal  0.123   0.33\n#> Noise       0.550   0.52\n#> \n#> -- Predictable variation in Y-joint part by X-joint part:\n#> Variation in T*B_T relative to U: 0.803 \n#> -- Predictable variation in X-joint part by Y-joint part:\n#> Variation in U*B_U relative to T: 0.803 \n#> \n#> -- Variances per component:\n#> \n#>            Comp 1\n#> X joint 23617.521\n#> Y joint   684.163\n#> \n#>          Comp 1\n#> X Orth 8889.238\n#> \n#>         Comp 1  Comp 2  Comp 3  Comp 4  Comp 5\n#> Y Orth 490.457 350.282 279.931 276.203 171.812\n#> \n#> \n#> -  Coefficient in 'U = T B_T + H_U' model:\n#> -- Diagonal elements of B_T =\n#>  0.152\n\nThese statistics can be visualised with the so2pls_plot_summary() function:\n\nso2pls_plot_summary(so2pls_final_run)\n\n\n\n\nThe plot on the left shows the percentage of variation explained by the joint, orthogonal/specific and residual parts for each dataset. In our example, the joint parts explain around 33% and 15% of the variation in the transcriptomics and metabolomics datasets, respectively, while the specific components explain around 12% and 33% of the variation in each dataset. Taken together, the joint and specific parts explain 45% of the variation present in the transcriptomics dataset and 48% in the metabolomics dataset. The plot on the right depicts the percentage of joint variation of a dataset explained by the joint variation of the other dataset, i.e. it gives an indication of how correlated the joint parts of the two datasets are. In our case, the joint part of each dataset explains between 80% of the joint variation in the other dataset, which is indicative of a good covariance between the datasets.\nTo get more information about the percentage of variation explained by each individual joint or specific component, we can have a look at the screeplot generated by the so2pls_screeplot() function, which shows the percentage of variance explained by each individual joint or specific component for each dataset:\n\nso2pls_screeplot(so2pls_final_run)\n\n\n\n\n\n9.6.2 Relationship between the datasets’ joint components\nAs the joint components of the two datasets are related, we can compare the joint components’ sample scores obtained for each dataset. This can be visualised with the so2pls_compare_samples_joint_components() function. In the resulting plot, the samples can be coloured according to some information that we have about the samples. This is done by passing the MultiDataSet multi-omics object to the function through the mo_data argument, and choosing the column from the samples metadata information that will be used to colour the samples, through the colour_by argument. Note that if nothing is passed to these two arguments, all samples will have the same colour. In our case, we want to colour the samples according to their disease status, and show the feedlot with the shape of the points:\n\ntar_load(mo_set_de)\n\nso2pls_compare_samples_joint_components(\n  so2pls_final_run,\n  mo_data = mo_set_de,\n  colour_by = \"status\",\n  shape_by = \"feedlot\"\n)\n\n\n\n\nIt seems that joint component 1 is pretty consistent between the two datasets, except for one individual (an infected animal from feedlot 2 seen on the bottom-left of the plot). For both datasets, this joint component clearly separates the control and infected animals.\nNote that, since the function returns a patchwork of ggplots, it is possible to customise the colours used as follows:\n\nso2pls_compare_samples_joint_components(\n  so2pls_final_run,\n  mo_data = tar_read(mo_set),\n  colour_by = \"status\",\n  shape_by = \"feedlot\"\n) &\n  scale_colour_brewer(palette = \"Set1\")\n\n\n\n\nWe can visualise precisely how the joint components from the two datasets are related. As it is possible to express each joint component of one dataset as a linear combination of the joint components of the other dataset, we can look at the coefficients of these linear combinations. This is the purpose of the so2pls_plot_joint_components_coefficients() function. In this case, since there is only one joint component, the visualisation is not particularly useful:\n\nso2pls_plot_joint_components_coefficients(so2pls_final_run)\n\n\n\n\n\n9.6.3 Samples plots\nIn Chapter 12, different visualisations implemented in moiraine are presented to show the samples in the space spanned by the latent components. However, since in sO2PLS there is a distinction between joint and specific latent components, some convenience functions have been implemented to generate such plots for all joint or all specific components at once.\nFirst, we will focus on the joint components. The so2pls_plot_samples_joint_components() function represents the sample scores for the joint components as either violin plots (if there is only one joint component) or as a matrix of two-by-two scatter plots. Rather than displaying the sample scores separately for each dataset, it instead represents for each joint component the average of the sample scores across the two datasets. This function is based on the plot_samples_score() function (see Section 12.4), so information about the samples can be added to the plot by passing a MultiDataSet object to the function. Here, we want to visualise the samples’ health status as well as feedlot.\n\nso2pls_plot_samples_joint_components(\n  so2pls_final_run,\n  mo_data = mo_set_de,\n  colour_upper = \"status\",\n  scale_colour_upper = scale_colour_brewer(palette = \"Paired\"),\n  shape_upper = \"feedlot\"\n) +\n  theme(legend.box = \"vertical\")\n\n\n\n\nWe can clearly see that joint component 1 separates most of the control from the infected animals. Note that the function returns a ggplot, which can be further customised.\nSimilarly, the so2pls_plot_samples_specific_components() function displays the sample scores for the specific components of each dataset. Contrary to the joint components, these specific sample scores plots are independent between the two datasets, and therefore the function returns a list of plots, one for each dataset. Again, the sample scores are represented either as a violin plot (if there is only one specific component), or as scatterplots (if there are more than one specific component). Samples metadata available in the MultiDataSet object can be used to colour the samples.\n\nso2pls_plot_samples_specific_components(\n  so2pls_final_run,\n  mo_data = mo_set_de,\n  colour_upper = \"feedlot\",\n  scale_colour_upper = scale_colour_brewer(palette = \"Paired\"),\n  colour_lower = \"rnaseq_batch\",\n  shape_upper = \"gender\"\n) |> \n  ## customising legend for each plot\n  map(\\(x) x + theme(legend.box = \"vertical\"))\n#> Warning in plot_samples_score(method_output, ld_list[[.x]], ...): Only one\n#> latent dimension to plot; 'colour_diag', 'colour_lower' and 'shape_lower'\n#> argument will be ignored.\n#> $rnaseq\n\n\n\n#> \n#> $metabolome\n\n\n\n\nThe transcriptomics specific components plots are harder to read as there are 8 of them, but it looks like for both datasets the specific components are not representing variation due to covariates such as gender or feedlot."
  },
  {
    "objectID": "so2pls.html#recap-targets-list",
    "href": "so2pls.html#recap-targets-list",
    "title": "9  Integration with sO2PLS",
    "section": "\n9.7 Recap – targets list",
    "text": "9.7 Recap – targets list\nFor convenience, here is the list of targets that we created in this section:\n\nTargets list for sO2PLS analysis\n\n\nlist(\n  ## Creating sO2PLS input\n  tar_target(\n    omicspls_input,\n    get_input_omicspls(\n      mo_presel_supervised,\n      datasets = c(\"rnaseq\", \"metabolome\")\n    )\n  ),\n  \n  ## Adjusted cross-validation for number of components\n  tar_target(\n    so2pls_cv_adj,\n    so2pls_crossval_o2m_adjR2(\n      omicspls_input,\n      a = 1:5,\n      ax = seq(0, 10, by = 2),\n      ay = seq(0, 10, by = 2),\n      nr_folds = 10,\n      nr_cores = 6,\n      seed = 127\n    )\n  ),\n  tar_target(\n    so2pls_cv_adj_res,\n    so2pls_get_optim_ncomp_adj(so2pls_cv_adj)\n  ),\n  \n  ## Plotting adjusted cross-validation results\n  tar_target(\n    so2pls_cv_adj_plot,\n    so2pls_plot_cv_adj(so2pls_cv_adj)\n  ),\n  \n  ## Standard cross-validation for number of components\n  tar_target(\n    so2pls_cv,\n    so2pls_crossval_o2m(\n      omicspls_input,\n      so2pls_cv_adj,\n      nr_folds = 10,\n      nr_cores = 6,\n      seed = 356\n    )\n  ),\n  tar_target(\n    so2pls_cv_res,\n    so2pls_get_optim_ncomp(so2pls_cv)\n  ),\n  \n  ## Plotting standard cross-validation results\n  tar_target(\n    so2pls_cv_plot,\n    so2pls_plot_cv(so2pls_cv)\n  ),\n  \n  ## Cross-validation for sparsity parameters\n  tar_target(\n    so2pls_cv_sparsity,\n    so2pls_crossval_sparsity(\n      omicspls_input,\n      n = so2pls_cv_res[\"n\"],\n      nx = so2pls_cv_res[\"nx\"],\n      ny = so2pls_cv_res[\"ny\"],\n      nr_folds = 10,\n      keepx_seq = c(seq(5, 30, 5), seq(40, 100, 10)),\n      keepy_seq = c(seq(5, 40, 5))\n    )\n  ),\n  tar_target(\n    so2pls_cv_sparsity_res,\n    so2pls_get_optim_keep(so2pls_cv_sparsity)\n  ),\n  \n  ## Plotting the results of the cross-validation for the number of features\n  ## to retain from each dataset for the different joint components\n  tar_target(\n    so2pls_cv_sparsity_plot,\n    so2pls_plot_cv_sparsity(so2pls_cv_sparsity)\n  ),\n  \n  ## Extracting sparsity results in table format\n  tar_target(\n    so2pls_cv_sparsity_table,\n    so2pls_print_cv_sparsity(so2pls_cv_sparsity_res)\n  ),\n  \n  ## Final sO2PLS run\n  tar_target(\n    so2pls_final_run,\n    so2pls_o2m(\n      omicspls_input,\n      so2pls_cv_res,\n      so2pls_cv_sparsity_res\n    )\n  ),\n  \n  ## Summary plot of percentage of variance explained\n  tar_target(\n    so2pls_summary_plot,\n    so2pls_plot_summary(so2pls_final_run)\n  ),\n  \n  ## Screeplot\n  tar_target(\n    so2pls_screeplot,\n    so2pls_screeplot(so2pls_final_run)\n  ),\n  \n  ## Comparison of samples score for joint components\n  tar_target(\n    so2pls_joint_components_comparison_plot,\n    so2pls_compare_samples_joint_components(\n      so2pls_final_run,\n      mo_data = mo_set_de,\n      colour_by = \"status\",\n      shape_by = \"feedlot\"\n    )\n  ),\n  \n  ## Coefficient plot for joint components\n  tar_target(\n    so2pls_joint_components_coefficients_plot,\n    so2pls_plot_joint_components_coefficients(so2pls_final_run)\n  ),\n  \n  ## Joint component samples score plot\n  tar_target(\n    so2pls_joint_components_samples_score_plot,\n    so2pls_plot_samples_joint_components(\n      so2pls_final_run,\n      mo_data = mo_set_de,\n      colour_upper = \"status\",\n      scale_colour_upper = scale_colour_brewer(palette = \"Paired\"),\n      shape_upper = \"feedlot\"\n    ) +\n      theme(legend.box = \"vertical\")\n  ),\n  \n  ## Specific components samples score plot\n  tar_target(\n    so2pls_specific_components_samples_score_plot,\n    so2pls_plot_samples_specific_components(\n      so2pls_final_run,\n      mo_data = mo_set_de,\n      colour_upper = \"feedlot\",\n      scale_colour_upper = scale_colour_brewer(palette = \"Paired\"),\n      colour_lower = \"rnaseq_batch\",\n      shape_upper = \"gender\"\n    ) |> \n      map(\\(x) x + theme(legend.box = \"vertical\"))\n  )\n)\n\n\n\n\n\n\nBouhaddani, Said el, Hae-Won Uh, Geurt Jongbloed, Caroline Hayward, Lucija Klarić, Szymon M. Kiełbasa, and Jeanine Houwing-Duistermaat. 2018. “Integrating Omics Datasets with the OmicsPLS Package.” BMC Bioinformatics 19 (1): 371. https://doi.org/10.1186/s12859-018-2371-3.\n\n\nGu, Zhujie, Said el Bouhaddani, Jiayi Pei, Jeanine Houwing-Duistermaat, and Hae-Won Uh. 2021. “Statistical Integration of Two Omics Datasets Using GO2PLS.” BMC Bioinformatics 22 (1): 131. https://doi.org/10.1186/s12859-021-03958-3."
  },
  {
    "objectID": "mofa.html#what-is-mofa",
    "href": "mofa.html#what-is-mofa",
    "title": "10  Integration with MOFA",
    "section": "\n10.1 What is MOFA?",
    "text": "10.1 What is MOFA?\nMOFA (for Multi-Omics Factor Analysis) is a method for the unsupervised integration of two or more omics datasets. It aims at uncovering the main axes of variations shared by all or a subset of the datasets, through the construction of a small number of latent factors. It can be assimilated to a generalisation of the PCA (Principal Components Analysis) to multiple datasets. The latent factors are constructed as sparse linear combinations of the omics features, highlighting the features that contribute to each axis of variation.\nMOFA uses a Bayesian framework to decompose each dataset (referred to as “view” in the package documentation) into the product of a latent factor matrix (representing to the main axes of variation) and a matrix of feature weights (indicating the extent to which the features contribute to the different latent factors). MOFA applies two levels of sparsity. The first level of sparsity is used to detect whether a given latent factor is active (i.e. explains variation) in each dataset. This allows to assess which sources of variations are shared across the datasets. The second level of sparsity is applied to the features, allowing to assess which features contribute to each source of variation.\nMOFA requires as input matrices of omics measurements that must have at least some samples in common, but accepts some samples being absent from some of the datasets. It is recommended to have at least 15 samples in common across the datasets in order to obtain sensible results. The number of features in each dataset must not be too small (i.e. at least 15). It is critical that each dataset is properly normalised, with batch effects removed. In addition, it is strongly recommended that the datasets are pre-filtered to retain highly variable features; a similar number of features should be retained across the datasets. Missing values are not a problem with MOFA. MOFA can also accept samples and features metadata as data-frames. Lastly, there is a number of parameters that can be customised. The most important ones will be mentioned in this chapter; for a complete list see the MOFA tutorial.\n\n\n\n\n\n\nNote\n\n\n\nA characteristic of the MOFA2 package is that the model training part of the analysis is done in Python with the mofapy2 module. MOFA2 interacts with Python from R with the reticulate package. This is important to know as it might affect the installation and run depending on the environment in which it is used.\n\n\n\n10.1.1 A note on groups in MOFA\nMOFA offers the option to assign samples to groups (referred to as the multi-group framework within MOFA). It is important to understand what this does before using it. In particular, if the aim of the analysis is to find features that separate samples based on a grouping, you should not use this multi-group framework. By setting sample groups in MOFA, it will ignore sources of variations that discriminate the groups. Instead, this multi-group framework will seek sources of variations that are shared between the different groups, and sources of variations that are exclusive to a specific group. For example, in this analysis, the multi-group framework was used to split samples (cells) based on their developmental stage. The goal of the analysis was to find coordinated variation between the different datasets, and detect at which developmental stage (i.e. in which group) it occurred, rather than trying to differentiate the different developmental stages.\n\n10.1.2 MEFISTO\nMEFISTO is an extension of MOFA that explicitly accounts for some continuous structure amongst the samples, i.e. temporal or 2D spatial relationships between the observations. The constructed latent factors’ associated with the covariate is assessed, to see whether they represent smooth variation which correlates with the covariate, or whether they are independent of the covariate. The trained model can then be used to extrapolate to unseen values of the covariate (e.g. missing time-points or physical locations). When using the multi-group framework, MEFISTO can also align the values of the covariate between the different groups, for example to account for differences in developmental speed between two groups of patients."
  },
  {
    "objectID": "mofa.html#creating-the-mofa-input",
    "href": "mofa.html#creating-the-mofa-input",
    "title": "10  Integration with MOFA",
    "section": "\n10.2 Creating the MOFA input",
    "text": "10.2 Creating the MOFA input\nThe first step is to transform the MultiDataSet object into a suitable format for the MOFA2 package. This is done through the get_input_mofa() function. In addition to the MultiDataSet object, this function accepts as arguments:\n\ndatasets: a vector of dataset names that dictates which datasets from the multi-omics set should be included in the analysis (by default, all datasets are included);\ngroups: the name of the column in the samples metadata to be used as group indicator if using the multi-group framework (if not set, the multi-group framework will not be used);\noptions_list: a list of options to customise the MOFA model – more information below;\nonly_common_samples: whether only the samples present in all datasets should be retained. The default value is FALSE; this argument should be set to TRUE when some datasets contain many more samples than others; when only a few samples are missing from some of the datasets, it is ok to leave it to FALSE.\n\nWe expand on the options that can be set with the options_list argument below.\n\n10.2.1 MOFA parameters\nMOFA has three type of parameters (referred to as options) that the user can control.\n\n10.2.1.1 Data options\nThese are options for data handling when creating the MOFA model. The two important options are:\n\nscale_views: logical, whether the datasets (views) should be scaled to unit variance. The default is FALSE, but it is recommended to set it to TRUE if the scale difference between the datasets is high.\nscale_groups: logical, whether to scale the groups to unit variance. Irrelevant unless using the multi-group framework. The default is FALSE, but it is recommended to set it to TRUE if the scale difference between the groups is high.\n\nSee the documentation for get_default_data_options() for a full list.\n\n10.2.1.2 Model options\nThese are the options defining different aspects of the MOFA model. The most important ones are:\n\nnum_factors: The maximum number of factors to construct (note that this is a maximum, i.e. MOFA can return a lower number of factors if there is not a lot of variation in the datasets). The default is set to 15, which is a good start. This can be adjusted after running MOFA with the default value.\nlikelihoods: Named character vector, the type of likelihood to use for each dataset. MOFA offers three options: Gaussian likelihood ('gaussian') for continuous data, Bernoulli likelihood ('bernoulli') for binary data, and Poisson likelihood ('poisson') for count data. It is highly recommended to transform the datasets in order to use a Gaussian likelihood: for example, applying a variance-stabilising transformation on RNAseq data rather than using the raw read counts with a Poisson likelihood. By default, a Gaussian likelihood is chosen for all datasets.\n\nSee the documentation for get_default_model_options() for a full list.\n\n10.2.1.3 Training options\nThese are the options that control how the model is trained. The most important one is:\n\n\nseed: setting the random seed. This is standard practice, to make sure that the results are reproducible.\n\nSee the documentation for get_default_training_options() for a full list.\n\n10.2.1.4 Passing the parameters to get_input_mofa\n\nWhen creating a MOFA input object with get_input_mofa(), all options will be set to their default values. It is possible to customise the values for some of the options through the options_list parameter. This should be a named list, with up to three elements (one per type of options that MOFA accepts): data_options, model_options, and training_options. Each element is itself a named list, where each element of the list corresponds to a specific option. All three elements do not have to be present; for example, if we want to only specify a value for the model option num_factors, we can set options_list to:\n\nlist(\n  model_options = list(num_factors = 10)\n)\n\nIf we also want to set the likelihoods and the random seed, then options_list becomes:\n\nlist(\n  model_options = list(num_factors = 10),\n  training_options = list(seed = 43)\n)\n\nFor our example, we’ll make sure that each dataset is scaled to unit variance, and that a Poisson likelihood is used for the genomics data, for which we have variants dosage. Since there are only 9 samples that are not present in all omics datasets, we can keep them in the analysis. We’ll set the random seed to ensure that the results are reproducible:\n\n\ntar_target(\n  mofa_input,\n  get_input_mofa(\n    mo_presel_supervised,\n    options_list = list(\n      data_options = list(scale_views = TRUE),\n      model_options = list(likelihoods = c(\n        \"snps\" = \"poisson\",\n        \"rnaseq\" = \"gaussian\",\n        \"metabolome\" = \"gaussian\")\n      ),\n      training_options = list(seed = 43)\n    ),\n    only_common_samples = FALSE\n  )\n)\n\n\nThis will produce a warning:\n\n#> Warning: Dataset snps is to be modelled with a poisson likelihood, but is not\n#> integer. Transforming to integer.\n\nThe warning informs us that we have chosen to use a Poisson likelihood for the genomics dataset, but the latter does not have integer data. This is because the missing values imputed with NIPALS-PCA (see Section 6.2.3) are continuous rather than discrete. This is taken care of by automatically rounding the dataset; but in other settings this warning can be an indication that the Poisson likelihood is not appropriate for the dataset.\n\n\n\n\n\n\nNote\n\n\n\nWhen constructing the MOFA object, if there exists a column named group in a samples metadata table in the MultiDataSet object, the column will be renamed as group_metadata in the resulting MOFA input object. This is because MOFA needs a group column its own version of the samples metadata (for the multi-group framework), so there cannot be another column named group. Note that will have no effect on the MultiDataSet object, but is important to remember if you want to use some of the plotting functionalities that MOFA2 offers.\n\n\nThe output of the get_input_mofa() function is a MOFA object, more specifically an untrained model:\n\ntar_load(mofa_input)\nmofa_input\n#> Untrained MOFA model with the following characteristics: \n#>  Number of views: 3 \n#>  Views names: snps rnaseq metabolome \n#>  Number of features (per view): 1000 994 55 \n#>  Number of groups: 1 \n#>  Groups names: group1 \n#>  Number of samples (per group): 144 \n#> \n\nWe did not use the multi-group framework, so there is only one samples group.\n\n10.2.2 MEFISTO input\nIn a similar way, we can construct the input object for a MEFISTO run with the get_input_mefisto() function. It is very similar to get_input_mofa(), except that is expects as second argument the name or names of the columns in the samples metadata tables corresponding to the continuous covariate(s) which represent(s) the structure amongst the samples. Note that there can be at most two covariates. For example, if we had a time-series dataset with information about the time at which each observation was taken in a column called time, we would use:\n\n\ntar_target(\n  mefisto_input,\n  get_input_mefisto(\n    mo_presel_supervised,\n    \"time\",\n    options_list = list(\n      data_options = list(scale_views = TRUE),\n      model_options = list(likelihoods = c(\n        \"snps\" = \"poisson\",\n        \"rnaseq\" = \"gaussian\",\n        \"metabolome\" = \"gaussian\")\n      ),\n      training_options = list(seed = 43)\n    ),\n    only_common_samples = FALSE\n  )\n)\n\n\nMEFISTO has some specific options that can be set in a similar way to the data, model and training options for MOFA. The most important are:\n\nwarping: Logical, whether the covariate(s) should be aligned between the groups. Only when using the multi-group framework.\nwarping_ref: Character, if using the warping option, the name of the group that should be used as reference (the covariates for the other groups will be aligned to the covariates for this group).\nnew_values: Numeric vector, values of the covariate(s) for which the factors should be predicted (for inter/extrapolation).\n\nTo set any of these options, they can be passed as a list to the options_list parameter as for the data, model and training options."
  },
  {
    "objectID": "mofa.html#visualising-the-mofa-input",
    "href": "mofa.html#visualising-the-mofa-input",
    "title": "10  Integration with MOFA",
    "section": "\n10.3 Visualising the MOFA input",
    "text": "10.3 Visualising the MOFA input\nIt is possible to represent the samples that are present or missing across the different datasets with the plot_data_overview() function implemented in MOFA2:\n\nplot_data_overview(mofa_input)\n\n\n\n\nThe plot generated shows the dimensions of the datasets that will be analysed.\nFor reporting purposes, it can also be useful to summarise the different options used to create the MOFA model. This can be done with the options_list_as_tibble() function, which turns a list of parameters into a tibble presenting the name and value of each parameter. For example, we can list the data options used:\n\noptions_list_as_tibble(mofa_input@data_options)\n#> # A tibble: 6 × 2\n#>   Parameter     Value                         \n#>   <chr>         <chr>                         \n#> 1 scale_views   TRUE                          \n#> 2 scale_groups  FALSE                         \n#> 3 center_groups TRUE                          \n#> 4 use_float32   TRUE                          \n#> 5 views         'snps', 'rnaseq', 'metabolome'\n#> 6 groups        group1"
  },
  {
    "objectID": "mofa.html#training-the-model",
    "href": "mofa.html#training-the-model",
    "title": "10  Integration with MOFA",
    "section": "\n10.4 Training the model",
    "text": "10.4 Training the model\nOnce we have prepared our MOFA input, we can train the model with the run_mofa() function (from the MOFA2 package). This is done through Python, so there might be some issues when trying to run the function for the first time after installing MOFA2 if the configuration is not correct. If that is the case, see the MOFA2 tutorial (e.g. their troubleshooting section) for tips on how to solve this.\nBy default, the function will save the resulting trained model in a temporary file, with the .hdf5 format. It can be preferable to save the result into the output folder of your project; here as we are using targets to save the results of each step of the analysis, we do not need to do so. In addition, is it strongly recommended to set the save_data parameter to TRUE, as otherwise without the data, some of the visualisation options might not be available. Lastly, the use_basilisk parameter might have to be switched to FALSE if there are any issues with calling the Python module:\n\n\ntar_target(\n  mofa_trained,\n  run_mofa(\n    mofa_input,\n    save_data = TRUE,\n    use_basilisk = TRUE\n  )\n)\n\n\nIn our case, the following warnings are returned:\n\n#> Warning: No output filename provided. Using tmpRtmpirYcNYmofa_20240222151639.hdf5 to store the trained model.\n#> \n#> Factors 1 are strongly correlated with the total number of expressed features for at least one of your omics. Such factors appear when there are differences in the total levels between your samples, sometimes because of poor normalisation in the preprocessing steps.\n\nThe first one has to do with saving the model into a temporary file. We will explain the others in more detail when analysing the resulting model.\nThe output of the function is a trained MOFA model, with 15 latent factors:\n\ntar_load(mofa_trained)\nmofa_trained\n#> Trained MOFA with the following characteristics: \n#>  Number of views: 3 \n#>  Views names: snps rnaseq metabolome \n#>  Number of features (per view): 1000 994 55 \n#>  Number of groups: 1 \n#>  Groups names: group1 \n#>  Number of samples (per group): 144 \n#>  Number of factors: 15"
  },
  {
    "objectID": "mofa.html#results-interpretation",
    "href": "mofa.html#results-interpretation",
    "title": "10  Integration with MOFA",
    "section": "\n10.5 Results interpretation",
    "text": "10.5 Results interpretation\nIn Chapter 12, we show the different functionalities implemented in the moiraine package that facilitate the interpretation of the results from an integration tool. In this section, we show some of the MOFA-specific plots that can be generated to help interpret the results of a MOFA run.\n\n10.5.1 Variance explained\nWhen training the model, MOFA2 constructs latent factors, which are sparse combination of the features, and which represent main axes of variation shared across all or a subsets of the datasets. One of the first steps to take when analysing the trained model is to assess the amount of variance in the datasets explained by each factor; similarly to what we would do when running a PCA.\nThe function plot_variance_explained() from MOFA2 displays the percentage of variance in each dataset explained by each factor as a heatmap. The x and y arguments (and also split_by argument when using the multi-group framework) control whether the factors or the datasets should be represented as the rows or columns in the heatmap:\n\nplot_variance_explained(\n  mofa_trained,\n  x = \"view\",  ## datasets on the x-axis\n  y = \"factor\" ## factors on the y-axis\n) \n\n\n\n\nHere, we see that factor 1 explains a lot (almost 50%) of variation in the transcriptomics dataset, a little (around 10%) in the metabolomics dataset and almost none in the genomics dataset. Factor 2 explains around 20% of variation in the genomics dataset, and none in the other datasets. Factors 3 and 4 seem specific to the transcriptomics datasets, and factors 5 to 15 explain very little variation; seeing this, we could re-train the MOFA model by setting the number of factors to 4 or 5.\nIn addition, the plot_variance_explained() function can create a second plot displaying the total percentage of variance explained by all the factors for each dataset, if the argument plot_total is set to TRUE :\n\nplot_variance_explained(\n  mofa_trained,\n  x = \"view\",\n  y = \"factor\",\n  plot_total = TRUE\n)[[2]] ## show only the 2nd plot\n\n\n\n\nThe factors explain almost 85% of the variation in the transcriptomics dataset, but less than 30% in in the genomics and metabolomics datasets.\n\n10.5.2 Correlation between factors\nBefore moving to the interpretation, it is always good practice to check the correlation between the different computed factors. All factors should be mostly uncorrelated; if a large correlation is observed between some factors, it could be an indication of poor model fit, either because too many factors were computed (in this case, try reducing the number of factors to compute or increasing the number of iterations for the model training via the convergence_mode training option) or maybe because of an improper normalisation of the datasets. The function plot_factor_cor() from MOFA2 displays the correlation between all factors via the corrplot::corrplot() function:\n\nplot_factor_cor(\n  mofa_trained,\n  type = \"upper\",\n  diag = FALSE,\n  tl.cex = 0.8\n)\n\n\n\n\nThere is a moderate positive correlation between factors 2 and 5, but nothing to be concerned about.\n\n10.5.3 Correlation between factors and samples covariates\nTo assess which sources of variation each factor is representing, we can check whether the factors are correlated with some known covariates that were recorded in the samples metadata. The mofa_plot_cor_covariates() function displays the correlation between each factor and the samples covariates. Note that factor covariates are transformed to numerical group indicators in order to compute the correlations. This function is similar to the MOFA2 function correlate_factors_with_covariates() except that it returns a ggplot (rather than creating a base R plot), and offers a few convenient features through the optional arguments. By default, the function uses all covariates recorded in the samples metadata; however we can focus on a subset of them by passing the column names to the covariates argument.\n\nmofa_plot_cor_covariates(\n  mofa_trained\n)\n\n\n\n\nFrom this plot, we can spot some interesting trends. For example, factor 1, which explains variation in the transcriptomics and metabolomics datasets, is strongly correlated with disease status. It makes sense, since the transcriptomics dataset has been filtered to retain genes most associated with differences between healthly and infected animals, so we expect it to be the strongest source of variation in the dataset. Factor 2, which explains variation only in the genomics dataset, is strongly correlated with the genomics composition of the animals, which makes a lot of sense as more related individuals share similar genomics profiles. It also makes sense that this variation is less present in the other two datasets. Factor 5, which explains variation only in the transcriptomics dataset, seems to be modestly correlated with the RNASeq batches.\nIn general, it is a good idea to interpret this correlation plot together with the plot representing the percentage of variation explained in the datasets by each factor. However, it is necessary to investigate more before making claims about what the factors are representing.\n\n10.5.4 Visualising the top features\nThe MOFA2 package offers a number of very useful visualisations to further interpret the results. For example, for a given factor and dataset of interest, we can visualise how the top contributing features vary with the factor values (i.e. the sample scores). For example, let’s have a look at the top contributing features from the transcriptomics dataset for factor 1:\n\nplot_data_scatter(\n  mofa_trained,\n  factor = 1,\n  view = \"rnaseq\",\n  features = 6,\n  color_by = \"status\",\n  shape_by = \"feedlot\"\n)\n\n\n\n\nFor all six genes, their expression is higher in infected animals compared with healthy ones.\nWe can also visualise the measurements of the top contributing features across the samples as a heatmap, for a given dataset and factor. That the annotation_samples argument allows us to add annotations on top of the heatmap to represent certain characteristics of the samples. For example here we’ll add information about the phenotype group and chromosome:\n\nMOFA2::plot_data_heatmap(\n  mofa_trained,\n  factor = 1,\n  view = \"rnaseq\",\n  features = 20,\n  annotation_samples = \"status\",\n  fontsize_col = 5\n)\n\n\n\n\nNote that moiraine implements similar functions to represent the top contributing features, as we will see in Chapter 12."
  },
  {
    "objectID": "mofa.html#recap-targets-list",
    "href": "mofa.html#recap-targets-list",
    "title": "10  Integration with MOFA",
    "section": "\n10.6 Recap – targets list",
    "text": "10.6 Recap – targets list\nFor convenience, here is the list of targets that we created in this section:\n\nTargets list for MOFA analysis\n\n\nlist(\n  ## Creating MOFA input\n  tar_target(\n    mofa_input,\n    get_input_mofa(\n      mo_presel_supervised,\n      options_list = list(\n        data_options = list(scale_views = TRUE),\n        model_options = list(likelihoods = c(\n          \"snps\" = \"poisson\",\n          \"rnaseq\" = \"gaussian\",\n          \"metabolome\" = \"gaussian\")\n        ),\n        training_options = list(seed = 43)\n      ),\n      only_common_samples = FALSE\n    )\n  ),\n  \n  ## Overview plot of the samples in each dataset\n  tar_target(\n    mofa_input_plot,\n    plot_data_overview(mofa_input)\n  ),\n  \n  ## Training MOFA model\n  tar_target(\n    mofa_trained,\n    run_mofa(\n      mofa_input,\n      save_data = TRUE,\n      use_basilisk = TRUE\n    )\n  ),\n  \n  ## Formatting MOFA output\n  tar_target(\n    mofa_output,\n    get_output(mofa_trained)\n  ),\n  \n  ## Plots of variance explained\n  tar_target(\n    mofa_var_explained_plot,\n    plot_variance_explained(\n      mofa_trained,\n      x = \"view\",  ## datasets on the x-axis\n      y = \"factor\" ## factors on the y-axis\n    )\n  ),\n  tar_target(\n    mofa_total_var_explained_plot,\n    plot_variance_explained(\n      mofa_trained,\n      x = \"view\",\n      y = \"factor\",\n      plot_total = TRUE\n    )[[2]]\n  ),\n  \n  ## Plot of factors correlation with covariates\n  tar_target(\n    mofa_factors_covariates_cor_plot,\n    mofa_plot_cor_covariates(mofa_trained)\n  )\n)"
  },
  {
    "objectID": "diablo.html#what-is-diablo",
    "href": "diablo.html#what-is-diablo",
    "title": "11  Integration with DIABLO",
    "section": "\n11.1 What is DIABLO?",
    "text": "11.1 What is DIABLO?\nDIABLO (for Data Integration Analysis for Biomarker discovery using Latent Components) is a multivariate approach to perform supervised data integration. Given two or more omics datasets for which measurements are taken on the same samples, DIABLO aims at selecting correlated features across the datasets that best discriminate between the different sample groups for a categorical outcome of interest.\nDIABLO works by iteratively constructing linear combinations of the features, called latent components, which maximise the correlation between the datasets and with the categorical outcome. In order to perform feature selection, the latent components are subjected to \\(L1\\)-regularisation (or LASSO), i.e. the number of features included in the linear combination is constrained by the user. Moreover, the optimisation problem is weighted to allow the user to control the balance between maximising the correlation between omics datasets and discriminating between the outcome groups of interest.\nDIABLO requires as input the matrices of omics measurements, all with the same samples, as well as a factor variable indicating the outcome group for each sample. While the omics datasets are automatically centred and scaled by DIABLO, proper preprocessing and normalisation is assumed to be carried out by the user. Although the DIABLO algorithm can handle the presence of missing features, it will prohibit the use of cross-validation. It is thus recommended to perform data imputation prior to running a DIABLO analysis. Importantly, DIABLO tends to perform better when the number of features in the datasets is not too large. Therefore, it is highly recommended to perform some prefiltering prior to using DIABLO."
  },
  {
    "objectID": "diablo.html#creating-the-diablo-input",
    "href": "diablo.html#creating-the-diablo-input",
    "title": "11  Integration with DIABLO",
    "section": "\n11.2 Creating the DIABLO input",
    "text": "11.2 Creating the DIABLO input\nThe first step is to transform the MultiDataSet object into a suitable format for the mixOmics package. This is done with the get_input_mixomics_supervised() function, which takes as input:\n\na MultiDataSet object,\nthe name of the column in the samples metadata table that corresponds to the categorical outcome of interest,\noptionally, the names of the datasets to include in the analysis. This is useful if we want to exclude one of more datasets from the analysis.\n\nIn our case, we want to find differences between the healthy and diseased animals. We will use the multi-omics datasets that have gone through supervised prefiltering (i.e. we discarded the features least related with the disease status, as seen in Chapter 7).\n\n\ntar_target(\n  diablo_input,\n  get_input_mixomics_supervised(\n    mo_presel_supervised,\n    group = \"status\"\n  )\n)\n\n\nImportantly, the get_input_mixomics_supervised() function only retains samples that are present in all omics datasets to be analysed. It also makes sure that the column provided as categorical outcome does not contain numerical values, as DIABLO can only handle categorical outcome. If the column contains integers, they will be considered as levels of a factor.\nThe result of the function is a named list with one element per dataset to integrate, plus a Y element that contains the categorical outcome. The omics datasets are stored as matrices with samples as rows and features as columns; the categorical outcome is a named factor vector.\n\ntar_load(diablo_input)\nstr(diablo_input)\n#> List of 4\n#>  $ snps      : num [1:135, 1:1000] 2 1 2 2 2 2 1 2 2 2 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : chr [1:135] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n#>   .. ..$ : chr [1:1000] \"21-25977541-C-T-rs41974686\" \"22-51403583-A-C-rs210306176\" \"24-12959068-G-T-rs381471286\" \"8-85224224-T-C-rs43565287\" ...\n#>   ..- attr(*, \"datatype\")= chr \"SnpSet\"\n#>   .. ..- attr(*, \"package\")= chr \"Biobase\"\n#>  $ rnaseq    : num [1:135, 1:994] 3.87 4.97 4.08 3.49 3.49 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : chr [1:135] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n#>   .. ..$ : chr [1:994] \"ENSBTAG00000000020\" \"ENSBTAG00000000046\" \"ENSBTAG00000000056\" \"ENSBTAG00000000061\" ...\n#>   ..- attr(*, \"datatype\")= chr \"ExpressionSet\"\n#>   .. ..- attr(*, \"package\")= chr \"Biobase\"\n#>  $ metabolome: num [1:135, 1:55] 3.19 3.28 3.22 3.72 3.63 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ : chr [1:135] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ...\n#>   .. ..$ : chr [1:55] \"HMDB00001\" \"HMDB00008\" \"HMDB00042\" \"HMDB00043\" ...\n#>   ..- attr(*, \"datatype\")= chr \"MetabolomeSet\"\n#>   .. ..- attr(*, \"package\")= chr \"moiraine\"\n#>  $ Y         : Factor w/ 2 levels \"BRD\",\"Control\": 2 2 2 2 1 2 2 2 2 2 ...\n#>   ..- attr(*, \"names\")= chr [1:135] \"R21\" \"Y3660\" \"Y3243\" \"R5764\" ..."
  },
  {
    "objectID": "diablo.html#constructing-the-design-matrix",
    "href": "diablo.html#constructing-the-design-matrix",
    "title": "11  Integration with DIABLO",
    "section": "\n11.3 Constructing the design matrix",
    "text": "11.3 Constructing the design matrix\nDIABLO relies on a design matrix to balance its two optimisation objectives: maximising the covariance between the omics datasets, and maximising the discrimination between the outcome categories. The design matrix is a matrix with one row and one column per dataset, plus a row and a column for the \"Y\" dataset, i.e. the categorical outcome. The values within each cell of the matrix indicate the ratio between the two objectives for this combination of dataset. A value of 0 means that we want to prioritise outcome discrimination, while a value of 1 indicates that we want to prioritise maximising the covariance between the two corresponding datasets. All values must be between 0 and 1.\nThere are two options for constructing the design matrix, which we present below.\n\n11.3.1 Predefined design matrices\nA first option is to choose a strategy based on what we are trying to obtain from the integration:\n\nif we want to strike a balance between the two objectives (recommended option), we’ll constructed a “weighted full” design matrix that looks like this:\n\n\ndiablo_predefined_design_matrix(names(diablo_input), \"weighted_full\")\n#>            snps rnaseq metabolome Y\n#> snps        0.0    0.1        0.1 1\n#> rnaseq      0.1    0.0        0.1 1\n#> metabolome  0.1    0.1        0.0 1\n#> Y           1.0    1.0        1.0 0\n\n\nif we want to maximise the discrimination between the outcome categories, we’ll construct a “null” design matrix that looks like this:\n\n\ndiablo_predefined_design_matrix(names(diablo_input), \"null\")\n#>            snps rnaseq metabolome Y\n#> snps          0      0          0 1\n#> rnaseq        0      0          0 1\n#> metabolome    0      0          0 1\n#> Y             1      1          1 0\n\n\nif we want only to maximise the covariance between the datasets, we’ll construct a “full” design matrix that looks like this:\n\n\ndiablo_predefined_design_matrix(names(diablo_input), \"full\")\n#>            snps rnaseq metabolome Y\n#> snps          0      1          1 1\n#> rnaseq        1      0          1 1\n#> metabolome    1      1          0 1\n#> Y             1      1          1 0\n\nWe will show how to use these pre-defined design matrices when running DIABLO.\n\n11.3.2 Estimating the design matrix through pairwise PLS\nAlternatively, we can let the data guide the construction of the design matrix. This is achieved by assessing the correlation between each pair of datasets, through a PLS (Projection to Latent Structures) run. More specifically, the correlation between the datasets is computed as the correlation coefficient between the first component constructed for each dataset during the PLS run. Then, based on the correlation obtained between a pair of dataset, we can decide on a value to use for the design matrix. Typically, the following thresholds are recommended by the authors of the mixOmics package:\n\ncorrelation coefficient of 0.8 or above between two datasets: assign a value of 1 in the corresponding cell of the design matrix;\ncorrelation coefficient below 0.8: assign a value of 0.1 in the corresponding cell of the design matrix.\n\nThe diablo_pairwise_pls_factory() function automates this process. It takes as input the DIABLO input object that we constructed previously:\n\n\ndiablo_pairwise_pls_factory(diablo_input)\n\n\nThe function works as follows:\n\nIt creates a list of all possible pairs of datasets, which is stored in the diablo_pairs_datasets target:\n\n\ntar_read(diablo_pairs_datasets)\n#> [[1]]\n#> [1] \"snps\"   \"rnaseq\"\n#> \n#> [[2]]\n#> [1] \"snps\"       \"metabolome\"\n#> \n#> [[3]]\n#> [1] \"rnaseq\"     \"metabolome\"\n\n\nIt uses dynamic branching to perform a PLS run on each pair of datasets, via the run_pairwise_pls() function. The results are stored as a list in the diablo_pls_runs_list target. Each element of the list has a datasets_name attribute to indicate which datasets were analysed:\n\n\nmap(tar_read(diablo_pls_runs_list), attr, \"datasets_name\")\n#> $diablo_pls_runs_list_05fb1980\n#> [1] \"snps\"   \"rnaseq\"\n#> \n#> $diablo_pls_runs_list_1b4ec539\n#> [1] \"snps\"       \"metabolome\"\n#> \n#> $diablo_pls_runs_list_4f48d450\n#> [1] \"rnaseq\"     \"metabolome\"\n\n\nIt constructs the estimated correlation matrix between the datasets, based on the results of the PLS runs, via the diablo_get_pairwise_pls_corr() function. The resulting matrix is available through the diablo_pls_correlation_matrix target:\n\n\ntar_read(diablo_pls_correlation_matrix)\n#>                 snps    rnaseq metabolome\n#> snps       1.0000000 0.6474490  0.6263349\n#> rnaseq     0.6474490 1.0000000  0.8607195\n#> metabolome 0.6263349 0.8607195  1.0000000\n\n\nIt constructs the design matrix according to the datasets correlation matrix, through the diablo_generate_design_matrix() function. This function has parameters to customise how the correlation matrix should be translated into a design matrix, notably by setting the threshold to use on the correlation coefficients (default is 0.8, as recommended). These arguments can be customised in the diablo_pairwise_pls_factory() function. The resulting design function is stored in the target diablo_design_matrix:\n\n\ntar_read(diablo_design_matrix)\n#>            snps rnaseq metabolome Y\n#> snps        0.0    0.1        0.1 1\n#> rnaseq      0.1    0.0        1.0 1\n#> metabolome  0.1    1.0        0.0 1\n#> Y           1.0    1.0        1.0 0\n\n\nConverting targets factory to R script\n\ndiablo_pairs_datasets <- utils::combn(\n  setdiff(names(diablo_input), \"Y\"),\n  2, \n  simplify = FALSE\n)\n\ndiablo_pls_runs_list <- diablo_pairs_datasets |> \n  map(\\(x) run_pairwise_pls(diablo_input, x))\n\ndiablo_pls_correlation_matrix <- diablo_get_pairwise_pls_corr(diablo_pls_runs_list)\n\ndiablo_design_matrix <- diablo_generate_design_matrix(diablo_pls_correlation_matrix)"
  },
  {
    "objectID": "diablo.html#choosing-the-number-of-latent-components",
    "href": "diablo.html#choosing-the-number-of-latent-components",
    "title": "11  Integration with DIABLO",
    "section": "\n11.4 Choosing the number of latent components",
    "text": "11.4 Choosing the number of latent components\nOne important parameter that must be set when performing a DIABLO analysis is the number of latent components to construct for each dataset. The optimal number of components can be estimated by cross-validation, implemented in the mixOmics::perf() function. This function assesses the classification performance (i.e. how well the different outcome groups are separated) achieved by DIABLO for different numbers of latent components.\nChoosing the optimal number of latent components to construct is a multi-step process. The first step is to run DIABLO without feature selection, setting the number of latent components to the maximum value we wish to test. We recommend to set this to the number of groups in the categorical outcome + 2, which in our case equals 4; however this can be further refined after checking the results. For this example, we will set the maximum to 7. This is done through the diablo_run() function, which is a wrapper for the mixOmics::block.splsda() function. The function also requires as input the design matrix to be used; here we will use the one constructed from the PLS runs:\n\n\ntar_target(\n  diablo_novarsel,\n  diablo_run(\n    diablo_input, \n    diablo_design_matrix, \n    ncomp = 7\n  )\n)\n\n\nAlternatively, if we want to use one of the predefined design matrices, we can pass on one of 'null', 'weighted_full' or 'full' instead of the computed diablo_design_matrix, e.g.:\n\n\ntar_target(\n  diablo_novarsel,\n  diablo_run(\n    diablo_input, \n    \"weighted_full\", \n    ncomp = 7\n  )\n)\n\n\nThen, we call the mixOmics::perf() function on the result of this first DIABLO run. There are a number of parameters to set:\n\nvalidation: the type of cross-validation to perform, M-fold (\"Mfold\") or leave-one-out (\"loo\"). We recommend to use M-fold validation, except when the number of samples is very small.\nfolds: for M-fold cross-validation, the number of folds to construct, i.e. the number of groups in which to split the samples. Each group in turn will be considered as test set while the remaining groups will be considered the training set. The value to use depends on the number of samples in the datasets. By default, 10 is a reasonable number. For leave-one-out cross-validation, this parameter is set to the number of samples (that is the principle of leave-one-out cross-validation).\nnrepeat: the number of times the cross-validation will be repeated. This is important for M-fold cross-validation, as the way the samples are split into groups affects the results. Therefore, by repeating the cross-validation scheme we’re averaging the results over different splits, thus reducing the impact of samples splitting. We recommend at least 10 repeats. Irrelevant for leave-one-out cross-validation, so can be left to 1.\ncpus: number of CPUs to use for the computation. Useful if folds \\(\\times\\) repeats is large, as this can be computationally intensive.\n\nHere we’ll perform a 10-fold cross validation with 10 repeats.\n\n\ntar_target(\n  diablo_perf_res,\n  mixOmics::perf(\n    diablo_novarsel,\n    validation = \"Mfold\",\n    folds = 10,\n    nrepeat = 10,\n    cpus = 3\n  )\n)\n\n\nWe can visualise the results of the cross-validation with the diablo_plot_perf() function:\n\ntar_load(diablo_perf_res)\ndiablo_plot_perf(diablo_perf_res)\n\n\n\n\nThe plot displays the cross-validation results computed with several different distances and error rates:\n\nDistance: this refers to the prediction distance that is used to predict the samples group in the test set, based on the samples grouping in the training set. DIABLO tests the maximum, centroids and Mahalanobis distance. The authors of the package recommend using either the centroids or the Mahalanobis distance over the maximum distance when choosing the optimal number of components.\nError rate: this refers to the method by which the performance of the produced model is computed. DIABLO uses both the overall misclassification error rate and the balanced error rate. The authors recommend the latter, as it is is less biased towards the majority group when there is an unbalanced number of samples per group.\n\nThe function diablo_get_optim_ncomp() extracts from the cross-validation results the optimal number of components to compute, given a chosen distance and error rate. The authors of the package recommend to use the results obtained with the centroids distance and the balanced error rate; these are used by default by the diablo_get_optim_ncomp() function. In our example, the optimal number of components is:\n\ndiablo_get_optim_ncomp(diablo_perf_res)\n#> [1] 4\n\nFor ease of reuse we will save this value as a target in our analysis pipeline:\n\n\ntar_target(\n  diablo_optim_ncomp,\n  diablo_get_optim_ncomp(diablo_perf_res)\n)"
  },
  {
    "objectID": "diablo.html#choosing-the-number-of-features-to-retain",
    "href": "diablo.html#choosing-the-number-of-features-to-retain",
    "title": "11  Integration with DIABLO",
    "section": "\n11.5 Choosing the number of features to retain",
    "text": "11.5 Choosing the number of features to retain\nThe next parameter to set is the number of features to retain from the different datasets for each latent component. This is usually chosen by performing cross-validation on a grid of possible values. The range of values to test depends on the type of question we are trying to answer: selecting a larger number of features might lead to a better discrimination of the outcome groups, but will be hard to manually inspect for further interpretation.\nThe function diablo_tune() provides a wrapper around the mixOmics::tune() function that performs this cross-validation. Some of the arguments are similar to the mixOmics::perf() function, e.g. validation, folds, nrepeats or cpus. In addition, we recommend setting the dist argument, which corresponds to the prediction distance metric used for performance assessment, to \"centroids.dist\" (or \"mahalanobis.dist\").\nThe keepX_list argument controls the grid of values to be tested as possible number of features to retain from each dataset. It should be in the form of a named list, with one element per dataset, and where each element is a vector of integers corresponding to the values to test. The names of the list should correspond to the names of the datasets in the MultiDataSet object. If no value is provided for keepX_list, six values ranging from 5 to 30 (by increments of 5) are tested for each dataset.\n\n\ntar_target(\n  diablo_tune_res,\n  diablo_tune(\n    diablo_input,\n    diablo_design_matrix,\n    ncomp = diablo_optim_ncomp,\n    validation = \"Mfold\",\n    folds = 10,\n    nrepeat = 5,\n    dist = \"centroids.dist\",\n    cpus = 3\n  )\n)\n\n\nThis step can be very time-consuming, especially if the grid of values to test is very large. For this example, it takes around 50 minutes to run.\nThe cross-validation results can be inspected with the diablo_plot_tune() function:\n\ntar_load(diablo_tune_res)\ndiablo_plot_tune(diablo_tune_res)\n\n\n\n\nThe visualisation shows the performance of DIABLO runs with different number of features retained from each dataset. The different runs are ordered according to their performance. Here, we can see for example that it seems preferable to retain more genes and less metabolites for component 1.\nThe optimal number of features to retain from each dataset for the different latent components is stored in the cross-validation results object, and can be accessed with:\n\ndiablo_tune_res$choice.keepX\n#> $snps\n#> [1] 20 25  5 25\n#> \n#> $rnaseq\n#> [1] 30 15 20 30\n#> \n#> $metabolome\n#> [1] 10 10  5  5\n\nFor reporting purposes, the diablo_table_optim_keepX() function displays the optimal keepX values in a table format:\n\ndiablo_table_optim_keepX(diablo_tune_res)\n#> # A tibble: 3 × 6\n#>   Dataset    `Component 1` `Component 2` `Component 3` `Component 4` Total\n#>   <chr>              <dbl>         <dbl>         <dbl>         <dbl> <dbl>\n#> 1 snps                  20            25             5            25    75\n#> 2 rnaseq                30            15            20            30    95\n#> 3 metabolome            10            10             5             5    30"
  },
  {
    "objectID": "diablo.html#final-diablo-run",
    "href": "diablo.html#final-diablo-run",
    "title": "11  Integration with DIABLO",
    "section": "\n11.6 Final DIABLO run",
    "text": "11.6 Final DIABLO run\nOnce a value has been selected for all parameters, it is time to perform the final DIABLO run:\n\n\ntar_target(\n  diablo_final_run,\n  diablo_run(\n    diablo_input,\n    diablo_design_matrix,\n    ncomp = diablo_optim_ncomp,\n    keepX = diablo_tune_res$choice.keepX\n  )\n)\n\n\n\ntar_load(diablo_final_run)\n\nTo facilitate reporting, the diablo_get_params() function extracts from the DIABLO result the parameters used (i.e. number of latent components computed and number of features retained from each dataset for each latent component), with HTML formatting:\n\ndiablo_get_params(diablo_final_run)\n#> # A tibble: 2 × 3\n#>   Parameter Description                                                    Value\n#>   <chr>     <chr>                                                          <chr>\n#> 1 ncomp     Number of latent component                                     4    \n#> 2 keepX     Number of features retained in each X for each latent compone… snps…"
  },
  {
    "objectID": "diablo.html#results-interpretation",
    "href": "diablo.html#results-interpretation",
    "title": "11  Integration with DIABLO",
    "section": "\n11.7 Results interpretation",
    "text": "11.7 Results interpretation\nIn Chapter 12, we show the different functionalities implemented in the moiraine package that facilitate the interpretation of the results from an integration tool. In this section, we show some of the DIABLO-specific plots that can be generated to help interpret the results of a DIABLO run.\n\n11.7.1 Correlation between datasets\nFirst, we can assess how well the latent components correlate across the datasets. The diablo_plot() function is adapted from the mixOmics::plotDiablo() function, and displays, for a given latent component (specified with the ncomp argument), the correlation between the samples coordinates for this latent component across the datasets. Additionally, it allows to assess how well the latent components discriminate the outcome groups in each dataset.\n\nn_comp <- diablo_get_optim_ncomp(diablo_perf_res)\nwalk(\n  seq_len(n_comp), \n  \\(x) {\n    diablo_plot(diablo_final_run, ncomp = x)\n    title(paste(\"Latent component\", x))\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor the first three latent components, the strongest correlation is observed between the transcriptomics and metabolomics components, while the lowest correlation is observed between the genomics and metabolomics components. Across all three datasets, the first latent component alone is able to separate quite clearly the control and diseased animals. Note that as each latent component maximises the correlation between the datasets, these plots inform us about co-variation across the datasets.\n\n11.7.2 Samples projection to the latent component space\nWe can also represent the samples in the subspace spanned by the latent components for each dataset, using the mixOmics::plotIndiv() function. For example, we can have a look at the samples coordinates for the first two latent components:\n\nplotIndiv(\n  diablo_final_run,\n  comp = 1:2,\n  ind.names = FALSE,\n  legend = TRUE,\n  legend.title = \"Disease status\"\n)\n\n\n\n\nAs noted above, based on the first two latent components, there is a clear separation of the control and BRD animals across all three datasets.\nIdeally, we would look at all possible combinations of latent components, as follows:\n\nwalk(\n  combn(seq_len(n_comp), 2, simplify = FALSE),\n  \\(x) {\n    plotIndiv(\n      diablo_final_run,\n      comp = x,\n      ind.names = FALSE,\n      legend = TRUE,\n      legend.title = \"Phenotype group\"\n    )\n  } \n)\n\n\n11.7.3 Correlation circle plots\nThe correlation circle plots produced by the mixOmics::plotVar() function displays the contribution of the selected features to the different latent components. We will focus here on the first two latent components:\n\nplotVar(\n  diablo_final_run,\n  comp = 1:2,\n  var.names = FALSE,\n  ## If overlap = TRUE, features from the\n  ## different datasets are shown in one plot\n  overlap = FALSE,\n  pch = rep(16, 3),\n  cex = rep(2, 3)\n)\n\n\n\n\nAcross all three datasets, it seems that most selected features contribute to either one or the other latent component, but not both.\nThe plotVar() function offers the option to show the label of the features rather than representing them as points. However, it can be more informative to use information from the feature metadata as labels, rather than using the feature IDs. For example in the transcriptomics dataset, it would be more interesting to use the name of the genes. This information is available in the datasets’ features metadata:\n\ntar_load(mo_set_de)\nget_features_metadata(mo_set_de)[[\"rnaseq\"]] |>\n  str()\n#> 'data.frame':    20335 obs. of  15 variables:\n#>  $ feature_id : chr  \"ENSBTAG00000000005\" \"ENSBTAG00000000008\" \"ENSBTAG00000000009\" \"ENSBTAG00000000010\" ...\n#>  $ chromosome : Factor w/ 178 levels \"1\",\"2\",\"3\",\"4\",..: 17 29 18 21 8 20 20 5 5 23 ...\n#>  $ start      : int  65389743 32214439 12338037 34209956 7950815 33708626 33674806 74883636 74905031 27720176 ...\n#>  $ end        : int  65505336 32244810 12342272 34223394 7971600 33732944 33703223 74893752 74919112 27721739 ...\n#>  $ width      : int  115594 30372 4236 13439 20786 24319 28418 10117 14082 1564 ...\n#>  $ strand     : Factor w/ 3 levels \"+\",\"-\",\"*\": 1 2 1 1 2 1 1 2 2 2 ...\n#>  $ Name       : chr  \"GRK3\" \"KCNJ1\" \"FOXF1\" \"UBL7\" ...\n#>  $ description: chr  \"G protein-coupled receptor kinase 3 [Source:VGNC Symbol;Acc:VGNC:53904]\" \"potassium inwardly rectifying channel subfamily J member 1 [Source:VGNC Symbol;Acc:VGNC:30453]\" \"forkhead box F1 [Source:VGNC Symbol;Acc:VGNC:29084]\" \"ubiquitin like 7 [Source:VGNC Symbol;Acc:VGNC:50128]\" ...\n#>  $ log_fc     : num  0.136 -0.1297 1.2714 0.3957 0.0777 ...\n#>  $ log_cpm    : num  5.905 -0.744 -2.563 6.256 -2.761 ...\n#>  $ f          : num  4.163 1.068 23.956 60.53 0.142 ...\n#>  $ p_value    : num  4.32e-02 3.03e-01 2.73e-06 1.58e-12 7.07e-01 ...\n#>  $ fdr        : num  7.17e-02 3.94e-01 9.67e-06 1.52e-11 7.77e-01 ...\n#>  $ de_signif  : chr  \"Not DE\" \"Not DE\" \"Not DE\" \"Not DE\" ...\n#>  $ de_status  : chr  \"Not DE\" \"Not DE\" \"Not DE\" \"Not DE\" ...\n\nThe diablo_plot_var() function is a variant of plotVar(), which uses columns from the features metadata to label features plot. It takes as an input the DIABLO result object as well as the MultiDataSet object, and a named list providing for each dataset the name of the column in the feature metadata data-frame to use as features label:\n\ndiablo_plot_var(\n  diablo_final_run,\n  mo_set_de,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  overlap = FALSE,\n  cex = rep(2, 3),\n  comp = 1:2\n)\n\n\n\n\nNote that if a dataset is not present in the list passed to label_cols (here, that is the case of the genomics dataset), the feature IDs will be used as labels.\n\n11.7.4 Circos plot\nLastly, it is possible to represent the correlation between features selected from different datasets, with the mixOmics::circosPlot() function. For ease of visualisation, it only displays correlations above a certain threshold (specified via the cutoff argument). By default, it displays the features selected for all latent components, but this can be controlled via the comp argument:\n\ncircosPlot(\n  diablo_final_run,\n  cutoff = 0.7,\n  size.variables = 0.5,\n  comp = 1:2\n)\n\n\n\n\nAs for the correlation circle plot function, the diablo_plot_circos() function generates the same plot, but allows us to use columns in the feature metadata of each dataset as feature labels:\n\ndiablo_plot_circos(\n  diablo_final_run,\n  tar_read(mo_set),\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  cutoff = 0.7,\n  size.variables = 0.5,\n  comp = 1:2\n)\n\n\n\n\nThis plot is useful to identify features across the datasets with high correlations."
  },
  {
    "objectID": "diablo.html#recap-targets-list",
    "href": "diablo.html#recap-targets-list",
    "title": "11  Integration with DIABLO",
    "section": "\n11.8 Recap – targets list",
    "text": "11.8 Recap – targets list\nFor convenience, here is the list of targets that we created in this section:\n\nTargets list for DIABLO analysis\n\n\nlist(\n  ## Creating the DIABLO input\n  tar_target(\n    diablo_input,\n    get_input_mixomics_supervised(\n      mo_presel_supervised,\n      group = \"status\"\n    )\n  ),\n  \n  ## Running sPLS on each dataset to construct the design matrix\n  diablo_pairwise_pls_factory(diablo_input),\n  \n  ## Initial DIABLO run with no feature selection and large number of components\n  tar_target(\n    diablo_novarsel,\n    diablo_run(\n      diablo_input,\n      diablo_design_matrix,\n      ncomp = 7\n    )\n  ),\n  \n  ## Cross-validation for number of components\n  tar_target(\n    diablo_perf_res,\n    mixOmics::perf(\n      diablo_novarsel,\n      validation = \"Mfold\",\n      folds = 10,\n      nrepeat = 10,\n      cpus = 3\n    )\n  ),\n  \n  ## Plotting cross-validation results (for number of components)\n  tar_target(\n    diablo_perf_plot,\n    diablo_plot_perf(diablo_perf_res)\n  ),\n  \n  ## Selected value for ncomp\n  tar_target(\n    diablo_optim_ncomp,\n    diablo_get_optim_ncomp(diablo_perf_res)\n  ),\n  \n  ## Cross-validation for number of features to retain\n  tar_target(\n    diablo_tune_res,\n    diablo_tune(\n      diablo_input,\n      diablo_design_matrix,\n      ncomp = diablo_optim_ncomp,\n      validation = \"Mfold\",\n      folds = 10,\n      nrepeat = 5,\n      dist = \"centroids.dist\",\n      cpus = 3\n    )\n  ),\n  \n  ## Plotting cross-validation results (for number of features)\n  tar_target(\n    diablo_tune_plot,\n    diablo_plot_tune(diablo_tune_res)\n  ),\n  \n  ## Final DIABLO run\n  tar_target(\n    diablo_final_run,\n    diablo_run(\n      diablo_input,\n      diablo_design_matrix,\n      ncomp = diablo_optim_ncomp,\n      keepX = diablo_tune_res$choice.keepX\n    )\n  )\n)"
  },
  {
    "objectID": "interpretation.html#sec-interpretation-dim-reduction",
    "href": "interpretation.html#sec-interpretation-dim-reduction",
    "title": "12  Interpreting the integration results",
    "section": "\n12.1 Dimension reduction methods",
    "text": "12.1 Dimension reduction methods\nDespite relying on very different statistical approaches, the different integration methods included in the pipeline all perform dimension reduction of the omics datasets through feature extraction. That is, they construct a small number of latent components/variables/dimensions (that we refer to as latent dimensions in the moiraine package) that capture as much information from the original datasets as possible. A dimension reduction approach typically returns, for each latent dimension constructed, two sets of values:\n\nFeatures weight: the contribution of the features from the different omics datasets to the latent dimension. All methods included in the pipeline construct latent dimensions as linear combinations of the original features, and therefore the features contribution is quantified by their weight in the linear combination for the corresponding latent dimension.\nSamples score: the projection of the samples onto the latent dimension.\n\nIn addition, the fraction or percentage of variance that each latent dimension explains in the different omics datasets is usually calculated.\nInterpreting the results of a dimension reduction method involves:\n\nUnderstanding the source of the variation captured by each latent dimension: is a given latent dimension representing an important source of biological variation, such as effect of a treatment, or age of the samples? Or do they show a source of technical variation, for example highlighting a group of outlier samples with different omics profiles from the rest of the observations? Answering these questions allows us to identify which latent dimensions capture the biological phenomenon investigated, or whether there are some sources of noise that should be accounted for in follow-up experiments.\nInvestigating which omics features are driving the latent dimensions: once we have identified some latent dimensions of interest, we can look at the features that contribute the most to these dimensions, in order to understand the molecular mechanisms or pathways involved. This is typically done after looking into the phenomenon captured by the latent dimensions, but can also help to identify it."
  },
  {
    "objectID": "interpretation.html#sec-interpretation-standard-output",
    "href": "interpretation.html#sec-interpretation-standard-output",
    "title": "12  Interpreting the integration results",
    "section": "\n12.2 Generating a standardised output",
    "text": "12.2 Generating a standardised output\n\n12.2.1 get_output function\nIn the moiraine package, the output of the different integration methods can be converted to a standardised output containing the pieces of information (features weight, samples score and percentage of variance explained) characteristic of dimension reduction methods, stored in a consistent format. This enables us to use functions for visualisation or analysis that can be applied to the results of any integration method, rather than having to implement one for each object type returned by the different integration packages.\nThe get_output() function transforms the output from any integration package included in moiraine into an output_dimension_reduction object, which is a list with three tibbles: features_weight, samples_score and variance_explained:\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\n\ntar_target(\n  spls_output,\n  get_output(spls_final_run)\n)\n\n\n\ntar_load(spls_output)\nspls_output\n#> $features_weight\n#> # A tibble: 2,098 × 5\n#>    feature_id         dataset latent_dimension weight importance\n#>    <chr>              <fct>   <fct>             <dbl>      <dbl>\n#>  1 ENSBTAG00000000020 rnaseq  Component 1           0          0\n#>  2 ENSBTAG00000000046 rnaseq  Component 1           0          0\n#>  3 ENSBTAG00000000056 rnaseq  Component 1           0          0\n#>  4 ENSBTAG00000000061 rnaseq  Component 1           0          0\n#>  5 ENSBTAG00000000113 rnaseq  Component 1           0          0\n#>  6 ENSBTAG00000000149 rnaseq  Component 1           0          0\n#>  7 ENSBTAG00000000164 rnaseq  Component 1           0          0\n#>  8 ENSBTAG00000000205 rnaseq  Component 1           0          0\n#>  9 ENSBTAG00000000212 rnaseq  Component 1           0          0\n#> 10 ENSBTAG00000000289 rnaseq  Component 1           0          0\n#> # ℹ 2,088 more rows\n#> \n#> $samples_score\n#> # A tibble: 278 × 3\n#>    sample_id latent_dimension score\n#>    <chr>     <fct>            <dbl>\n#>  1 G1979     Component 1      -3.63\n#>  2 G2500     Component 1      -2.46\n#>  3 G3030     Component 1      -6.42\n#>  4 G3068     Component 1      -6.16\n#>  5 G3121     Component 1      -3.39\n#>  6 G3315     Component 1       4.98\n#>  7 G3473     Component 1       5.29\n#>  8 G3474     Component 1       4.97\n#>  9 G3550     Component 1      -4.17\n#> 10 G3594     Component 1       4.71\n#> # ℹ 268 more rows\n#> \n#> $variance_explained\n#> # A tibble: 4 × 3\n#>   latent_dimension dataset    prop_var_expl\n#>   <fct>            <fct>              <dbl>\n#> 1 Component 1      rnaseq             0.205\n#> 2 Component 1      metabolome         0.179\n#> 3 Component 2      rnaseq             0.147\n#> 4 Component 2      metabolome         0.108\n#> \n#> attr(,\"class\")\n#> [1] \"output_dimension_reduction\"\n#> attr(,\"method\")\n#> [1] \"sPLS\"\n\n\n\n\n\ntar_target(\n  so2pls_output,\n  get_output(so2pls_final_run)\n)\n\n\n\ntar_load(so2pls_output)\nso2pls_output\n#> $features_weight\n#> # A tibble: 2,318 × 5\n#>    feature_id         dataset latent_dimension  weight importance\n#>    <chr>              <fct>   <fct>              <dbl>      <dbl>\n#>  1 ENSBTAG00000000020 rnaseq  joint component 1      0          0\n#>  2 ENSBTAG00000000046 rnaseq  joint component 1      0          0\n#>  3 ENSBTAG00000000056 rnaseq  joint component 1      0          0\n#>  4 ENSBTAG00000000061 rnaseq  joint component 1      0          0\n#>  5 ENSBTAG00000000113 rnaseq  joint component 1      0          0\n#>  6 ENSBTAG00000000149 rnaseq  joint component 1      0          0\n#>  7 ENSBTAG00000000164 rnaseq  joint component 1      0          0\n#>  8 ENSBTAG00000000205 rnaseq  joint component 1      0          0\n#>  9 ENSBTAG00000000212 rnaseq  joint component 1      0          0\n#> 10 ENSBTAG00000000289 rnaseq  joint component 1      0          0\n#> # ℹ 2,308 more rows\n#> \n#> $samples_score\n#> # A tibble: 973 × 3\n#>    sample_id latent_dimension   score\n#>    <chr>     <fct>              <dbl>\n#>  1 G1979     joint component 1  -8.12\n#>  2 G2500     joint component 1  -9.81\n#>  3 G3030     joint component 1  -9.93\n#>  4 G3068     joint component 1 -14.7 \n#>  5 G3121     joint component 1  -5.01\n#>  6 G3315     joint component 1   9.66\n#>  7 G3473     joint component 1   9.79\n#>  8 G3474     joint component 1   9.99\n#>  9 G3550     joint component 1  -9.70\n#> 10 G3594     joint component 1   8.37\n#> # ℹ 963 more rows\n#> \n#> $variance_explained\n#> # A tibble: 8 × 3\n#>   latent_dimension                dataset    prop_var_expl\n#>   <fct>                           <fct>              <dbl>\n#> 1 joint component 1               rnaseq            0.327 \n#> 2 joint component 1               metabolome        0.150 \n#> 3 rnaseq specific component 1     rnaseq            0.123 \n#> 4 metabolome specific component 1 metabolome        0.107 \n#> 5 metabolome specific component 2 metabolome        0.0767\n#> 6 metabolome specific component 3 metabolome        0.0613\n#> 7 metabolome specific component 4 metabolome        0.0605\n#> 8 metabolome specific component 5 metabolome        0.0376\n#> \n#> attr(,\"class\")\n#> [1] \"output_dimension_reduction\"\n#> attr(,\"method\")\n#> [1] \"sO2PLS\"\n\n\n\n\n\ntar_target(\n  mofa_output,\n  get_output(mofa_trained)\n)\n\n\n\ntar_load(mofa_output)\nmofa_output\n#> $features_weight\n#> # A tibble: 30,735 × 5\n#>    feature_id                  dataset latent_dimension     weight importance\n#>    <chr>                       <fct>   <fct>                 <dbl>      <dbl>\n#>  1 21-25977541-C-T-rs41974686  snps    Factor 1          0.000374      0.139 \n#>  2 22-51403583-A-C-rs210306176 snps    Factor 1          0.0000535     0.0199\n#>  3 24-12959068-G-T-rs381471286 snps    Factor 1          0.000268      0.0999\n#>  4 8-85224224-T-C-rs43565287   snps    Factor 1         -0.000492      0.183 \n#>  5 ARS-BFGL-BAC-16973          snps    Factor 1         -0.000883      0.329 \n#>  6 ARS-BFGL-BAC-19403          snps    Factor 1         -0.000500      0.186 \n#>  7 ARS-BFGL-BAC-2450           snps    Factor 1          0.000555      0.207 \n#>  8 ARS-BFGL-BAC-2600           snps    Factor 1         -0.0000325     0.0121\n#>  9 ARS-BFGL-BAC-27911          snps    Factor 1         -0.000568      0.212 \n#> 10 ARS-BFGL-BAC-35925          snps    Factor 1          0.000803      0.299 \n#> # ℹ 30,725 more rows\n#> \n#> $samples_score\n#> # A tibble: 2,160 × 3\n#>    sample_id latent_dimension score\n#>    <chr>     <fct>            <dbl>\n#>  1 G1979     Factor 1          1.95\n#>  2 G2500     Factor 1          1.98\n#>  3 G3030     Factor 1          3.39\n#>  4 G3068     Factor 1          3.65\n#>  5 G3121     Factor 1          1.57\n#>  6 G3315     Factor 1         -1.81\n#>  7 G3473     Factor 1         -2.63\n#>  8 G3474     Factor 1         -2.30\n#>  9 G3550     Factor 1          2.98\n#> 10 G3594     Factor 1         -1.88\n#> # ℹ 2,150 more rows\n#> \n#> $variance_explained\n#> # A tibble: 45 × 3\n#>    latent_dimension dataset    prop_var_expl\n#>    <fct>            <fct>              <dbl>\n#>  1 Factor 1         snps           0.000313 \n#>  2 Factor 1         rnaseq         0.496    \n#>  3 Factor 1         metabolome     0.137    \n#>  4 Factor 2         snps           0.239    \n#>  5 Factor 2         rnaseq         0.000197 \n#>  6 Factor 2         metabolome     0.0108   \n#>  7 Factor 3         snps           0.000108 \n#>  8 Factor 3         rnaseq         0.199    \n#>  9 Factor 3         metabolome     0.0000872\n#> 10 Factor 4         snps           0.0000927\n#> # ℹ 35 more rows\n#> \n#> attr(,\"class\")\n#> [1] \"output_dimension_reduction\"\n#> attr(,\"method\")\n#> [1] \"MOFA\"\n\n\n\n\n\ntar_target(\n  diablo_output,\n  get_output(diablo_final_run)\n)\n\n\n\ntar_load(diablo_output)\ndiablo_output\n#> $features_weight\n#> # A tibble: 8,196 × 5\n#>    feature_id                  dataset latent_dimension weight importance\n#>    <chr>                       <fct>   <fct>             <dbl>      <dbl>\n#>  1 21-25977541-C-T-rs41974686  snps    Component 1           0          0\n#>  2 22-51403583-A-C-rs210306176 snps    Component 1           0          0\n#>  3 24-12959068-G-T-rs381471286 snps    Component 1           0          0\n#>  4 8-85224224-T-C-rs43565287   snps    Component 1           0          0\n#>  5 ARS-BFGL-BAC-16973          snps    Component 1           0          0\n#>  6 ARS-BFGL-BAC-19403          snps    Component 1           0          0\n#>  7 ARS-BFGL-BAC-2450           snps    Component 1           0          0\n#>  8 ARS-BFGL-BAC-2600           snps    Component 1           0          0\n#>  9 ARS-BFGL-BAC-27911          snps    Component 1           0          0\n#> 10 ARS-BFGL-BAC-35925          snps    Component 1           0          0\n#> # ℹ 8,186 more rows\n#> \n#> $samples_score\n#> # A tibble: 540 × 3\n#>    sample_id latent_dimension score\n#>    <chr>     <fct>            <dbl>\n#>  1 G1979     Component 1       1.97\n#>  2 G2500     Component 1       1.50\n#>  3 G3030     Component 1       3.57\n#>  4 G3068     Component 1       3.50\n#>  5 G3121     Component 1       2.13\n#>  6 G3315     Component 1      -3.26\n#>  7 G3473     Component 1      -3.97\n#>  8 G3474     Component 1      -3.20\n#>  9 G3550     Component 1       2.46\n#> 10 G3594     Component 1      -2.38\n#> # ℹ 530 more rows\n#> \n#> $variance_explained\n#> # A tibble: 12 × 3\n#>    latent_dimension dataset    prop_var_expl\n#>    <fct>            <fct>              <dbl>\n#>  1 Component 1      snps             0.0698 \n#>  2 Component 1      rnaseq           0.201  \n#>  3 Component 1      metabolome       0.171  \n#>  4 Component 2      snps             0.0213 \n#>  5 Component 2      rnaseq           0.0801 \n#>  6 Component 2      metabolome       0.0521 \n#>  7 Component 3      snps             0.00898\n#>  8 Component 3      rnaseq           0.149  \n#>  9 Component 3      metabolome       0.0634 \n#> 10 Component 4      snps             0.0136 \n#> 11 Component 4      rnaseq           0.0601 \n#> 12 Component 4      metabolome       0.0399 \n#> \n#> attr(,\"class\")\n#> [1] \"output_dimension_reduction\"\n#> attr(,\"method\")\n#> [1] \"DIABLO\"\n\n\n\n\nThe features_weight tibble contains one row per combination of feature and latent dimension. The ID of the features and the name of the dataset from which they originate are stored in the feature_id and dataset columns, respectively. The latent_dimension column gives the name of the latent dimension; this is a factor column. For each feature and latent dimension, the weight column shows the weight that was attributed to the feature for the corresponding latent dimension. In addition, the importance column contains the features importance score, which is computed as the absolute value of the features weight, divided by the maximum absolute weight across all features from the same omics dataset for the corresponding latent dimension. This importance score allows us to compare the contribution of the features across latent dimensions or integration methods, as the weight can be on different scales and thus cannot be directly compared. The importance scores range from 0 to 1. For any method performing feature selection (e.g. sPLS or DIABLO), features that were not selected for a given latent dimension are assigned a weight and importance score of 0.\nThe samples score tibble contains for each sample (sample_id) and latent dimension (latent_dimension) the sample’s coordinate for the corresponding latent dimension.\nThe variance_explained tibble gives for each latent dimension (latent_dimension) the proportion of variance explained (prop_var_expl) for each dataset (dataset). The values in prop_var_expl are between 0 and 1.\nIn addition, the name of the integration method used to obtain these results is stored in the method attribute of the output_dimension_reduction object:\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\nattr(spls_output, \"method\")\n#> [1] \"sPLS\"\n\n\n\n\nattr(so2pls_output, \"method\")\n#> [1] \"sO2PLS\"\n\n\n\n\nattr(mofa_output, \"method\")\n#> [1] \"MOFA\"\n\n\n\n\nattr(diablo_output, \"method\")\n#> [1] \"DIABLO\"\n\n\n\n\nFor convenience, the get_latent_dimensions() function can be used on an output_dimension_reduction object to see the names of the latent dimensions (the levels used for the latent_dimension column in each tibble):\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\nget_latent_dimensions(spls_output)\n#> [1] \"Component 1\" \"Component 2\"\n\n\n\n\nget_latent_dimensions(so2pls_output)\n#> [1] \"joint component 1\"               \"rnaseq specific component 1\"    \n#> [3] \"metabolome specific component 1\" \"metabolome specific component 2\"\n#> [5] \"metabolome specific component 3\" \"metabolome specific component 4\"\n#> [7] \"metabolome specific component 5\"\n\n\n\n\nget_latent_dimensions(mofa_output)\n#>  [1] \"Factor 1\"  \"Factor 2\"  \"Factor 3\"  \"Factor 4\"  \"Factor 5\"  \"Factor 6\" \n#>  [7] \"Factor 7\"  \"Factor 8\"  \"Factor 9\"  \"Factor 10\" \"Factor 11\" \"Factor 12\"\n#> [13] \"Factor 13\" \"Factor 14\" \"Factor 15\"\n\n\n\n\nget_latent_dimensions(diablo_output)\n#> [1] \"Component 1\" \"Component 2\" \"Component 3\" \"Component 4\"\n\n\n\n\n\n\n\n\n\n\nOther methods covered by get_output\n\n\n\nNote that both PCA and sPLS-DA (the method used for supervised features preselection in Section 7.3.2) are also dimension reduction methods. Therefore, the get_output() function also converts pcaRes objects (from run_pca() or pcaMethods::pca()) and mixo_splsda objects (from run_splsda() or mixOmics::splsda()) into output_dimension_reduction objects.\n\n\n\n12.2.2 Averaging latent dimensions over datasets\nWhile MOFA computes one score per sample for each latent dimension created, sPLS, sO2PLS and DIABLO all compute one score per dataset for each sample and latent dimension. For each latent dimension, the samples score obtained for the different datasets are then compared, to assess the agreement or covariation between datasets. Ideally, these scores should be highly correlated across datasets, since the methods aim at maximising the variation between datasets, but it is not always the case. However, when they are highly correlated, it becomes redundant to interpret each dataset-specific version of the latent dimensions.\nInstead, the mixOmics authors proposed a solution for DIABLO, which is to construct a weighted average space in which to represent the samples: for each latent component, the samples score are averaged over the different datasets. The weight attributed to each dataset is determined by how well the corresponding dataset discriminates between the samples group of interest. This way, rather than looking at samples score for each dataset for any given latent component, we can look at an average of them.\nThe get_output() function uses this idea to construct, for the output of sPLS, sO2PLS and DIABLO a set of average samples score for each latent dimension, rather than returning a set of samples score per dataset. For DIABLO, the average is weighted as explained above, while for sPLS and sO2PLS each dataset is given equal weight in the average. This calculation can be disabled in the get_output() function to extract the dataset-specific samples score, by setting the use_average_dimensions parameter to FALSE. Note that this only affects the samples_score tibble in terms of dimensions, but the name of the latent dimensions will change to reflect the dataset to which they refer.\n\n\nsPLS\nsO2PLS\nDIABLO\n\n\n\n\n\ntar_target(\n  spls_output_no_average,\n  get_output(spls_final_run, use_average_dimensions = FALSE)\n)\n\n\n\ntar_load(spls_output_no_average)\n\nget_latent_dimensions(spls_output_no_average)\n#> [1] \"rnaseq Component 1\"     \"metabolome Component 1\" \"rnaseq Component 2\"    \n#> [4] \"metabolome Component 2\"\n\nnrow(spls_output$samples_score)\n#> [1] 278\nnrow(spls_output_no_average$samples_score)\n#> [1] 556\n\n\n\n\n\ntar_target(\n  so2pls_output_no_average,\n  get_output(so2pls_final_run, use_average_dimensions = FALSE)\n)\n\n\n\ntar_load(so2pls_output_no_average)\n\nget_latent_dimensions(so2pls_output_no_average)\n#> [1] \"rnaseq joint component 1\"        \"metabolome joint component 1\"   \n#> [3] \"rnaseq specific component 1\"     \"metabolome specific component 1\"\n#> [5] \"metabolome specific component 2\" \"metabolome specific component 3\"\n#> [7] \"metabolome specific component 4\" \"metabolome specific component 5\"\n\nnrow(so2pls_output$samples_score)\n#> [1] 973\nnrow(so2pls_output_no_average$samples_score)\n#> [1] 1112\n\n\n\n\n\ntar_target(\n  diablo_output_no_average,\n  get_output(diablo_final_run, use_average_dimensions = FALSE)\n)\n\n\n\ntar_load(diablo_output_no_average)\n  \nget_latent_dimensions(diablo_output_no_average)\n#>  [1] \"snps Component 1\"       \"rnaseq Component 1\"     \"metabolome Component 1\"\n#>  [4] \"snps Component 2\"       \"rnaseq Component 2\"     \"metabolome Component 2\"\n#>  [7] \"snps Component 3\"       \"rnaseq Component 3\"     \"metabolome Component 3\"\n#> [10] \"snps Component 4\"       \"rnaseq Component 4\"     \"metabolome Component 4\"\n\nnrow(diablo_output$samples_score)\n#> [1] 540\nnrow(diablo_output_no_average$samples_score)\n#> [1] 1620"
  },
  {
    "objectID": "interpretation.html#percentage-of-variance-explained",
    "href": "interpretation.html#percentage-of-variance-explained",
    "title": "12  Interpreting the integration results",
    "section": "\n12.3 Percentage of variance explained",
    "text": "12.3 Percentage of variance explained\nThe first step in interpreting the results of a dimension reduction method is to assess how much variance is explained by the different latent dimensions for each dataset. The function plot_variance_explained() takes as input a output_dimension_reduction object and constructs a dataset-specific screeplot:\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\nplot_variance_explained(spls_output)\n\n\n\n\n\n\n\nplot_variance_explained(so2pls_output, ncol = 1) +\n  theme(axis.text.x = element_text(size = 9, angle = 30, hjust = 1))\n\n\n\n\n\n\n\nplot_variance_explained(mofa_output, ncol = 1) +\n  theme(axis.text.x = element_text(size = 9, angle = 30, hjust = 1))\n\n\n\n\n\n\n\nplot_variance_explained(diablo_output, ncol = 2)"
  },
  {
    "objectID": "interpretation.html#sec-interpretation-samples-scores",
    "href": "interpretation.html#sec-interpretation-samples-scores",
    "title": "12  Interpreting the integration results",
    "section": "\n12.4 Samples plot",
    "text": "12.4 Samples plot\nTo understand the phenomenon driving the variation represented by the different latent components, we can investigate the coordinates of the samples in the space spanned by these latent components, in combination with information that we have about the samples.\nWe will start by loading the MultiDataSet object and generating some custom colour palettes for different samples covariates of interest, that we will use in the rest of the section.\n\ntar_load(mo_set_complete)\n\n## Choosing colour palettes for the samples covariates\npalette_status <- scale_colour_brewer(palette = \"Set1\")\npalette_feedlot <- scale_colour_brewer(palette = \"Set2\")\npalette_geno_comp <- scale_colour_brewer(palette = \"Dark2\")\npalette_rnaseq_batch <- scale_colour_brewer(palette = \"Paired\")\n\n## For some plots will need both colour and fill\npalette_status_fill <- scale_colour_brewer(\n  palette = \"Set1\", \n  aesthetics = c(\"colour\", \"fill\")\n)\n\n\n12.4.1 Matrix of scatter plots\nThe plot_samples_score() function shows the samples score in a matrix of scatter plots that represent all possible two-by-two combinations of the latent dimensions. The plots in the resulting matrix are redundant: the lower plots (below the diagonal) are just a rotated version of the upper plots (above the diagonal). The function takes as input an output_dimension_reduction object. In addition, it accepts a MultiDataSet object to extract information about the samples that can then be used to customise the plot. Since the plots are redundant, different properties of the samples can be shown in the upper and lower plots. For example, we will colour the samples according to disease status in the upper plots, while representing some other covariate in the lower plots. We will use the shape of the points to illustrate gender in both upper and lower plots. By default, all latent dimensions are included in the plots, but it is possible to select some of them by passing their names to the latent_dimensions argument. There are more options to further customise the plot, which are shown in the function’s help.\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\nplot_samples_score(\n  spls_output,\n  mo_data = mo_set_complete,\n  colour_upper = \"status\",\n  scale_colour_upper = palette_status,\n  shape_upper = \"gender\",\n  colour_lower = \"feedlot\",\n  scale_colour_lower = palette_feedlot\n) +\n  theme(legend.box = \"vertical\")\n\n\n\n\nComponent 1 clearly splits the control and BRD animals, while component 2 seems to separate two samples from the rest. There is no clear separation of the samples by feedlot or gender.\n\n\nHere we will focus on the joint components. Since there is only one, instead of a matrix of scatterplot, the function will display the samples score with a violin plot, and the properties selected for the upper plots will be used to customise the points:\n\nplot_samples_score(\n  so2pls_output,\n  latent_dimensions = \"joint component 1\",\n  mo_data = mo_set_complete,\n  colour_upper = \"status\",\n  scale_colour_upper = palette_status,\n  shape_upper = \"gender\",\n  colour_lower = \"feedlot\",\n  scale_colour_lower = palette_feedlot\n)\n#> Warning in plot_samples_score(so2pls_output, latent_dimensions = \"joint\n#> component 1\", : Only one latent dimension to plot; 'colour_diag',\n#> 'colour_lower' and 'shape_lower' argument will be ignored.\n\n\n\n\nJoint component 1 separates the BRD and control animals, although some of them overlap.\n\n\nFor clarity we will focus here on the first four factors:\n\nplot_samples_score(\n  mofa_output,\n  latent_dimensions = paste(\"Factor\", 1:4),\n  mo_data = mo_set_complete,\n  colour_upper = \"status\",\n  scale_colour_upper = palette_status,\n  shape_upper = \"gender\",\n  colour_lower = \"geno_comp_cluster\",\n  scale_colour_lower = palette_geno_comp\n) +\n  theme(legend.box = \"vertical\")\n#> Warning: Removed 2 rows containing missing values (`geom_point()`).\n#> Removed 2 rows containing missing values (`geom_point()`).\n#> Removed 2 rows containing missing values (`geom_point()`).\n#> Removed 2 rows containing missing values (`geom_point()`).\n#> Removed 2 rows containing missing values (`geom_point()`).\n#> Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\nFactor 1 clearly separates the control and BRD animals. Factor 2 separates samples from the genomics composition cluster K1 from the other two clusters. None of the factors are separating the animals by gender, indicating that this covariate does not have a strong effect in the omics measurements.\n\n\n\nplot_samples_score(\n  diablo_output,\n  mo_data = mo_set_complete,\n  colour_upper = \"status\",\n  scale_colour_upper = palette_status,\n  shape_upper = \"gender\",\n  colour_lower = \"rnaseq_batch\",\n  scale_colour_lower = palette_rnaseq_batch\n) +\n  theme(legend.box = \"vertical\")\n\n\n\n\nAs DIABLO is a supervised method, it is no surprise that the first component clearly separates the two disease status groups. The second latent component separates samples according to the RNAseq batch. From this plot it is not clear what components 3 and 4 represent.\n\n\n\n\n12.4.2 Scatter plot for pair of latent dimensions\nWe can also focus on a specific pair of latent dimensions and represent the samples in the space spanned by these two dimensions, with the plot_samples_score_pair() function. The two latent dimensions to plot are selected by passing their names to the function. This function also accepts a MultiDataSet object, whose samples metadata will be used to customise the plot.\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\nplot_samples_score_pair(\n  spls_output,\n  paste(\"Component\", 1:2),\n  mo_data = mo_set_complete,\n  colour_by = \"status\",\n  shape_by = \"gender\"\n) +\n  palette_status\n\n\n\n\nThe two disease status groups are well separated in this space.\n\n\nTo showcase this function, we will look at the first two metabolomics-specific latent components:\n\nplot_samples_score_pair(\n  so2pls_output,\n  paste(\"metabolome specific component\", 1:2),\n  mo_data = mo_set_complete,\n  colour_by = \"status\",\n  shape_by = \"gender\"\n) +\n  palette_status\n\n\n\n\nThese two specific components are not related to disease status or gender.\n\n\n\nplot_samples_score_pair(\n  mofa_output,\n  paste(\"Factor\", 1:2),\n  mo_data = mo_set_complete,\n  colour_by = \"status\",\n  shape_by = \"geno_comp_cluster\"\n) +\n  palette_status\n#> Warning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\nWe see that these first two factors discriminate the disease status groups and the genomics composition clusters.\n\n\n\nplot_samples_score_pair(\n  diablo_output,\n  paste(\"Component\", 1:2),\n  mo_data = mo_set_complete,\n  colour_by = \"status\",\n  shape_by = \"rnaseq_batch\"\n) +\n  palette_status\n\n\n\n\nWe see that these first two components discriminate the disease status groups and the RNAseq batches.\n\n\n\n\n12.4.3 Samples score vs covariate\nLastly, we can plot the samples score for each latent dimension against a samples covariate of interest, with the plot_samples_score_covariate() function. This is useful to focus on one dimension at a time rather than pairs of them. By default, the function displays all latent dimensions, but we can focus on a subset of them through the latent_dimensions arguments. The function needs a MultiDataSet object to extract information about the samples. The plot generated will depend on whether the covariate of interest is categorical or continuous. We will show both options below. In addition to the main covariate of interest that will be displayed on the x-axis, the colour and shape of the points can be further customised according to other samples properties.\nFirst, with a categorical covariate:\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\nplot_samples_score_covariate(\n  spls_output,\n  mo_set_complete,\n  \"status\",\n  colour_by = \"status\"\n) +\n  palette_status_fill\n\n\n\n\n\n\nFor clarity we will focus on the first joint component only.\n\nplot_samples_score_covariate(\n  so2pls_output,\n  mo_set_complete,\n  \"status\",\n  colour_by = \"status\",\n  latent_dimensions = \"joint component 1\"\n) +\n  palette_status_fill\n\n\n\n\n\n\nFor clarity we will focus on the first two factors only.\n\nplot_samples_score_covariate(\n  mofa_output,\n  mo_set_complete,\n  \"status\",\n  colour_by = \"status\",\n  shape_by = \"geno_comp_cluster\",\n  latent_dimensions = paste(\"Factor\", 1:2)\n) +\n  palette_status_fill\n#> Warning: Removed 4 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\nFor clarity we will focus on the first two components only.\n\nplot_samples_score_covariate(\n  diablo_output,\n  mo_set_complete,\n  \"status\",\n  colour_by = \"status\",\n  shape_by = \"rnaseq_batch\",\n  latent_dimensions = paste(\"Component\", 1:2)\n) +\n  palette_status_fill\n\n\n\n\n\n\n\nNow, with a continuous covariate:\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\nplot_samples_score_covariate(\n  spls_output,\n  mo_set_complete,\n  \"day_on_feed\",\n  colour_by = \"status\"\n) +\n  palette_status_fill\n\n\n\n\n\n\nFor clarity we will focus on the first joint component only.\n\nplot_samples_score_covariate(\n  so2pls_output,\n  mo_set_complete,\n  \"day_on_feed\",\n  colour_by = \"status\",\n  latent_dimensions = \"joint component 1\"\n) +\n  palette_status_fill\n\n\n\n\n\n\nFor clarity we will focus on the first two factors only.\n\nplot_samples_score_covariate(\n  mofa_output,\n  mo_set_complete,\n  \"day_on_feed\",\n  colour_by = \"status\",\n  shape_by = \"geno_comp_cluster\",\n  latent_dimensions = paste(\"Factor\", 1:2)\n) +\n  palette_status_fill\n#> Warning: Removed 4 rows containing non-finite values (`stat_smooth()`).\n#> Warning: Removed 4 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\nFor clarity we will focus on the first two components only.\n\nplot_samples_score_covariate(\n  diablo_output,\n  mo_set_complete,\n  \"day_on_feed\",\n  colour_by = \"status\",\n  shape_by = \"rnaseq_batch\",\n  latent_dimensions = paste(\"Component\", 1:2)\n) +\n  palette_status_fill"
  },
  {
    "objectID": "interpretation.html#feature-plots",
    "href": "interpretation.html#feature-plots",
    "title": "12  Interpreting the integration results",
    "section": "\n12.5 Feature plots",
    "text": "12.5 Feature plots\nNext, we can have a look at the features contributing to each latent dimension.\n\n12.5.1 Features weight distribution\nWe can start by looking at the distribution of features weight for each latent dimension across the datasets, with the plot_features_weight_distr() function. Again, the function takes an output_dimension_reduction object as first input; by default it will show all latent dimensions and datasets, but they can be specified through the latent_dimensions and datasets arguments. The function shows by default the distribution of the “signed” importance scores, i.e. the features weights normalised by the highest absolute weight value for the corresponding latent dimension and dataset, but we can also show the distribution of importance scores (which are absolute values) and non-transformed features weight (through the features_metric argument). Note that the function returns a patchwork of ggplots.\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\nplot_features_weight_distr(spls_output)\n\n\n\n\nAs sPLS performs feature selection, most of the weights are equal to 0.\n\n\n\nplot_features_weight_distr(so2pls_output) +\n  ## showing two plots per column (from patchwork package)\n  plot_layout(ncol = 2)\n\n\n\n\nAs sO2PLS performs feature selection for the joint components, most of the weights are equal to 0 for joint component 1.\n\n\nWe will only look at factors 1 to 4 for clarity:\n\nplot_features_weight_distr(\n  mofa_output,\n  latent_dimensions = paste(\"Factor\", 1:4)\n) +\n  ## showing one plot per column (from patchwork package)\n  plot_layout(ncol = 1)\n\n\n\n\nWe can see for example for factor 1 that only a couple of metabolites have an importance score above 0.5, this small number of features are driving the variation captured by factor 1.\n\n\n\nplot_features_weight_distr(\n  diablo_output\n) +\n  ## showing one plot per column (from patchwork package)\n  plot_layout(ncol = 1)\n\n\n\n\nAs DIABLO performs feature selection, most of the weights are equal to zero.\n\n\n\n\n12.5.2 Comparing features importance between latent components\nWe can also compare the importance score given to the features between any two latent dimensions with the plot_features_weight_pair() function.\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\nplot_features_weight_pair(\n  spls_output,\n  paste(\"Component\", 1:2),\n  mo_data = mo_set_complete,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  )\n)\n\n\n\n\nAll genes and most metabolites selected for the two components are different.\n\n\n\nplot_features_weight_pair(\n  so2pls_output,\n  paste(\"metabolome specific component\", 1:2),\n  mo_data = mo_set_complete,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  )\n)\n\n\n\n\nThe plot shows an interesting pattern: the weights of the compound for these two specific components are negatively correlated, except for a couple of outliers.\n\n\n\nplot_features_weight_pair(\n  mofa_output,\n  paste(\"Factor\", 1:2),\n  mo_data = mo_set_complete,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  )\n)\n\n\n\n\nWe can see that the genomic markers are mostly given weights of opposite signs for the first two MOFA factors (e.g. positive weight for factor 1 and negative weight for factor 2). For the transcriptomics and metabolomics datasets, the importance score are mostly uncorrelated between the first two factors.\n\n\n\nplot_features_weight_pair(\n  diablo_output,\n  paste(\"Component\", 1:2),\n  mo_data = mo_set_complete,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  )\n)\n\n\n\n\nWe can see that different features were selected for the first two latent components from each omics dataset.\n\n\n\nThese plots allow us to quickly check whether different latent dimensions capture different or related aspects of the data. The top 5 features according to their consensus importance score (see Section 14.9) are highlighted in red.\nBy default, the function shows the signed importance score of the features, i.e. their importance score to which the sign of their weight was added. This can be changed through the features_metric argument of the function.\n\n12.5.3 Plotting top features weight\nWe can then investigate which features are assigned the highest weights for each latent dimension. These are the features driving the variation captured by the latent components. This is done with the plot_top_features() function.\nBy default, the feature IDs will be used as labels in the plot, but by passing a MultiDataSet object to the function we can use a column from the features metadata table instead. To do so, we need to pass a named list to the label_cols argument: the names of the elements in the list should correspond to dataset names in the MultiDataSet object, and the value should be the name of the column in the features metadata table of the corresponding dataset to use as feature label. The number of features displayed is controlled through the top_n argument (the default value is 20). Note that if a lower number of features is selected for a certain dataset and latent dimension, only the selected features will be displayed. Again, the function returns a patchwork of ggplots.\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\nplot_top_features(\n  spls_output,\n  mo_data = mo_set_complete,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  )\n)\n\n\n\n\nWe can see that citric acid and D-mannose have an importance score close to 1 for component 1. Citric acid has a negative weight, meaning that its abundance is negatively correlated with component 1, while D-mannose has a positive weight, so its abundance is positively correlated with component 1. For the second component, only two genes have an importance score above 0.5.\n\n\nWe will focus on joint component 1:\n\nplot_top_features(\n  so2pls_output,\n  mo_data = mo_set_complete,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  latent_dimensions = \"joint component 1\"\n)\n\n\n\n\nWhile all top 20 genes have an importance score above 0.5 for joint component 1, only citric acid is given a high importance score for joint component 1 in the metabolomics dataset.\n\n\nWe will focus on the first two factors here:\n\nplot_top_features(\n  mofa_output,\n  mo_data = mo_set_complete,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  latent_dimensions = paste(\"Factor\", 1:2)\n)\n\n\n\n\nFor factor 1, citric acid is the only metabolite with an importance score above 0.75, while in the genomics dataset four markers have a high importance score, and most of the top 20 genes have an importance score aroung 0.7 or higher.\n\n\nFor clarity, we will focus on the first two latent components:\n\nplot_top_features(\n  diablo_output,\n  mo_data = mo_set_complete,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  latent_dimensions = paste(\"Component\", 1:2)\n)\n\n\n\n\nFor component 1, we can see three markers from the genomics dataset and three genes with a high importance score. From the metabolomics dataset, less than 20 features were retained.\n\n\n\n\n12.5.4 Extracting top features\nIt is also possible to extract information about the top contributing features as a table with the function get_top_features(). The function offers two options:\n\nReturn for each dataset the top N features contributing to the latent dimensions of interest. N is specified through the n_features argument;\nReturn for each dataset features whose importance score is at least equal to a certain threshold. The threshold is specified through the min_importance argument.\n\nThe first option is preferred when many features contribute to a given factor. The second option has been implemented for cases where some latent dimensions are driven by a small number of features (so for example in the top 10 contributing features, only 3 features would actually have a high importance score). By default, the function returns the top contributing features from all datasets for all latent dimensions, but we can focus on some datasets and/or latent dimensions of interest by passing their names to the datasets and latent_dimensions arguments of the function. Additionally, we can pass to the function a MultiDataSet object (through the mo_data argument); the function will extract information about the features from the features metadata.\nWe illustrate the two possible options below. For the second option, we add features information to the table:\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\nget_top_features(spls_output, n_features = 3) |> \n  head()\n#> # A tibble: 6 × 5\n#>   feature_id         dataset    latent_dimension weight importance\n#>   <chr>              <fct>      <fct>             <dbl>      <dbl>\n#> 1 ENSBTAG00000022715 rnaseq     Component 1      -0.318      1    \n#> 2 ENSBTAG00000050618 rnaseq     Component 1      -0.302      0.950\n#> 3 ENSBTAG00000018223 rnaseq     Component 1      -0.291      0.916\n#> 4 HMDB00094          metabolome Component 1       0.451      1    \n#> 5 HMDB00169          metabolome Component 1      -0.327      0.726\n#> 6 HMDB00159          metabolome Component 1      -0.312      0.692\n\nget_top_features(\n  spls_output,\n  min_importance = 0.8,\n  mo_data = mo_set_complete\n) |> \n  head()\n#> # A tibble: 6 × 31\n#>   feature_id      dataset latent_dimension weight importance chromosome  p_value\n#>   <chr>           <fct>   <fct>             <dbl>      <dbl> <chr>         <dbl>\n#> 1 ENSBTAG0000002… rnaseq  Component 1      -0.318      1     26         1.79e-33\n#> 2 ENSBTAG0000005… rnaseq  Component 1      -0.302      0.950 26         2.54e-33\n#> 3 ENSBTAG0000001… rnaseq  Component 1      -0.291      0.916 16         7.14e-31\n#> 4 ENSBTAG0000004… rnaseq  Component 1      -0.266      0.837 15         4.14e-36\n#> 5 ENSBTAG0000003… rnaseq  Component 1      -0.264      0.831 7          1.22e-35\n#> 6 HMDB00094       metabo… Component 1       0.451      1     <NA>       2.48e-41\n#> # ℹ 24 more variables: fdr <dbl>, start <int>, end <int>, width <int>,\n#> #   strand <fct>, Name <chr>, description <chr>, log_fc <dbl>, log_cpm <dbl>,\n#> #   f <dbl>, de_signif <chr>, de_status <chr>, hmdb_id <chr>, name <chr>,\n#> #   chemical_formula <chr>, monisotopic_molecular_weight <dbl>,\n#> #   cas_registry_number <chr>, smiles <chr>, inchikey <chr>, kegg_id <chr>,\n#> #   direct_parent <chr>, super_class <chr>, t_value <dbl>, padj <dbl>\n\n\n\n\nget_top_features(so2pls_output, n_features = 3) |> \n  head()\n#> # A tibble: 6 × 5\n#>   feature_id         dataset    latent_dimension  weight importance\n#>   <chr>              <fct>      <fct>              <dbl>      <dbl>\n#> 1 ENSBTAG00000048835 rnaseq     joint component 1 -0.268      1    \n#> 2 ENSBTAG00000049569 rnaseq     joint component 1 -0.266      0.993\n#> 3 ENSBTAG00000039037 rnaseq     joint component 1 -0.248      0.925\n#> 4 HMDB00094          metabolome joint component 1  0.751      1    \n#> 5 HMDB00042          metabolome joint component 1  0.335      0.445\n#> 6 HMDB00357          metabolome joint component 1  0.319      0.424\n\nget_top_features(\n  so2pls_output,\n  min_importance = 0.8,\n  mo_data = mo_set_complete\n) |> \n  head()\n#> # A tibble: 6 × 31\n#>   feature_id      dataset latent_dimension weight importance chromosome  p_value\n#>   <chr>           <fct>   <fct>             <dbl>      <dbl> <chr>         <dbl>\n#> 1 ENSBTAG0000004… rnaseq  joint component… -0.268      1     24         5.43e-27\n#> 2 ENSBTAG0000004… rnaseq  joint component… -0.266      0.993 NKLS02001… 1.14e-27\n#> 3 ENSBTAG0000003… rnaseq  joint component… -0.248      0.925 NKLS02001… 1.45e-28\n#> 4 ENSBTAG0000003… rnaseq  joint component… -0.235      0.876 7          1.22e-35\n#> 5 ENSBTAG0000005… rnaseq  joint component… -0.227      0.847 NKLS02000… 1.31e-22\n#> 6 ENSBTAG0000002… rnaseq  joint component… -0.216      0.805 26         1.79e-33\n#> # ℹ 24 more variables: fdr <dbl>, start <int>, end <int>, width <int>,\n#> #   strand <fct>, Name <chr>, description <chr>, log_fc <dbl>, log_cpm <dbl>,\n#> #   f <dbl>, de_signif <chr>, de_status <chr>, hmdb_id <chr>, name <chr>,\n#> #   chemical_formula <chr>, monisotopic_molecular_weight <dbl>,\n#> #   cas_registry_number <chr>, smiles <chr>, inchikey <chr>, kegg_id <chr>,\n#> #   direct_parent <chr>, super_class <chr>, t_value <dbl>, padj <dbl>\n\n\n\n\nget_top_features(mofa_output, n_features = 3) |> \n  head()\n#> # A tibble: 6 × 5\n#>   feature_id             dataset latent_dimension   weight importance\n#>   <chr>                  <fct>   <fct>               <dbl>      <dbl>\n#> 1 BovineHD0100032240     snps    Factor 1         -0.00268      1    \n#> 2 Hapmap55381-rs29025399 snps    Factor 1         -0.00268      1    \n#> 3 BovineHD0100032254     snps    Factor 1          0.00249      0.927\n#> 4 ENSBTAG00000049569     rnaseq  Factor 1          1.89         1    \n#> 5 ENSBTAG00000048835     rnaseq  Factor 1          1.88         0.999\n#> 6 ENSBTAG00000039037     rnaseq  Factor 1          1.81         0.961\n\nget_top_features(\n  mofa_output,\n  min_importance = 0.8,\n  mo_data = mo_set_complete\n) |> \n  head()\n#> # A tibble: 6 × 40\n#>   feature_id    dataset latent_dimension   weight importance chromosome position\n#>   <chr>         <fct>   <fct>               <dbl>      <dbl> <chr>         <dbl>\n#> 1 BovineHD0100… snps    Factor 1         -0.00268      1     1            1.13e8\n#> 2 Hapmap55381-… snps    Factor 1         -0.00268      1     1            1.13e8\n#> 3 BovineHD0100… snps    Factor 1          0.00249      0.927 1            1.13e8\n#> 4 BovineHD2700… snps    Factor 1         -0.00225      0.839 27           3.57e7\n#> 5 ENSBTAG00000… rnaseq  Factor 1          1.89         1     NKLS02001…  NA     \n#> 6 ENSBTAG00000… rnaseq  Factor 1          1.88         0.999 24          NA     \n#> # ℹ 33 more variables: gen_train_score <dbl>, ref <chr>, alt <chr>,\n#> #   ilmn_strand <chr>, customer_strand <chr>, norm_id <dbl>, qtl_type <chr>,\n#> #   qtl_effect <dbl>, p_value <dbl>, fdr <dbl>, start <int>, end <int>,\n#> #   width <int>, strand <fct>, Name <chr>, description <chr>, log_fc <dbl>,\n#> #   log_cpm <dbl>, f <dbl>, de_signif <chr>, de_status <chr>, hmdb_id <chr>,\n#> #   name <chr>, chemical_formula <chr>, monisotopic_molecular_weight <dbl>,\n#> #   cas_registry_number <chr>, smiles <chr>, inchikey <chr>, kegg_id <chr>, …\n\n\n\n\nget_top_features(diablo_output, n_features = 3) |> \n  head()\n#> # A tibble: 6 × 5\n#>   feature_id         dataset latent_dimension weight importance\n#>   <chr>              <fct>   <fct>             <dbl>      <dbl>\n#> 1 ARS-BFGL-NGS-27468 snps    Component 1      -0.632      1    \n#> 2 BovineHD2300010006 snps    Component 1       0.509      0.807\n#> 3 BovineHD0300000351 snps    Component 1       0.337      0.534\n#> 4 ENSBTAG00000022715 rnaseq  Component 1       0.465      1    \n#> 5 ENSBTAG00000050618 rnaseq  Component 1       0.378      0.813\n#> 6 ENSBTAG00000049888 rnaseq  Component 1       0.305      0.655\n\nget_top_features(\n  diablo_output,\n  min_importance = 0.8,\n  mo_data = mo_set_complete\n) |> \n  head()\n#> # A tibble: 6 × 40\n#>   feature_id      dataset latent_dimension weight importance chromosome position\n#>   <chr>           <fct>   <fct>             <dbl>      <dbl> <chr>         <dbl>\n#> 1 ARS-BFGL-NGS-2… snps    Component 1      -0.632      1     1            1.34e8\n#> 2 BovineHD230001… snps    Component 1       0.509      0.807 23           3.43e7\n#> 3 ENSBTAG0000002… rnaseq  Component 1       0.465      1     26          NA     \n#> 4 ENSBTAG0000005… rnaseq  Component 1       0.378      0.813 26          NA     \n#> 5 HMDB00094       metabo… Component 1      -0.716      1     <NA>        NA     \n#> 6 BovineHD070000… snps    Component 2      -0.543      1     7            2.11e5\n#> # ℹ 33 more variables: gen_train_score <dbl>, ref <chr>, alt <chr>,\n#> #   ilmn_strand <chr>, customer_strand <chr>, norm_id <dbl>, qtl_type <chr>,\n#> #   qtl_effect <dbl>, p_value <dbl>, fdr <dbl>, start <int>, end <int>,\n#> #   width <int>, strand <fct>, Name <chr>, description <chr>, log_fc <dbl>,\n#> #   log_cpm <dbl>, f <dbl>, de_signif <chr>, de_status <chr>, hmdb_id <chr>,\n#> #   name <chr>, chemical_formula <chr>, monisotopic_molecular_weight <dbl>,\n#> #   cas_registry_number <chr>, smiles <chr>, inchikey <chr>, kegg_id <chr>, …\n\n\n\n\n\n12.5.5 Extracting the selected features\nFor methods that perform feature selection (i.e. sPLS, sO2PLS and DIABLO), we can extract information about the selected features with the get_selected_features() function. As with get_top_features(), if a MultiDataSet object is passed to the function, it will extract information about the features from the features metadata tables and return them. If applied to the results of a method that does not perform feature selection, all features will be returned.\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\nselected_features <- get_selected_features(spls_output) \n\ndim(selected_features)\n#> [1] 120   5\nhead(selected_features)\n#> # A tibble: 6 × 5\n#>   feature_id         dataset latent_dimension weight importance\n#>   <chr>              <fct>   <fct>             <dbl>      <dbl>\n#> 1 ENSBTAG00000022715 rnaseq  Component 1      -0.318      1    \n#> 2 ENSBTAG00000050618 rnaseq  Component 1      -0.302      0.950\n#> 3 ENSBTAG00000018223 rnaseq  Component 1      -0.291      0.916\n#> 4 ENSBTAG00000049888 rnaseq  Component 1      -0.266      0.837\n#> 5 ENSBTAG00000031647 rnaseq  Component 1      -0.264      0.831\n#> 6 ENSBTAG00000046158 rnaseq  Component 1      -0.248      0.781\n\n\n\n\nselected_features <- get_selected_features(so2pls_output) \n\ndim(selected_features)\n#> [1] 1394    5\nhead(selected_features)\n#> # A tibble: 6 × 5\n#>   feature_id         dataset latent_dimension  weight importance\n#>   <chr>              <fct>   <fct>              <dbl>      <dbl>\n#> 1 ENSBTAG00000048835 rnaseq  joint component 1 -0.268      1    \n#> 2 ENSBTAG00000049569 rnaseq  joint component 1 -0.266      0.993\n#> 3 ENSBTAG00000039037 rnaseq  joint component 1 -0.248      0.925\n#> 4 ENSBTAG00000031647 rnaseq  joint component 1 -0.235      0.876\n#> 5 ENSBTAG00000052012 rnaseq  joint component 1 -0.227      0.847\n#> 6 ENSBTAG00000022715 rnaseq  joint component 1 -0.216      0.805\n\n\n\n\nselected_features <- get_selected_features(mofa_output) \n\ndim(selected_features)\n#> [1] 30735     5\nhead(selected_features)\n#> # A tibble: 6 × 5\n#>   feature_id             dataset latent_dimension   weight importance\n#>   <chr>                  <fct>   <fct>               <dbl>      <dbl>\n#> 1 BovineHD0100032240     snps    Factor 1         -0.00268      1    \n#> 2 Hapmap55381-rs29025399 snps    Factor 1         -0.00268      1    \n#> 3 BovineHD0100032254     snps    Factor 1          0.00249      0.927\n#> 4 BovineHD2700010051     snps    Factor 1         -0.00225      0.839\n#> 5 Hapmap44084-BTA-48504  snps    Factor 1         -0.00194      0.724\n#> 6 BovineHD2100007115     snps    Factor 1          0.00190      0.709\n\n\n\n\nselected_features <- get_selected_features(diablo_output) \n\ndim(selected_features)\n#> [1] 200   5\nhead(selected_features)\n#> # A tibble: 6 × 5\n#>   feature_id         dataset latent_dimension weight importance\n#>   <chr>              <fct>   <fct>             <dbl>      <dbl>\n#> 1 ARS-BFGL-NGS-27468 snps    Component 1      -0.632      1    \n#> 2 BovineHD2300010006 snps    Component 1       0.509      0.807\n#> 3 BovineHD0300000351 snps    Component 1       0.337      0.534\n#> 4 BovineHD1900011146 snps    Component 1      -0.210      0.333\n#> 5 BovineHD0900026231 snps    Component 1      -0.191      0.302\n#> 6 BovineHD1100030384 snps    Component 1      -0.181      0.286\n\n\n\n\n\n12.5.6 Features measurements\nFinally, we can investigate further some features of interest using the functions shown in Section 4.5. For the example, we will extract the top 3 contributing features from each dataset for the first latent dimension generated with the methods:\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\nspls_top_features <- get_top_features(\n  spls_output,\n  n_features = 3,\n  latent_dimensions = \"Component 1\"\n) |> \n  pull(feature_id)\n\nspls_top_features\n#> [1] \"ENSBTAG00000022715\" \"ENSBTAG00000050618\" \"ENSBTAG00000018223\"\n#> [4] \"HMDB00094\"          \"HMDB00169\"          \"HMDB00159\"\n\n\n\n\nso2pls_top_features <- get_top_features(\n  so2pls_output,\n  n_features = 3,\n  latent_dimensions = \"joint component 1\"\n) |> \n  pull(feature_id)\n\nso2pls_top_features\n#> [1] \"ENSBTAG00000048835\" \"ENSBTAG00000049569\" \"ENSBTAG00000039037\"\n#> [4] \"HMDB00094\"          \"HMDB00042\"          \"HMDB00357\"\n\n\n\n\nmofa_top_features <- get_top_features(\n  mofa_output,\n  n_features = 3,\n  latent_dimensions = \"Factor 1\"\n) |> \n  pull(feature_id)\n\nmofa_top_features\n#> [1] \"BovineHD0100032240\"     \"Hapmap55381-rs29025399\" \"BovineHD0100032254\"    \n#> [4] \"ENSBTAG00000049569\"     \"ENSBTAG00000048835\"     \"ENSBTAG00000039037\"    \n#> [7] \"HMDB00094\"              \"HMDB00042\"              \"HMDB00357\"\n\n\n\n\ndiablo_top_features <- get_top_features(\n  diablo_output,\n  n_features = 3,\n  latent_dimensions = \"Component 1\"\n) |> \n  pull(feature_id)\n\ndiablo_top_features\n#> [1] \"ARS-BFGL-NGS-27468\" \"BovineHD2300010006\" \"BovineHD0300000351\"\n#> [4] \"ENSBTAG00000022715\" \"ENSBTAG00000050618\" \"ENSBTAG00000049888\"\n#> [7] \"HMDB00094\"          \"HMDB00042\"          \"HMDB00169\"\n\n\n\n\nWe can use the plot_data_heatmap() function to visualise the measurements for the features across the samples as a heatmap. By passing a MultiDataSet object to the function, we can add information about the samples and the features around the heatmap, and change the label used for the features.\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\nplot_data_heatmap(\n  mo_set_complete,\n  spls_top_features,\n  center = TRUE,\n  scale = TRUE,\n  show_column_names = FALSE,\n  only_common_samples = TRUE,\n  samples_info = c(\"status\", \"day_on_feed\"),\n  features_info = c(\"de_status\"),\n  colours_list = list(\n    \"status\" = c(\"Control\" = \"gold\", \"BRD\" = \"lightblue\"),\n    \"day_on_feed\" = colorRamp2(c(5, 70), c(\"white\", \"pink3\")),\n    \"de_status\" = c(\"downregulated\" = \"deepskyblue\", \n                    \"upregulated\" = \"chartreuse3\")\n  ),\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  truncate = 20\n)\n\n\n\n\n\n\n\nplot_data_heatmap(\n  mo_set_complete,\n  so2pls_top_features,\n  center = TRUE,\n  scale = TRUE,\n  show_column_names = FALSE,\n  only_common_samples = TRUE,\n  samples_info = c(\"status\", \"day_on_feed\"),\n  features_info = c(\"de_status\"),\n  colours_list = list(\n    \"status\" = c(\"Control\" = \"gold\", \"BRD\" = \"lightblue\"),\n    \"day_on_feed\" = colorRamp2(c(5, 70), c(\"white\", \"pink3\")),\n    \"de_status\" = c(\"downregulated\" = \"deepskyblue\", \n                    \"upregulated\" = \"chartreuse3\")\n  ),\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  truncate = 20\n)\n\n\n\n\n\n\n\nplot_data_heatmap(\n  mo_set_complete,\n  mofa_top_features,\n  center = TRUE,\n  scale = TRUE,\n  show_column_names = FALSE,\n  only_common_samples = TRUE,\n  samples_info = c(\"status\", \"day_on_feed\"),\n  features_info = c(\"de_status\"),\n  colours_list = list(\n    \"status\" = c(\"Control\" = \"gold\", \"BRD\" = \"lightblue\"),\n    \"day_on_feed\" = colorRamp2(c(5, 70), c(\"white\", \"pink3\")),\n    \"de_status\" = c(\"downregulated\" = \"deepskyblue\", \n                    \"upregulated\" = \"chartreuse3\")\n  ),\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  truncate = 20\n)\n\n\n\n\n\n\n\nplot_data_heatmap(\n  mo_set_complete,\n  diablo_top_features,\n  center = TRUE,\n  scale = TRUE,\n  show_column_names = FALSE,\n  only_common_samples = TRUE,\n  samples_info = c(\"status\", \"day_on_feed\"),\n  features_info = c(\"de_status\"),\n  colours_list = list(\n    \"status\" = c(\"Control\" = \"gold\", \"BRD\" = \"lightblue\"),\n    \"day_on_feed\" = colorRamp2(c(5, 70), c(\"white\", \"pink3\")),\n    \"de_status\" = c(\"downregulated\" = \"deepskyblue\", \n                    \"upregulated\" = \"chartreuse3\")\n  ),\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  ),\n  truncate = 20\n)\n\n\n\n\n\n\n\nAlternatively, we can display the features’ measurements against some samples covariate, with the plot_data_covariate() function:\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\nplot_data_covariate(\n  mo_set_complete,\n  \"status\",\n  spls_top_features,\n  only_common_samples = TRUE,\n  label_cols = list(\n    \"rnaseq\" = \"Name\", \n    \"metabolome\" = \"name\"\n  )\n)\n\n\n\n\n\n\n\nplot_data_covariate(\n  mo_set_complete,\n  \"status\",\n  so2pls_top_features,\n  only_common_samples = TRUE,\n  label_cols = list(\n    \"rnaseq\" = \"Name\", \n    \"metabolome\" = \"name\"\n  )\n)\n\n\n\n\n\n\n\nplot_data_covariate(\n  mo_set_complete,\n  \"status\",\n  mofa_top_features,\n  only_common_samples = TRUE,\n  label_cols = list(\n    \"rnaseq\" = \"Name\", \n    \"metabolome\" = \"name\"\n  )\n)\n\n\n\n\n\n\n\nplot_data_covariate(\n  mo_set_complete,\n  \"status\",\n  diablo_top_features,\n  only_common_samples = TRUE,\n  label_cols = list(\n    \"rnaseq\" = \"Name\", \n    \"metabolome\" = \"name\"\n  )\n)"
  },
  {
    "objectID": "interpretation.html#recap-targets-list",
    "href": "interpretation.html#recap-targets-list",
    "title": "12  Interpreting the integration results",
    "section": "\n12.6 Recap – targets list",
    "text": "12.6 Recap – targets list\nFor convenience, here is the list of targets that we created in this section:\n\nTargets list for results interpretation\nIn the targets script, before the targets list, we will add the following code to create the colour palettes used in some of the plots:\n\n\n## In the preamble of the _targets.R script\n\n## Choosing colour palettes for the samples covariates\npalette_status <- scale_colour_brewer(palette = \"Set1\")\npalette_feedlot <- scale_colour_brewer(palette = \"Set2\")\npalette_geno_comp <- scale_colour_brewer(palette = \"Dark2\")\npalette_rnaseq_batch <- scale_colour_brewer(palette = \"Paired\")\n\n\n\n\nsPLS\nsO2PLS\nMOFA\nDIABLO\n\n\n\n\n\nlist(\n  ## Generating standardised output\n  tar_target(\n    spls_output,\n    get_output(spls_final_run)\n  ),\n  \n  ## Percentage of variance explained\n  tar_target(\n    spls_plot_variance_explained,\n    plot_variance_explained(spls_output)\n  ),\n  \n  ## Samples score matrix plot\n  tar_target(\n    spls_samples_scores_plot,\n    plot_samples_score(\n      spls_output,\n      mo_data = mo_set_complete,\n      colour_upper = \"status\",\n      scale_colour_upper = palette_status,\n      shape_upper = \"gender\",\n      colour_lower = \"feedlot\",\n      scale_colour_lower = palette_feedlot\n    ) +\n      theme(legend.box = \"vertical\")\n  ),\n  \n  ## Distribution of features weight\n  tar_target(\n    spls_features_weight_distribution,\n    plot_features_weight_distr(spls_output)\n  ),\n  \n  ## Plot of top contributing features\n  tar_target(\n    spls_top_features_plot,\n    plot_top_features(\n      spls_output,\n      mo_data = mo_set_complete,\n      label_cols = list(\n        \"rnaseq\" = \"Name\",\n        \"metabolome\" = \"name\"\n      )\n    )\n  ),\n  \n  ## Table of selected features\n  tar_target(\n    spls_selected_features,\n    get_selected_features(spls_output)\n  )\n)\n\n\n\n\n\n\nlist(\n  ## Generating standardised output\n  tar_target(\n    so2pls_output,\n    get_output(so2pls_final_run)\n  ),\n  \n  ## Percentage of variance explained\n  tar_target(\n    so2pls_plot_variance_explained,\n    plot_variance_explained(so2pls_output, ncol = 1) +\n      theme(axis.text.x = element_text(size = 9, angle = 30, hjust = 1))\n  ),\n  \n  ## Samples score matrix plot\n  tar_target(\n    so2pls_samples_scores_plot,\n    plot_samples_score(\n      so2pls_output,\n      latent_dimensions = \"joint component 1\",\n      mo_data = mo_set_complete,\n      colour_upper = \"status\",\n      scale_colour_upper = palette_status,\n      shape_upper = \"gender\"\n    )\n  ),\n  \n  ## Distribution of features weight\n  tar_target(\n    so2pls_features_weight_distribution,\n    plot_features_weight_distr(so2pls_output) +\n      plot_layout(ncol = 2)\n  ),\n  \n  ## Plot of top contributing features\n  tar_target(\n    so2pls_top_features_plot,\n    plot_top_features(\n      so2pls_output,\n      mo_data = mo_set_complete,\n      label_cols = list(\n        \"rnaseq\" = \"Name\",\n        \"metabolome\" = \"name\"\n      )\n    )\n  ),\n  \n  ## Table of selected features\n  tar_target(\n    so2pls_selected_features,\n    get_selected_features(\n      so2pls_output,\n      latent_dimensions = \"joint component 1\"\n    )\n  )\n)\n\n\n\n\n\n\nlist(\n  ## Generating standardised output\n  tar_target(\n    mofa_output,\n    get_output(mofa_trained)\n  ),\n  \n  ## Percentage of variance explained\n  tar_target(\n    mofa_plot_variance_explained,\n    plot_variance_explained(mofa_output, ncol = 1) +\n      theme(axis.text.x = element_text(size = 9, angle = 30, hjust = 1))\n  ),\n  \n  ## Samples score matrix plot\n  tar_target(\n    mofa_samples_scores_plot,\n    plot_samples_score(\n      mofa_output,\n      latent_dimensions = paste(\"Factor\", 1:4),\n      mo_data = mo_set_complete,\n      colour_upper = \"status\",\n      scale_colour_upper = palette_status,\n      shape_upper = \"gender\",\n      colour_lower = \"geno_comp_cluster\",\n      scale_colour_lower = palette_geno_comp\n    ) +\n      theme(legend.box = \"vertical\")\n  ),\n  \n  ## Distribution of features weight\n  tar_target(\n    mofa_features_weight_distribution,\n    plot_features_weight_distr(\n      mofa_output,\n      latent_dimensions = paste(\"Factor\", 1:4)\n    ) +\n      plot_layout(ncol = 1)\n  ),\n  \n  ## Plot of top contributing features\n  tar_target(\n    mofa_top_features_plot,\n    plot_top_features(\n      mofa_output,\n      mo_data = mo_set_complete,\n      label_cols = list(\n        \"rnaseq\" = \"Name\",\n        \"metabolome\" = \"name\"\n      ),\n      latent_dimensions = paste(\"Factor\", 1:2)\n    )\n  ),\n  \n  ## Table of top contributing features\n  tar_target(\n    mofa_top_features,\n    get_top_features(\n      mofa_output,\n      min_importance = 0.8,\n      mo_data = mo_set_complete\n    )\n  )\n)\n\n\n\n\n\n\nlist(\n  ## Generating standardised output\n  tar_target(\n    diablo_output,\n    get_output(diablo_final_run)\n  ),\n  \n  ## Percentage of variance explained\n  tar_target(\n    diablo_plot_variance_explained,\n    plot_variance_explained(diablo_output, ncol = 2)\n  ),\n  \n  ## Samples score matrix plot\n  tar_target(\n    diablo_samples_scores_plot,\n    plot_samples_score(\n      diablo_output,\n      mo_data = mo_set_complete,\n      colour_upper = \"status\",\n      scale_colour_upper = palette_status,\n      shape_upper = \"gender\",\n      colour_lower = \"rnaseq_batch\",\n      scale_colour_lower = palette_rnaseq_batch\n    ) +\n      theme(legend.box = \"vertical\")\n  ),\n  \n  ## Distribution of features weight\n  tar_target(\n    diablo_features_weight_distribution,\n    plot_features_weight_distr(\n      diablo_output\n    ) +\n      plot_layout(ncol = 1)\n  ),\n  \n  ## Plot of top contributing features\n  tar_target(\n    diablo_top_features_plot,\n    plot_top_features(\n      diablo_output,\n      mo_data = mo_set_complete,\n      label_cols = list(\n        \"rnaseq\" = \"Name\",\n        \"metabolome\" = \"name\"\n      ),\n      latent_dimensions = paste(\"Component\", 1:2)\n    )\n  ),\n  \n  ## Table of top contributing features\n  tar_target(\n    diablo_selected_features,\n    get_selected_features(diablo_output) \n  )\n)"
  },
  {
    "objectID": "evaluation.html#introduction",
    "href": "evaluation.html#introduction",
    "title": "13  Evaluating the integration results",
    "section": "\n13.1 Introduction",
    "text": "13.1 Introduction\nEvaluating the results of a multi-omics integration analysis is not an easy task, mainly because when analysing biological data there is no ground truth about the underlying biological mechanisms at play. However, it is possible to gain some measure of confidence in our results by comparing them to what we already know about the biological system studied, or to other analyses (typically single-omics analyses) performed on the dataset. In the latter case, this can also show us what insights are gained by analysing the omics datasets together that would have been missed by looking at each omics dataset separately. Note that in this vignette, we refer to the evaluation of an integration method as comparison with prior knowledge or previous studies, while in Chapter 14 we will talk about the comparison of results obtained with different integration tools.\nWhen evaluating integration results, we can compare the features contribution (see Section 12.1) to some prior information that we have about the features: for example, their score in a differential expression analysis, whether they were found differentially expressed or not, or the group to which they belong (e.g. biological pathway or chemical class). On the other hand, we can assess whether the latent dimensions created separate different sample groups (e.g. control vs treatment, or different time points).\nFor this vignette, we will use the results from the DIABLO (Chapter 11) and MOFA (Chapter 10) analyses as examples. We will use the dimension reduction output objects that we created in Chapter 12, which contains the results of the DIABLO and MOFA runs stored in a standardised format (Section 12.2):\n\ntar_load(diablo_output)\ntar_load(mofa_output)\n\nNote that for the DIABLO run, the samples score are computed for the weighted average of each latent component, rather than for the dataset-specific latent components (this is controlled through the use_average_dimensions argument from the get_output() function).\nWe will also use the MultiDataSet object that contains information about the samples and features:\n\ntar_load(mo_set_complete)"
  },
  {
    "objectID": "evaluation.html#evaluating-features-prioritisation",
    "href": "evaluation.html#evaluating-features-prioritisation",
    "title": "13  Evaluating the integration results",
    "section": "\n13.2 Evaluating features prioritisation",
    "text": "13.2 Evaluating features prioritisation\nFirst, we can evaluate the integration results in terms of the features prioritisation, i.e. the ranking of the features for each latent dimension in terms of their importance score. We can for example assess whether the features that were given the highest scores for some latent components were also highlighted through single-omics analyses, or compare the importance score of groups of features, for example compounds from different chemical classes or genes from different gene families.\nHere, we will compare the DIABLO results to the results of traditional single-omics analyses. In our case, a GWAS and eQTL analysis were performed to detect genomic variants associated with the disease status of the samples. The mode of action of significant markers (i.e. QTL, cis-eQTL or trans-eQTL). The GWAS status (high-scoring or not) of each marker was recorded in the genomics features metadata table:\n\nget_features_metadata(mo_set_complete)[[\"snps\"]] |> \n  pull(qtl_type) |> \n  unique()\n#> [1] \"non signif.\" \"cis eQTL\"    \"trans eQTL\"  \"QTL\"\n\nFor the transcriptomics and metabolomics dataset, a differential expression (DE) analysis was performed on each of them to compare control and BRD animals. The resulting adjusted p-value, log2-fold change or t-value, status (upregulated, downregulated or not differentially expressed) and significance (differentially expressed or not) of each gene or compound are recorded in each dataset’s features metadata:\n\nget_features_metadata(mo_set_complete)[[\"rnaseq\"]] |> \n  select(feature_id, log_fc:de_status) |> \n  head()\n#>                            feature_id      log_fc    log_cpm          f\n#> ENSBTAG00000000005 ENSBTAG00000000005  0.13603041  5.9051177  4.1626465\n#> ENSBTAG00000000008 ENSBTAG00000000008 -0.12965356 -0.7437052  1.0676845\n#> ENSBTAG00000000009 ENSBTAG00000000009  1.27141158 -2.5627934 23.9562951\n#> ENSBTAG00000000010 ENSBTAG00000000010  0.39567729  6.2563594 60.5303416\n#> ENSBTAG00000000011 ENSBTAG00000000011  0.07766873 -2.7608361  0.1418457\n#> ENSBTAG00000000012 ENSBTAG00000000012  0.15756169  3.6628775 11.0448775\n#>                         p_value          fdr de_signif de_status\n#> ENSBTAG00000000005 4.324808e-02 7.170137e-02    Not DE    Not DE\n#> ENSBTAG00000000008 3.032916e-01 3.938643e-01    Not DE    Not DE\n#> ENSBTAG00000000009 2.731328e-06 9.665375e-06    Not DE    Not DE\n#> ENSBTAG00000000010 1.581955e-12 1.521160e-11    Not DE    Not DE\n#> ENSBTAG00000000011 7.070363e-01 7.773874e-01    Not DE    Not DE\n#> ENSBTAG00000000012 1.141125e-03 2.623062e-03    Not DE    Not DE\n\nget_features_metadata(mo_set_complete)[[\"metabolome\"]] |>  \n  select(feature_id, t_value:de_status) |>\n  head()\n#>           feature_id     t_value      p_value         padj de_signif\n#> HMDB00001  HMDB00001  -0.5557020 5.797635e-01 6.784466e-01    Not DE\n#> HMDB00008  HMDB00008   0.2181562 8.276321e-01 8.925444e-01    Not DE\n#> HMDB00042  HMDB00042 -12.5323491 1.753101e-24 4.821028e-23        DE\n#> HMDB00043  HMDB00043  -7.9073179 7.827088e-13 3.913544e-12        DE\n#> HMDB00060  HMDB00060  -0.4369834 6.628164e-01 7.439776e-01    Not DE\n#> HMDB00062  HMDB00062   8.2347595 1.271549e-13 6.993518e-13        DE\n#>               de_status\n#> HMDB00001        Not DE\n#> HMDB00008        Not DE\n#> HMDB00042 downregulated\n#> HMDB00043 downregulated\n#> HMDB00060        Not DE\n#> HMDB00062   upregulated\n\n\n13.2.1 Table of counts of selected genes against a grouping\nAs DIABLO performs feature selection, it is of interest to assess how many (e)QTLs and DE genes and compounds were retained for each latent component. We can use the evaluate_feature_selection_table() function to generate a table of counts comparing the features selected for each latent component to a features grouping (in our case, the results of the single-omics analyses). The features grouping is obtained from the features metadata stored in the MultiDataSet object. The function takes as input the integration result object, the MultiDataSet object and a named list giving for each dataset the name of the column from their features metadata table containing the features grouping:\n\ndiablo_evaluation_counts_table <- evaluate_feature_selection_table(\n  diablo_output,\n  mo_data = mo_set_complete,\n  col_names = list(\n    \"snps\" = \"qtl_type\",\n    \"rnaseq\" = \"de_signif\",\n    \"metabolome\" = \"de_signif\"\n  )\n)\n\ndiablo_evaluation_counts_table |> \n  filter(latent_dimension == \"Component 1\")\n#> # A tibble: 8 × 6\n#>   method latent_dimension dataset    feature_label selected not_selected\n#>   <chr>  <fct>            <fct>      <chr>            <int>        <int>\n#> 1 DIABLO Component 1      snps       cis eQTL             1            2\n#> 2 DIABLO Component 1      snps       non signif.         17          975\n#> 3 DIABLO Component 1      snps       QTL                  1            0\n#> 4 DIABLO Component 1      snps       trans eQTL           1            3\n#> 5 DIABLO Component 1      rnaseq     DE                  23           52\n#> 6 DIABLO Component 1      rnaseq     Not DE               7          912\n#> 7 DIABLO Component 1      metabolome DE                  10           20\n#> 8 DIABLO Component 1      metabolome Not DE               0           25\n\ndiablo_evaluation_counts_table |> \n  filter(latent_dimension == \"Component 2\")\n#> # A tibble: 8 × 6\n#>   method latent_dimension dataset    feature_label selected not_selected\n#>   <chr>  <fct>            <fct>      <chr>            <int>        <int>\n#> 1 DIABLO Component 2      snps       cis eQTL             0            3\n#> 2 DIABLO Component 2      snps       non signif.         25          967\n#> 3 DIABLO Component 2      snps       QTL                  0            1\n#> 4 DIABLO Component 2      snps       trans eQTL           0            4\n#> 5 DIABLO Component 2      rnaseq     DE                   0           75\n#> 6 DIABLO Component 2      rnaseq     Not DE              15          904\n#> 7 DIABLO Component 2      metabolome DE                   6           24\n#> 8 DIABLO Component 2      metabolome Not DE               4           21\n\nWe can see that for the first latent component, only three out of the eight (e)QTLs were selected 1; two-third of the genes selected were found differentially expressed; and all ten of the selected compounds were found differentially expressed. Conversely, for the second latent component, none of the selected markers were QTLs, and none of the selected genes were differentially expressed. This makes sense, as the DIABLO analysis was run with the goal of separating the control and infected animals; therefore it makes sense that the features selected for the first latent component, which is the one best able to separate the groups, are the features detected as differentially expressed. On the contrary, the second latent component is constructed to be orthogonal to the first one, therefore the features selected will likely not be differentially expressed.\nWith this function, we can focus on only some datasets, by changing which datasets are present in the list passed to col_names. Similarly, we can select specific latent dimensions through the latent_dimensions parameter. For example, let us count the number of DE genes selected with the first latent component:\n\nevaluate_feature_selection_table(\n  diablo_output,\n  mo_data = mo_set_complete,\n  col_names = list(\"rnaseq\" = \"de_signif\"),\n  latent_dimensions = \"Component 1\"\n)\n#> # A tibble: 2 × 6\n#>   method latent_dimension dataset feature_label selected not_selected\n#>   <chr>  <fct>            <fct>   <chr>            <int>        <int>\n#> 1 DIABLO Component 1      rnaseq  DE                  23           52\n#> 2 DIABLO Component 1      rnaseq  Not DE               7          912\n\nNote that this function is useful for integration methods that perform feature selection, such as DIABLO or sO2PLS, but will be irrelevant for methods that do not perform feature selection (for example MOFA tends to assign a non-null weight to most features).\n\n13.2.2 Plotting features weight against a covariate\nWe can go further and compare the weights or importance scores given to the features for each latent component to the outcome of the single-omics results. This can be done with the plot_features_weight_covariate() function. As its name suggests, this function displays the features weight for each latent dimension against some covariate obtained from the features metadata tables. Again, we will look at the results of the GWAS/QTL and DE analyses and see whether (e)QTLs, DE genes and compounds were assigned higher weights is some of the latent components constructed with DIABLO. The input parameters for this function are similar to those for the evaluate_feature_selection_table() function: we need to pass the results of the integration method, the MultiDataSet object, and the named list giving the column in each features metadata table containing information about the features grouping. The latter is passed to the covariate argument of the function. If some datasets are not present in this list, they won’t be present in the plot.\n\nplot_features_weight_covariate(\n  diablo_output, \n  mo_data = mo_set_complete, \n  covariate = list(\n    \"snps\" = \"qtl_type\", \n    \"rnaseq\" = \"de_status\", \n    \"metabolome\" = \"de_status\"\n  )\n)\n#> Warning: Groups with fewer than two data points have been dropped.\n#> Groups with fewer than two data points have been dropped.\n#> Groups with fewer than two data points have been dropped.\n#> Groups with fewer than two data points have been dropped.\n#> Groups with fewer than two data points have been dropped.\n#> Groups with fewer than two data points have been dropped.\n#> Groups with fewer than two data points have been dropped.\n#> Groups with fewer than two data points have been dropped.\n\n\n\n\nBy default, the function plots on the y-axis the signed importance score of the features, that is, their importance score to which the sign of their weight was added. This can be controlled via the features_metric argument. We see that most of the points have an importance score of 0, because most of the features were not selected. We can focus on only those features with a non-null weight with the remove_null_weight argument:\n\nplot_features_weight_covariate(\n  diablo_output, \n  mo_data = mo_set_complete, \n  covariate = list(\n    \"snps\" = \"qtl_type\", \n    \"rnaseq\" = \"de_status\", \n    \"metabolome\" = \"de_status\"\n  ),\n  remove_null_weight = TRUE\n)\n#> Warning: Groups with fewer than two data points have been dropped.\n#> Groups with fewer than two data points have been dropped.\n#> Groups with fewer than two data points have been dropped.\n#> Groups with fewer than two data points have been dropped.\n#> Groups with fewer than two data points have been dropped.\n\n\n\n\nHere, we see that for the first latent component, selected genes that were also found up-regulated were assigned on average a higher importance score that selected genes that were found non DE. Also, for the metabolomics dataset, selected compounds that were found up-regulated were assigned a positive weight while those found down-regulated were assigned a negative weight.\nNote that with the plot_features_weight_covariate() function, we can also plot the features against a continuous covariate, e.g. the log2-fold change obtained with the differential expressions:\n\nplot_features_weight_covariate(\n  diablo_output, \n  mo_data = mo_set_complete, \n  covariate = list(\n    \"rnaseq\" = \"log_fc\", \n    \"metabolome\" = \"t_value\"\n  )\n)\n#> Warning: Removed 508 rows containing non-finite values (`stat_smooth()`).\n#> Warning: Removed 508 rows containing missing values (`geom_point()`).\n\n\n\n\nWe can see a nice trend between compounds’ t-value and their signed importance score in the differential expression analysis for the first latent component.\nWe can further change the colour or shape of the points according to some information from the features metadata (information must be passed as a named list as for the covariate).\n\nplot_features_weight_covariate(\n  diablo_output, \n  mo_data = mo_set_complete, \n  covariate = list(\n    \"rnaseq\" = \"log_fc\", \n    \"metabolome\" = \"t_value\"\n  ),\n  colour_by = list(\n    \"rnaseq\" = \"fdr\",\n    \"metabolome\" = \"padj\"\n  )\n) +\n  scale_colour_viridis_c(aesthetics = c(\"colour\", \"fill\"))\n#> Warning: Removed 508 rows containing non-finite values (`stat_smooth()`).\n#> Warning: Removed 508 rows containing missing values (`geom_point()`).\n\n\n\n\nNote that for continuous covariates, as with the function plot_samples_score_covariate(), a loess curve is fit to summarise the trend between the covariates and the features weight. If colour_by is used, and the corresponding variables are categorical, a different loess curve is fitted for each category. If instead the colour_by variables are numeric, a single loess curve will be plotted for each latent dimension and dataset."
  },
  {
    "objectID": "evaluation.html#features-set-enrichment",
    "href": "evaluation.html#features-set-enrichment",
    "title": "13  Evaluating the integration results",
    "section": "\n13.3 Features set enrichment",
    "text": "13.3 Features set enrichment\nIn addition to looking at the distribution of features importance score or counting the number of selected features, we can also perform an enrichment to assess whether each of the latent dimensions constructed is enriched for some features set of interest. Features sets are groups of features that belong in a similar category: e.g. all features involved in a same biological pathway, or with the same GO term annotation, or even all up- or down-regulated features. They are built using prior knowledge, for example information extracted from databases, or constructed from the results of previous analyses. Importantly, a feature can belong to more than one set (for example a compound can be involved in several biological pathways).\n\n13.3.1 Constructing feature sets\nWith the moiraine package, there are two ways to obtain feature sets to perform enrichment or for plots. The first one is to extract information from the features metadata tables stored in our MultiDataSet object; which is done with the make_feature_sets_from_fm() function. Note that if some features grouping is stored in the features metadata, it means that features can only belong to one set. For example, we will use the results of the single-omics analyses to group the features into sets: QTLs, cis-eQTLs, trans-eQTLs and non significant genomics markers, and up-regulated, down-regulated or non DE genes and compounds. Again, the function accepts a named list giving for each dataset the name of the column in the corresponding features metadata table to use to generate the groups, passed to the col_names argument of the function. It returns a named list where each element is a feature set, and contains the ID of the features in the set:\n\n\ntar_target(\n  sets_single_omics,\n  make_feature_sets_from_fm(\n    mo_set_complete,\n    col_names = list(\n      \"snps\" = \"qtl_type\", \n      \"rnaseq\" = \"de_status\", \n      \"metabolome\" = \"de_status\"\n    )\n  )\n)\n\n\n\ntar_read(sets_single_omics) |> \n  str()\n#> List of 10\n#>  $ non signif.               : chr [1:23000] \"1_41768691\" \"10-27008241-A-C-rs42918694\" \"10-37505419-T-C-rs136559242\" \"10-49904259-G-A-rs471723345\" ...\n#>  $ cis eQTL                  : chr [1:31] \"ARS-BFGL-BAC-13210\" \"ARS-BFGL-NGS-113310\" \"ARS-BFGL-NGS-5022\" \"ARS-BFGL-NGS-59463\" ...\n#>  $ trans eQTL                : chr [1:4] \"ARS-BFGL-NGS-80280\" \"BovineHD0100032240\" \"BovineHD2300010006\" \"Hapmap55381-rs29025399\"\n#>  $ QTL                       : chr \"BovineHD1800016801\"\n#>  $ Not DE - rnaseq           : chr [1:20224] \"ENSBTAG00000000005\" \"ENSBTAG00000000008\" \"ENSBTAG00000000009\" \"ENSBTAG00000000010\" ...\n#>  $ upregulated - rnaseq      : chr [1:102] \"ENSBTAG00000000377\" \"ENSBTAG00000000783\" \"ENSBTAG00000001051\" \"ENSBTAG00000001785\" ...\n#>  $ downregulated - rnaseq    : chr [1:9] \"ENSBTAG00000001032\" \"ENSBTAG00000004824\" \"ENSBTAG00000011990\" \"ENSBTAG00000012403\" ...\n#>  $ Not DE - metabolome       : chr [1:25] \"HMDB00001\" \"HMDB00008\" \"HMDB00060\" \"HMDB00097\" ...\n#>  $ downregulated - metabolome: chr [1:20] \"HMDB00042\" \"HMDB00043\" \"HMDB00064\" \"HMDB00094\" ...\n#>  $ upregulated - metabolome  : chr [1:10] \"HMDB00062\" \"HMDB00092\" \"HMDB00159\" \"HMDB00169\" ...\n\nBy default, the function keeps the different omics features separate: here for example, there is a “Not DE” set for the transcriptomics dataset, and a “Not DE” set for the metabolomics dataset. When there is no ambiguity as to which omics dataset they represent, the name of the dataset is not included in the set’s name. It is possible to merge feature sets with the same name between the omics datasets, by setting the combine_omics_sets argument to TRUE:\n\n\ntar_target(\n  sets_single_omics_merged,\n  make_feature_sets_from_fm(\n    mo_set_complete,\n    col_names = list(\n      \"snps\" = \"qtl_type\", \n      \"rnaseq\" = \"de_status\", \n      \"metabolome\" = \"de_status\"\n    ),\n    combine_omics_sets = TRUE\n  )\n)\n\n\n\ntar_read(sets_single_omics_merged) |> \n  str()\n#> List of 7\n#>  $ non signif.  : chr [1:23000] \"1_41768691\" \"10-27008241-A-C-rs42918694\" \"10-37505419-T-C-rs136559242\" \"10-49904259-G-A-rs471723345\" ...\n#>  $ cis eQTL     : chr [1:31] \"ARS-BFGL-BAC-13210\" \"ARS-BFGL-NGS-113310\" \"ARS-BFGL-NGS-5022\" \"ARS-BFGL-NGS-59463\" ...\n#>  $ trans eQTL   : chr [1:4] \"ARS-BFGL-NGS-80280\" \"BovineHD0100032240\" \"BovineHD2300010006\" \"Hapmap55381-rs29025399\"\n#>  $ QTL          : chr \"BovineHD1800016801\"\n#>  $ Not DE       : chr [1:20249] \"ENSBTAG00000000005\" \"ENSBTAG00000000008\" \"ENSBTAG00000000009\" \"ENSBTAG00000000010\" ...\n#>  $ upregulated  : chr [1:112] \"ENSBTAG00000000377\" \"ENSBTAG00000000783\" \"ENSBTAG00000001051\" \"ENSBTAG00000001785\" ...\n#>  $ downregulated: chr [1:29] \"ENSBTAG00000001032\" \"ENSBTAG00000004824\" \"ENSBTAG00000011990\" \"ENSBTAG00000012403\" ...\n\nNow the not DE set contains all genes and compounds ID that have not been found differentially expressed.\nAlternatively, feature sets can be constructed from an input data-frame. This is useful when looking at pathways or GO annotations, for which features can belong to several sets at once, as this information cannot be stored in a features metadata table. Here, we will use the GO terms assigned to the genes. Note that in this example, the feature sets will contain features from only one omics dataset, but it doesn’t have to be; instead the sets could contain features from different omics datasets.\nWe start by reading in the data-frame of GO terms. We will focus on GO terms relating to biological processes for this example:\n\n\nlist(\n  tar_target(\n    rnaseq_go_terms_file,\n    system.file(\n      \"extdata/transcriptomics_go_annotation.csv\", \n      package = \"moiraine\"\n    ),\n    format = \"file\"\n  ),\n  \n  tar_target(\n    rnaseq_go_df,\n    read_csv(rnaseq_go_terms_file) |> \n      filter(go_domain == \"Biological process\")\n  )\n)\n\n\n\ntar_load(rnaseq_go_df)\n\ndim(rnaseq_go_df)\n#> [1] 89226     4\nhead(rnaseq_go_df)\n#> # A tibble: 6 × 4\n#>   gene_id            go_id      go_name                                go_domain\n#>   <chr>              <chr>      <chr>                                  <chr>    \n#> 1 ENSBTAG00000000005 GO:0006468 protein phosphorylation                Biologic…\n#> 2 ENSBTAG00000000005 GO:0007165 signal transduction                    Biologic…\n#> 3 ENSBTAG00000000005 GO:0031623 receptor internalization               Biologic…\n#> 4 ENSBTAG00000000008 GO:0006813 potassium ion transport                Biologic…\n#> 5 ENSBTAG00000000009 GO:0006355 regulation of DNA-templated transcrip… Biologic…\n#> 6 ENSBTAG00000000009 GO:0006357 regulation of transcription by RNA po… Biologic…\n\nThe data-frame contains one row per gene (gene_id) / GO term (go_id) pair. In addition, the name of each GO term and the category (biological process, molecular function or cellular component) are indicated in the go_name and go_domain columns, respectively. When reading in the file, we’ve restricted the GO terms to only those that correspond to biological processes.\nWe can turn this data-frame into a list of feature sets with the make_feature_sets_from_df() function. The function takes as input the data-frame, as well as the name of the column in the data-frame that contains the features ID (col_id argument) and the name of the column in the data-frame that contains the feature sets ID or name (col_set argument):\n\n\ntar_target(\n  go_sets,\n  make_feature_sets_from_df(\n    rnaseq_go_df,\n    col_id = \"gene_id\",\n    col_set = \"go_id\"\n  )\n)\n\n\n\ntar_load(go_sets)\n\nlength(go_sets)\n#> [1] 10745\nhead(go_sets) |> \n  str()\n#> List of 6\n#>  $ GO:0006468: chr [1:580] \"ENSBTAG00000000005\" \"ENSBTAG00000000013\" \"ENSBTAG00000000056\" \"ENSBTAG00000000184\" ...\n#>  $ GO:0007165: chr [1:737] \"ENSBTAG00000000005\" \"ENSBTAG00000000073\" \"ENSBTAG00000000081\" \"ENSBTAG00000000105\" ...\n#>  $ GO:0031623: chr [1:31] \"ENSBTAG00000000005\" \"ENSBTAG00000000308\" \"ENSBTAG00000001050\" \"ENSBTAG00000001139\" ...\n#>  $ GO:0006813: chr [1:96] \"ENSBTAG00000000008\" \"ENSBTAG00000000082\" \"ENSBTAG00000000745\" \"ENSBTAG00000000973\" ...\n#>  $ GO:0006355: chr [1:915] \"ENSBTAG00000000009\" \"ENSBTAG00000000040\" \"ENSBTAG00000000052\" \"ENSBTAG00000000074\" ...\n#>  $ GO:0006357: chr [1:627] \"ENSBTAG00000000009\" \"ENSBTAG00000000039\" \"ENSBTAG00000000052\" \"ENSBTAG00000000154\" ...\n\n\n13.3.2 Filtering feature sets against the datasets\nBefore performing any enrichment, we want to make sure that the only features in the sets are the ones that were measured in the datasets. This is part of ensuring that an appropriate background or reference features set is used when performing enrichment (see for example Timmons, Szkop, and Gallagher (2015)). To this end, the reduce_feature_sets_data() function filters a list of feature sets so that only features present in a given MultiDataSet object are kept in the sets; it then removes empty feature sets. Note that for this filtering, we are using the MultiDataSet object that contains the full omics datasets, before pre-filtering:\n\n\ntar_target(\n  go_sets_filtered,\n  reduce_feature_sets_data(go_sets, mo_set_complete)\n)\n\n\nThe function yields the following message:\n\n#> All features in sets are in the multi-omics dataset.\n\n\ntar_load(go_sets_filtered)\n\n\n13.3.3 Checking the number of features assigned to sets\nWe can then check the number of features that are assigned to at least one set with the check_feature_sets() function, to get an idea of the coverage of our annotation. We will restrict the check to the transcriptomics dataset, since the GO annotation only covers genes:\n\nsets_check <- check_feature_sets(\n  go_sets_filtered, \n  mo_set_complete,\n  datasets = \"rnaseq\"\n)\n#> rnaseq dataset: 14,364 of 20,335 (70.6%) features assigned to at least one set.\n\nsets_check\n#> # A tibble: 1 × 5\n#>   dataset n_annotated     n frac_annotated message                              \n#>   <fct>         <int> <int>          <dbl> <chr>                                \n#> 1 rnaseq        14364 20335          0.706 rnaseq dataset: 14,364 of 20,335 (70…\n\nThe function returns a tibble giving the name of the datasets, the number and fraction of features from the dataset that are present in at least one feature set (n_annotated and frac_annotated columns), the total number of features in the corresponding dataset (n column), as well as sentence summarising this information (message column) that is useful for reporting. In this example, 70.6% of the genes from the transcriptomics dataset are assigned to at least one GO term. This is important to check as the annotation coverage will impact the quality of the enrichment results that we get.\n\n13.3.4 Enrichment of latent dimensions\nWe are now ready to perform an enrichment of the latent dimensions. There are many ways to perform functional enrichment (e.g. see Zhao and Rhee (2023)): based on over-representation, feature ranking, or even topology when the feature sets are representing biological pathways. Here, we are not trying to provide an exhaustive list of options; however it is relatively straightforward to extract from an integration method output the features importance or list of selected features for a specific latent dimension, and use it for enrichment with the package of your choice.\nIn moiraine, we use the gage package (Luo et al. 2009) to perform the enrichment of each latent dimension against a list of feature sets. It uses a two-sample t-test to assess whether features in a set have higher importance scores than features not in the set. The evaluate_method_enrichment() function takes as input the results from an integration method in a standardised format (here our diablo_output object), and performs an enrichment for each latent dimension using the features sets provided as a list. We can focus on specific datasets or latent dimensions by passing their name to the datasets or latent_dimensions arguments, respectively. There are a number of parameters that need to be set:\n\nuse_abs: by default, the function uses the absolute value of the importance score to perform the enrichment, which allows it to detect features sets in which features are given strong weights that are both positive and negative. If we instead want to search for features sets in which the weight of the features are coordinated (i.e. either all positive or negative), we can set the use_abs argument to FALSE.\nmin_set_size: the minimum number of features in a set needed for the set to be considered for enrichment. The default value is 5, i.e. sets with less than 5 features will not be tested for enrichment.\nadd_missing_features and mo_data: when performing multi-omics integration, it is highly likely that the omics datasets have been pre-filtered prior to the analysis, which means that some features will not have received a weight in the results of the integration analysis. This can bias the enrichment results, as these are based on only features that have a weight. So if a features set contains 50 features, but 40 of these were discarded during the pre-filtering step, only the remaining 10 features will be considered when performing an enrichment. This might lead to finding a latent dimension enriched for this set, even though the set might not be biologically relevant since 80% of its features did not even pass the pre-filtering step. To account for that, it is possible to add to the integration results all of the features in a MultiDataSet object that are not present in the results. These features will be assigned a weight of 0 to emphasise that they were not found to play any role for the latent dimensions. This is done by setting add_missing_features to TRUE, and passing to mo_data a MultiDataSet object that contains the omics datasets that have not been filtered. This way, the background set used in the enrichment will be all features measured in the omics datasets, and not only the ones that passed the pre-filtering step.\nsets_info_df and col_set: the feature sets are passed as a named list, therefore the only information that we have about these sets are their names as found in the list. To facilitate the interpretation of the enrichment results, it is possible to pass a data-frame giving information about the sets, through the sets_info_df argument. This information will be added to the enrichment results table. In that case, the col_set argument must also be specified: it takes the name of the column in the data-frame passed to sets_info_df that contains the sets ID or named as seen in the list. Here we will create this data-frame as follows:\n\n\n\ntar_target(\n  go_sets_info,\n  rnaseq_go_df |>\n    dplyr::select(go_id, go_name) |>\n    dplyr::distinct()\n)\n\n\n\ntar_read(go_sets_info) |> \n  head()\n#> # A tibble: 6 × 2\n#>   go_id      go_name                                         \n#>   <chr>      <chr>                                           \n#> 1 GO:0006468 protein phosphorylation                         \n#> 2 GO:0007165 signal transduction                             \n#> 3 GO:0031623 receptor internalization                        \n#> 4 GO:0006813 potassium ion transport                         \n#> 5 GO:0006355 regulation of DNA-templated transcription       \n#> 6 GO:0006357 regulation of transcription by RNA polymerase II\n\nWe can run the enrichment analysis:\n\n\ntar_target(\n  diablo_enrichment_results,\n  evaluate_method_enrichment(\n    diablo_output,\n    go_sets_filtered,\n    datasets = \"rnaseq\",\n    use_abs = TRUE,\n    min_set_size = 10,\n    add_missing_features = TRUE,\n    mo_data = mo_set_complete,\n    sets_info_df = go_sets_info,\n    col_set = \"go_id\"\n  )\n)\n\n\nThe function returns a table giving for each latent component (latent_dimension) and feature set (set_id) the enrichment statistics (stat_mean), p-value (pvalue), adjusted p-value (adj_pvalue) as well as the number of features in the set that are present in the integration results (set_size). The table is arranged by increasing adjusted p-value, such that the significant results are at the top of the table. It is important to note that the multiple testing correction applied to the p-values occurs independently for each latent dimension, but there is no multiple testing correction performed across the latent dimensions. This can easily be done by the user, and should be considered when reporting the results.\n\ntar_read(diablo_enrichment_results) |> \n  head()\n#> # A tibble: 6 × 7\n#>   latent_dimension set_id     stat_mean pvalue adj_pvalue set_size go_name      \n#>   <fct>            <chr>          <dbl>  <dbl>      <dbl>    <dbl> <chr>        \n#> 1 Component 2      GO:0006935     1.39  0.0846      0.601       57 chemotaxis   \n#> 2 Component 2      GO:0042274     1.37  0.0889      0.601       54 ribosomal sm…\n#> 3 Component 2      GO:0050727     1.27  0.104       0.601       56 regulation o…\n#> 4 Component 2      GO:0006364     0.977 0.166       0.601       77 rRNA process…\n#> 5 Component 2      GO:0030890     0.979 0.168       0.601       30 positive reg…\n#> 6 Component 2      GO:0043029     0.983 0.168       0.601       25 T cell homeo…\n\nIn that case, unsurprisingly, neither of the latent components were enriched for any GO term. This makes sense since DIABLO performed a strong feature selection, so very few genes had non-null weights. We can repeat the enrichment with the MOFA integration results to show more interesting results. We will run the enrichment only for the first three factors for conciseness:\n\n\ntar_target(\n  mofa_enrichment_results,\n  evaluate_method_enrichment(\n    mofa_output,\n    go_sets_filtered,\n    datasets = \"rnaseq\",\n    latent_dimensions = paste(\"Factor\", 1:3),\n    use_abs = TRUE,\n    min_set_size = 10,\n    add_missing_features = TRUE,\n    mo_data = mo_set_complete,\n    sets_info_df = go_sets_info,\n    col_set = \"go_id\"\n  )\n)\n\n\nThis time, there are a couple of small p-values (even though the adjusted p-values are all quite large):\n\ntar_load(mofa_enrichment_results)\n\nmofa_enrichment_results |> head()\n#> # A tibble: 6 × 7\n#>   latent_dimension set_id     stat_mean   pvalue adj_pvalue set_size go_name    \n#>   <fct>            <chr>          <dbl>    <dbl>      <dbl>    <dbl> <chr>      \n#> 1 Factor 3         GO:0031424      4.13 0.000275      0.549       20 keratiniza…\n#> 2 Factor 3         GO:0045109      3.60 0.000713      0.711       25 intermedia…\n#> 3 Factor 3         GO:0030855      2.56 0.00651       0.764       56 epithelial…\n#> 4 Factor 3         GO:0031069      2.07 0.0244        0.764       25 hair folli…\n#> 5 Factor 3         GO:0030216      1.90 0.0317        0.764       49 keratinocy…\n#> 6 Factor 3         GO:0001942      1.82 0.0373        0.764       38 hair folli…\n\nWe can see for example that MOFA factor 3 seems enriched in genes associated with the keratinization GO term (GO:0031424). For factor 1 (the factor separating the healthy and infected animals), the keratinization term also yields the smallest p-value, together with several GO terms related to inflammation (even though after correction for multiple testing these p-values are no longer significant):\n\nmofa_enrichment_results |>\n  filter(latent_dimension == \"Factor 1\") |> \n  head()\n#> # A tibble: 6 × 7\n#>   latent_dimension set_id     stat_mean  pvalue adj_pvalue set_size go_name     \n#>   <fct>            <chr>          <dbl>   <dbl>      <dbl>    <dbl> <chr>       \n#> 1 Factor 1         GO:0031424      2.70 0.00516      0.786       20 keratinizat…\n#> 2 Factor 1         GO:0045109      2.43 0.00948      0.786       25 intermediat…\n#> 3 Factor 1         GO:0010951      2.15 0.0208       0.786       25 negative re…\n#> 4 Factor 1         GO:0006954      1.86 0.0318       0.786      165 inflammator…\n#> 5 Factor 1         GO:0050727      1.75 0.0421       0.786       56 regulation …\n#> 6 Factor 1         GO:0007166      1.62 0.0533       0.786      138 cell surfac…\n\n\n13.3.5 Plotting features weight for feature sets\nWe can dig into the results of the enrichment by visualising the distribution of features weight or importance score between features that are in a specific features set vs features that are not in the set. For example, to continue with the MOFA example, let’s look at the importance score of genes associated with the GO term GO:0031424. We’ll only look at factors 1 and 3 for this example:\n\nplot_features_weight_set(\n  mofa_output,\n  go_sets_filtered[[\"GO:0031424\"]],\n  set_name = \"GO:0031424 (keratinization)\",\n  features_metric = \"importance\",\n  datasets = \"rnaseq\",\n  latent_dimensions = paste(\"Factor\", c(1, 3)),\n  point_alpha = 0.2\n)\n\n\n\n\nIn the resulting plot, we can see for each dataset (in this case, we’re only looking at the transcriptomics dataset since we have gene sets) and latent dimensions (rows of the plot) the distribution of features importance for genes in the set vs not in the set. We can see that the GO term investigated contains 20 genes, and in total, 994 genes have been assigned a weight with MOFA (because we have performed some pre-filtering on the transcriptomics dataset prior to running MOFA). Therefore, out of all the genes in the set, 9 of them have no weight (they did not pass the pre-filtering step). We can add these features that did not make it into the MOFA input data in the same way as we did for the enrichment function, namely by setting the add_missing_features argument to TRUE and passing the non-filtering MultiDataSet object through mo_data:\n\nplot_features_weight_set(\n  mofa_output,\n  go_sets_filtered[[\"GO:0031424\"]],\n  set_name = \"GO:0031424 (keratinization)\",\n  features_metric = \"importance\",\n  datasets = \"rnaseq\",\n  latent_dimensions = paste(\"Factor\", c(1, 3)),\n  point_alpha = 0.2,\n  add_missing_features = TRUE,\n  mo_data = mo_set_complete\n)\n\n\n\n\nThis is the distribution of values that were used for the enrichment test, but it’s not very useful to look at since the vast majority of the genes have a weight of zero."
  },
  {
    "objectID": "evaluation.html#assessing-samples-clustering",
    "href": "evaluation.html#assessing-samples-clustering",
    "title": "13  Evaluating the integration results",
    "section": "\n13.4 Assessing samples clustering",
    "text": "13.4 Assessing samples clustering\nAnother aspect that we can evaluate is whether the integration method was able to separate different groups of samples, for example to identify differences between control and treatment samples. This is done by comparing the coordinates of the samples in the space spanned by the latent dimensions created (i.e. the samples score) to a samples label that is obtained from the samples metadata. We can use for that the silhouette score, which is a metric that quantifies how well-defined different clusters are in a given space, i.e. how well-grouped points from a same cluster (here samples group) are, and how separate they are from points from other clusters. First, a silhouette score (or silhouette width) is computed for each individual point (here sample). Then, these values are averaged over all points in a given cluster to yield a cluster silhouette score. The resulting values, both at the point- and cluster- level, can range from -1 to 1. Negative values indicate that the point is grouped with points from another cluster, while positive values indicate that the point is grouped with other points from its cluster. Values close to 0 show that the clustering is ambiguous, while scores close to 1 are indicative of well-defined clusters.\nThe compute_samples_silhouette() function relies on the cluster::silhouette() function from the cluster package to compute silhouette score. It takes as input the integration results in a standardised format, as well as the MultiDataSet object (to access the samples metadata) and the name of the column in the samples metadata table that contains the samples grouping information. In addition, it is possible to specify the distance metric that should be used to compute distances between the samples (through the distance_metric argument). By default, the function uses euclidean distances, but other options are available.\nHere, we will check how well DIABLO managed to separate the bruising groups:\n\n\ntar_target(\n  diablo_silhouette,\n  compute_samples_silhouette(\n    diablo_output,\n    mo_set_complete,\n    \"status\"\n  )\n)\n\n\n\ntar_load(diablo_silhouette)\n\ndiablo_silhouette\n#> $samples_silhouette\n#> # A tibble: 135 × 4\n#>    sample_id group   neighbour_group silhouette_width\n#>    <chr>     <fct>   <fct>                      <dbl>\n#>  1 G1979     BRD     Control                    0.334\n#>  2 G2500     BRD     Control                    0.255\n#>  3 G3030     BRD     Control                    0.328\n#>  4 G3068     BRD     Control                    0.370\n#>  5 G3121     BRD     Control                    0.423\n#>  6 G3315     Control BRD                        0.529\n#>  7 G3473     Control BRD                        0.355\n#>  8 G3474     Control BRD                        0.477\n#>  9 G3550     BRD     Control                    0.362\n#> 10 G3594     Control BRD                        0.567\n#> # ℹ 125 more rows\n#> \n#> $groups_average_silhouette\n#> # A tibble: 2 × 2\n#>   group   group_average_width\n#>   <fct>             <dbl[1d]>\n#> 1 BRD                   0.309\n#> 2 Control               0.455\n\nThe function returns a list with two elements: a tibble of samples silhouette widths (samples_silhouette), and a tibble of groups average silhouette (groups_average_silhouette). In the first table, the group column indicates for each sample the group to which it is assigned (based on the samples metadata), and the neighbour_group column indicates the closest other group in the latent dimensions space (which is not very useful in this case since we only have two groups). The samples silhouette width is shown in the silhouette_width column. This is very useful to identify “outlier” samples that were not grouped as expected:\n\ndiablo_silhouette$samples_silhouette |> \n  filter(silhouette_width < 0)\n#> # A tibble: 1 × 4\n#>   sample_id group neighbour_group silhouette_width\n#>   <chr>     <fct> <fct>                      <dbl>\n#> 1 P4735     BRD   Control                   -0.217\n\nHere, there is one sample from an infected animal that clusters with the control samples in the latent dimensions space.\nThe average silhouette score for the two disease status groups are both positive, although not close to 1, indicating that DIABLO did a reasonable job of identifying differences between the two groups:\n\ndiablo_silhouette$groups_average_silhouette\n#> # A tibble: 2 × 2\n#>   group   group_average_width\n#>   <fct>             <dbl[1d]>\n#> 1 BRD                   0.309\n#> 2 Control               0.455\n\nThis is expected, since DIABLO is a supervised integration method which tries to maximise the separation between groups of samples.\nWe can repeat the operation for the MOFA results. By default, the compute_samples_silhouette() function uses all latent dimensions to compute distances between samples, but it is possible to specify which latent dimensions should be considered through the latent_dimensions argument. For example, we will see how the first three MOFA factors separate the disease status groups:\n\n\ntar_target(\n  mofa_silhouette,\n  compute_samples_silhouette(\n    mofa_output,\n    mo_set_complete,\n    \"status\",\n    latent_dimensions = paste(\"Factor\", 1:3)\n  )\n)\n\n\n\ntar_load(mofa_silhouette)\n\nmofa_silhouette$groups_average_silhouette\n#> # A tibble: 2 × 2\n#>   group   group_average_width\n#>   <fct>             <dbl[1d]>\n#> 1 BRD                   0.257\n#> 2 Control               0.524\n\nBoth groups’ silhouette scores are positive, although the BRD group silhouette is not very high. Also, more samples have a silhouette width below 0.\n\nmofa_silhouette$samples_silhouette |> \n  filter(silhouette_width < 0)\n#> # A tibble: 11 × 4\n#>    sample_id group neighbour_group silhouette_width\n#>    <chr>     <fct> <fct>                      <dbl>\n#>  1 O3720     BRD   Control                 -0.430  \n#>  2 O4492     BRD   Control                 -0.246  \n#>  3 O4919     BRD   Control                 -0.440  \n#>  4 O5003     BRD   Control                 -0.243  \n#>  5 P4666     BRD   Control                 -0.0994 \n#>  6 P4735     BRD   Control                 -0.429  \n#>  7 R50       BRD   Control                 -0.168  \n#>  8 R5979     BRD   Control                 -0.00625\n#>  9 R9887     BRD   Control                 -0.0659 \n#> 10 Y3059     BRD   Control                 -0.00504\n#> 11 Y9745     BRD   Control                 -0.0358\n\nNote that with MOFA, since the different factors represent different trends within the data, it is possible that using more factors will yield smaller average silhouette groups. For example if we used all constructed factors:\n\ncompute_samples_silhouette(\n    mofa_output,\n    mo_set_complete,\n    \"status\"\n)$groups_average_silhouette\n#> # A tibble: 2 × 2\n#>   group   group_average_width\n#>   <fct>             <dbl[1d]>\n#> 1 BRD                  0.0658\n#> 2 Control              0.272\n\nIn such cases, it makes more sense to evaluate the ability of one or two latent dimensions to separate the samples group."
  },
  {
    "objectID": "evaluation.html#recap-targets-list",
    "href": "evaluation.html#recap-targets-list",
    "title": "13  Evaluating the integration results",
    "section": "\n13.5 Recap – targets list",
    "text": "13.5 Recap – targets list\nFor convenience, here is the list of targets that we created in this section:\n\nTargets list for evaluating the output of an integration method:\n\n\nlist(\n  ## Evaluating DIABLO selected features against single-omics results\n  tar_target(\n    diablo_selected_vs_singleomics_table,\n    evaluate_feature_selection_table(\n      diablo_output,\n      mo_data = mo_set_complete,\n      col_names = list(\n        \"snps\" = \"qtl_type\",\n        \"rnaseq\" = \"de_signif\",\n        \"metabolome\" = \"de_signif\"\n      )\n    )\n  ),\n  \n  ## Plotting DIABLO features weight against single-omics results\n  tar_target(\n    diablo_features_weight_vs_singleomics_plot,\n    plot_features_weight_covariate(\n      diablo_output, \n      mo_data = mo_set_complete, \n      covariate = list(\n        \"snps\" = \"qtl_type\", \n        \"rnaseq\" = \"de_status\", \n        \"metabolome\" = \"de_status\"\n      ),\n      remove_null_weight = TRUE\n    )\n  ),\n  \n  ## Genes GO annotation file \n  tar_target(\n    rnaseq_go_terms_file,\n    system.file(\n      \"extdata/transcriptomics_go_annotation.csv\", \n      package = \"moiraine\"\n    ),\n    format = \"file\"\n  ),\n  \n  ## Genes GO annotation data-frame \n  tar_target(\n    rnaseq_go_df,\n    read_csv(rnaseq_go_terms_file) |> \n      filter(go_domain == \"Biological process\")\n  ),\n  \n  ## GO term sets\n  tar_target(\n    go_sets,\n    make_feature_sets_from_df(\n      rnaseq_go_df,\n      col_id = \"gene_id\",\n      col_set = \"go_id\"\n    )\n  ),\n  \n  ## Filtering GO term sets against measured features\n  tar_target(\n    go_sets_filtered,\n    reduce_feature_sets_data(go_sets, mo_set_complete)\n  ),\n  \n  ## Checking genes GO term sets against datasets\n  tar_target(\n    go_sets_check,\n    check_feature_sets(\n      go_sets_filtered, \n      mo_set_complete,\n      datasets = \"rnaseq\"\n    )\n  ),\n  \n  ## Table of information about GO terms\n  tar_target(\n    go_sets_info,\n    rnaseq_go_df |>\n      dplyr::select(go_id, go_name) |>\n      dplyr::distinct()\n  ),\n  \n  ## MOFA latent components enrichment analysis\n  tar_target(\n    mofa_enrichment_results,\n    evaluate_method_enrichment(\n      mofa_output,\n      go_sets_filtered,\n      datasets = \"rnaseq\",\n      latent_dimensions = paste(\"Factor\", 1:3),\n      use_abs = TRUE,\n      min_set_size = 10,\n      add_missing_features = TRUE,\n      mo_data = mo_set_complete,\n      sets_info_df = go_sets_info,\n      col_set = \"go_id\"\n    )\n  ),\n  \n  ## Plotting features weight for GO term 'GO:0031424'\n  tar_target(\n    mofa_enrichment_go0031424_plot,\n    plot_features_weight_set(\n      mofa_output,\n      go_sets_filtered[[\"GO:0031424\"]],\n      set_name = \"GO:0031424 (keratinization)\",\n      features_metric = \"importance\",\n      datasets = \"rnaseq\",\n      latent_dimensions = paste(\"Factor\", c(1, 3)),\n      point_alpha = 0.2\n    )\n  ),\n  \n  ## Assessing DIABLO samples clustering\n  tar_target(\n    diablo_silhouette,\n    compute_samples_silhouette(\n      diablo_output,\n      mo_set_complete,\n      \"status\"\n    )\n  )\n)\n\n\n\n\n\n\nLuo, Weijun, Michael S. Friedman, Kerby Shedden, Kurt D. Hankenson, and Peter J. Woolf. 2009. “GAGE: Generally Applicable Gene Set Enrichment for Pathway Analysis.” BMC Bioinformatics 10 (1): 161. https://doi.org/10.1186/1471-2105-10-161.\n\n\nTimmons, James A., Krzysztof J. Szkop, and Iain J. Gallagher. 2015. “Multiple Sources of Bias Confound Functional Enrichment Analysis of Global -Omics Data.” Genome Biology 16 (1): 186. https://doi.org/10.1186/s13059-015-0761-7.\n\n\nZhao, Kangmei, and Seung Yon Rhee. 2023. “Interpreting Omics Data with Pathway Enrichment Analysis.” Trends in Genetics 39 (4): 308–19. https://doi.org/10.1016/j.tig.2023.01.003."
  },
  {
    "objectID": "comparison.html#introduction",
    "href": "comparison.html#introduction",
    "title": "14  Comparing the integration results",
    "section": "\n14.1 Introduction",
    "text": "14.1 Introduction\nAs explained in Section 12.1, the integration tools considered in moiraine all perform dimension reduction of the omics datasets, and therefore all construct latent dimensions which can be described in terms of their features weight and their samples score. Therefore, we can compare the results of different integration methods in terms of their latent dimensions, by comparing either the latent dimensions’ samples score, or their features weight. When comparing the samples score, we are answering the question: are the different methods capturing the same trends from the datasets? By comparing features weight, we are instead answering a slightly different question: are the different methods highlighting similar sets of features as driving variation in the datasets? Of course, these comparisons are related, as two latent dimensions that identify very different trends in the data will most likely give high importance to very different sets of features.\nNote that, although this chapter mainly considers a comparison of different integration methods, we could also compare the results of a same integration but with different pre-processing options (e.g. to assess the impact of datasets normalisation or pre-filtering on the integration results). To illustrate this, we will run a second MOFA analysis, but this time using the datasets that have been pre-filtered to retain the most variable features (Section 7.3.1), as opposed to the supervised pre-filtering results that we have used in the main analysis (Section 7.3.2).\n\n\nlist(\n  ## Creating the input object for the MOFA pipeline\n  ## using the unsupervised preselection results\n  tar_target(\n    mofa_unsupervised_input,\n    get_input_mofa(\n      mo_presel_unsupervised,\n      options_list = list(\n        data_options = list(scale_views = TRUE),\n        model_options = list(\n          likelihoods = c(\n            \"snps\" = \"poisson\",\n            \"rnaseq\" = \"gaussian\",\n            \"metabolome\" = \"gaussian\")\n        ),\n        training_options = list(seed = 72)\n      ),\n      only_common_samples = FALSE\n    )\n  ),\n  \n  ## Training the model with the MOFA algorithm\n  tar_target(\n    mofa_unsupervised_trained,\n    run_mofa(\n      mofa_unsupervised_input,\n      save_data = TRUE,\n      use_basilisk = TRUE\n    )\n  ),\n  \n  ## Formatting MOFA output\n  tar_target(\n    mofa_unsupervised_output,\n    get_output(mofa_unsupervised_trained)\n  )\n)"
  },
  {
    "objectID": "comparison.html#extracting-integration-results",
    "href": "comparison.html#extracting-integration-results",
    "title": "14  Comparing the integration results",
    "section": "\n14.2 Extracting integration results",
    "text": "14.2 Extracting integration results\nThe first step in order to compare the results from different methods is to convert them to a standardised format with the get_output() function, which we did in Chapter 12. The function returns an output_dimension_reduction object which contains information about the latent dimensions’ features weight and samples score, as well as a summary of the percentage of variance explained for each dataset. The output_dimension_reduction object created also has an attribute called method, which contains the name of the integration method used:\n\ntar_load(diablo_output)\nattr(diablo_output, \"method\")\n#> [1] \"DIABLO\"\n\nTo facilitate comparisons, we will combine these objects into a list:\n\n\ntar_target(\n  output_list,\n  list(spls_output, so2pls_output, mofa_output, diablo_output)\n)\n\n\nThis list will be the input of most of the functions that we will showcase in this chapter.\n\ntar_load(output_list)\n\nYou can notice that we didn’t give any name to the elements of the list that we just created. When comparing results from different integration methods, the comparison functions implemented in moiraine automatically extract the name of the method from each object (as shown above), and use this as labels in the plots. However, when we want to compare several results from a same integration method, we need to give unique names to the different elements in the output list, e.g.:\n\n\ntar_target(\n  output_list_mofa,\n  list(\n    \"MOFA (supervised pref.)\" = mofa_output,\n    \"MOFA (unsupervised pref.)\" = mofa_unsupervised_output\n  )\n)\n\n\n\ntar_load(output_list_mofa)"
  },
  {
    "objectID": "comparison.html#clustered-correlation-heatmaps",
    "href": "comparison.html#clustered-correlation-heatmaps",
    "title": "14  Comparing the integration results",
    "section": "\n14.3 Clustered correlation heatmaps",
    "text": "14.3 Clustered correlation heatmaps\nWe can visualise the correlation between the samples score and features weight of the different latent dimensions constructed by the integration methods as a heatmap, using the comparison_heatmap_corr() function. The main input parameter of the function is a list of output_dimension_reduction objects, which we constructed in the previous section:\n\ncomparison_heatmap_corr(output_list, legend_ncol = 4)\n\n\n\n\nThe function generates two half-heatmaps. The heatmap on the left is a visualisation of the correlation between the features weight of the different latent dimensions; the one on the right shows the correlation between their samples score. Since correlation matrices are symmetric, only one triangle of each matrix is represented. The rows and columns of the heatmaps each correspond to one of the latent dimensions generated by one of the integration methods. Their name is abbreviated (C stands for component, F for Factor, JC for joint component, RSC for rnaseq-specific component and MSC for metabolome-specific component). The method through which each latent dimension was generated is indicated next to its name as a coloured annotation. In each heatmap, the rows and columns have been ordered according to a clustering performed on the correlation matrix, so that the latent dimensions most similar (in terms of samples score or features weight) are next to each other.\nBy default, the function represents all of the latent dimensions generated by each method, but the latent_dimensions parameter allows us to select only the ones we are interested in comparing. It accepts a named list, where each element gives for an integration method the latent dimensions to use. The names of the list must correspond to methods name. For example, we will look at all latent dimensions from sPLS and DIABLO, but restrict to only the first four MOFA factors, and only the joint component and first two dataset-specific components for sO2PLS:\n\ncomparison_heatmap_corr(\n  output_list,\n  latent_dimensions = list(\n    \"sO2PLS\" = c(\n      \"joint component 1\",\n      paste(\"metabolome specific component\", 1:2),\n      \"rnaseq specific component 1\"\n    ),\n    \"MOFA\" = paste(\"Factor\", 1:4)\n  )\n)\n\n\n\n\nFrom the heatmaps, we can see that some latent dimensions constructed by the different methods seem to capture similar trends in the data. For example, MOFA factor 1, sPLS component 1, DIABLO component 1 and sO2PLS joint component 1 are all strongly correlated in terms of their samples score. Their correlation in terms of features weight is a bit lower, which is due to the fact that some methods perform features selection, therefore all non-selected features are given a weight of 0. Note that the sign of the correlation is interesting but not very important. We can also see some latent dimensions that seem correlated with respect to one metric but not the other. For example, there is a strong correlation between the samples score of MOFA factor 4 and sPLS component 2, but this is not reflected in their features weight. Again, that can be because one method performs latent selection and not the other. On the other hand, the correlation between sPLS component 3 and DIABLO component 2 is stronger when looking at their features weight than at their samples score.\nWhen using the function to compare the results of the two MOFA runs, the names that we gave to the list of output will be used as method name, and these are the names to use in order to select some latent dimensions of interest. For example:\n\ncomparison_heatmap_corr(\n  output_list_mofa,\n  latent_dimensions = list(\n    \"MOFA (supervised pref.)\" = paste0(\"Factor \", 1:5),\n    \"MOFA (unsupervised pref.)\" = paste0(\"Factor \", 1:5)\n  )\n)"
  },
  {
    "objectID": "comparison.html#a-note-about-missing-features",
    "href": "comparison.html#a-note-about-missing-features",
    "title": "14  Comparing the integration results",
    "section": "\n14.4 A note about missing features",
    "text": "14.4 A note about missing features\nTypically, when comparing the output of different integration methods, we assume that the same input data was used for each method. However, when we are instead comparing the impact of data pre-processing on the integration results, it is possible that not all features are present in the input data for each of the methods. This is for example the case when assessing the impact of different prefiltering settings (e.g. supervised vs unsupervised) on the results of a particular integration method. It is also the case if we are comparing the integration results when using different subset of omics data as input: in our example, both DIABLO and MOFA were used on the three omics datasets (genomics, transcriptomics and metabolomics), while sPLS and sO2PLS were run on the transcriptomics and metabolomics datasets only. If that is the case, some features will have no weight in some of the results we are comparing (as they are not in the input data analysed by the integration method). There are two approaches to deal with that:\n\nApproach 1: remove these features from the comparison. The correlation between the features weight of any two latent dimensions will only be calculated using the features that are assigned a weight by both latent dimensions. This is the default approach used by comparison_heatmap_corr() and other comparison functions.\nApproach 2: the features that are assigned a weight by some methods but not others are retained for the comparison, and the missing weights are replaced with zero values.\n\nThe problem with approach 2 is that it might artificially decrease the computed correlation coefficients, which is why approach 1 is the default in this package. However, approach 2 may reveal interesting patterns and therefore was also implemented.\nIn comparison_heatmap_corr() and other comparison functions where relevant, the choice between these two approaches is controlled by the include_missing_features parameter. The first approach is selected with include_missing_features = FALSE, while the second approach is selected with include_missing_features = TRUE.\nNote that the first approach does not remove features that were discarded as a result of feature selection by one of the integration method, but only features that were not in the input data for the integration method. For example, sO2PLS performs feature selection for the joint components, and as a consequence the features that are not selected as assigned a weight of 0. These features are not impacted by the choice of approach."
  },
  {
    "objectID": "comparison.html#correlation-matrices",
    "href": "comparison.html#correlation-matrices",
    "title": "14  Comparing the integration results",
    "section": "\n14.5 Correlation matrices",
    "text": "14.5 Correlation matrices\nWe can obtain the correlation coefficients displayed in the heatmaps with the get_features_weight_correlation() and get_samples_score_correlation() functions:\n\nget_samples_score_correlation(output_list)[1:5, 1:5]\n#>                                          sPLS___Component 1 sPLS___Component 2\n#> sPLS___Component 1                              1.000000000        0.004845557\n#> sPLS___Component 2                              0.004845557        1.000000000\n#> sO2PLS___joint component 1                      0.973652291       -0.006320588\n#> sO2PLS___rnaseq specific component 1           -0.123298596        0.025496756\n#> sO2PLS___metabolome specific component 1        0.033930444       -0.148278174\n#>                                          sO2PLS___joint component 1\n#> sPLS___Component 1                                      0.973652291\n#> sPLS___Component 2                                     -0.006320588\n#> sO2PLS___joint component 1                              1.000000000\n#> sO2PLS___rnaseq specific component 1                   -0.007293233\n#> sO2PLS___metabolome specific component 1               -0.003995068\n#>                                          sO2PLS___rnaseq specific component 1\n#> sPLS___Component 1                                               -0.123298596\n#> sPLS___Component 2                                                0.025496756\n#> sO2PLS___joint component 1                                       -0.007293233\n#> sO2PLS___rnaseq specific component 1                              1.000000000\n#> sO2PLS___metabolome specific component 1                          0.018259608\n#>                                          sO2PLS___metabolome specific component 1\n#> sPLS___Component 1                                                    0.033930444\n#> sPLS___Component 2                                                   -0.148278174\n#> sO2PLS___joint component 1                                           -0.003995068\n#> sO2PLS___rnaseq specific component 1                                  0.018259608\n#> sO2PLS___metabolome specific component 1                              1.000000000\n\nget_features_weight_correlation(output_list)[1:5, 1:5]\n#>                                          sPLS___Component 1 sPLS___Component 2\n#> sPLS___Component 1                              1.000000000        0.008381676\n#> sPLS___Component 2                              0.008381676        1.000000000\n#> sO2PLS___joint component 1                      0.702008542       -0.005438028\n#> sO2PLS___rnaseq specific component 1           -0.200398661        0.012947768\n#> sO2PLS___metabolome specific component 1        0.151077963       -0.180756532\n#>                                          sO2PLS___joint component 1\n#> sPLS___Component 1                                      0.702008542\n#> sPLS___Component 2                                     -0.005438028\n#> sO2PLS___joint component 1                              1.000000000\n#> sO2PLS___rnaseq specific component 1                   -0.418570009\n#> sO2PLS___metabolome specific component 1                0.113863838\n#>                                          sO2PLS___rnaseq specific component 1\n#> sPLS___Component 1                                                -0.20039866\n#> sPLS___Component 2                                                 0.01294777\n#> sO2PLS___joint component 1                                        -0.41857001\n#> sO2PLS___rnaseq specific component 1                               1.00000000\n#> sO2PLS___metabolome specific component 1                                   NA\n#>                                          sO2PLS___metabolome specific component 1\n#> sPLS___Component 1                                                      0.1510780\n#> sPLS___Component 2                                                     -0.1807565\n#> sO2PLS___joint component 1                                              0.1138638\n#> sO2PLS___rnaseq specific component 1                                           NA\n#> sO2PLS___metabolome specific component 1                                1.0000000\n\nNote that the formatting of the row and column names is designed for easier handling in the various plotting functions."
  },
  {
    "objectID": "comparison.html#pairwise-comparisons",
    "href": "comparison.html#pairwise-comparisons",
    "title": "14  Comparing the integration results",
    "section": "\n14.6 Pairwise comparisons",
    "text": "14.6 Pairwise comparisons\nWhile the comparison_heatmap_corr() function can handle any number of methods to compare (in our example it was 4), the heatmap can become difficult to interpret. As an alternative option, it is possible to visualise the correlation between the latent dimensions of any two methods. This is what the function comparison_plot_correlation() is for. It also takes as input a list of methods’ output, but the list must only contain two elements. For example, we will compare the results of sPLS and sO2PLS:\n\ncomparison_plot_correlation(output_list[2:1])\n\n\n\n\nAs with comparison_heatmap_corr(), the function displays the correlation between the latent dimensions’ samples score on the left, and between their features weight on the right, but using correlation plots rather than heatmaps. By default, only correlation coefficients above 0.2 have their value displayed (for better clarity), but this can be customised through the min_show_corr argument.\nBy default, the function plots both samples score correlations and features weight correlation, but it is possible to display only one of them by setting the by argument to either samples or features. In addition, as for the heatmap plotting function, it is possible to focus on certain latent dimensions by passing a named list of latent dimensions name to the latent_dimensions argument:\n\ncomparison_plot_correlation(\n  output_list[2:1],\n  by = \"samples\",\n  latent_dimensions = list(\n    \"sO2PLS\" = c(\"joint component 1\", \"rnaseq specific component 1\")\n  )\n)"
  },
  {
    "objectID": "comparison.html#comparing-samples-score",
    "href": "comparison.html#comparing-samples-score",
    "title": "14  Comparing the integration results",
    "section": "\n14.7 Comparing samples score",
    "text": "14.7 Comparing samples score\nThe correlation plots shown above provide a useful summary of the similarity between the latent dimensions constructed by different integration methods. We can then investigate further how any two latent dimensions (from two different integration methods) are related. One way to do so is to compare their samples score in a scatterplot. In Section 12.4.2, the plot_samples_score_pair() function has been used to display the samples score of two latent dimensions from the result of an integration method, e.g.:\n\ntar_load(mo_set_complete)\n\nplot_samples_score_pair(\n  diablo_output,\n  c(\"Component 1\", \"Component 2\"),\n  mo_data = mo_set_complete,\n  colour_by = \"status\"\n) +\n  scale_colour_brewer(palette = \"Set1\")\n\n\n\n\nThis function can also be used to compare the samples score of two latent dimensions from two integration different methods. This is done by passing to the function a list of length 2 containing the output of two different methods. The name of the latent dimensions to compare are provided as a named list, where each name corresponds to either the name of the method (if the input list is not named) or the name of the element in the input list. So for example, to compare the first latent dimension of MOFA and DIABLO:\n\nplot_samples_score_pair(\n  output_list[3:4],\n  list(\"MOFA\" = \"Factor 1\", \"DIABLO\" = \"Component 1\"),\n  mo_data = mo_set_complete,\n  colour_by = \"status\"\n) +\n  scale_colour_brewer(palette = \"Set1\")\n#> Warning: Removed 9 rows containing missing values (`geom_point()`).\n\n\n\n\nWe can see that the samples score of the two latent dimensions are strongly correlated, showing that the two latent dimensions capture a similar trend in the data."
  },
  {
    "objectID": "comparison.html#comparing-features-weight",
    "href": "comparison.html#comparing-features-weight",
    "title": "14  Comparing the integration results",
    "section": "\n14.8 Comparing features weight",
    "text": "14.8 Comparing features weight\nIn a similar way, we can compare the features importance score of two latent dimensions from two different integration methods. In Section 12.5.2, the plot_features_weight_pair() function has been used to display the features weight or importance score of two latent dimensions from the result of an integration method, e.g.:\n\nplot_features_weight_pair(\n  diablo_output,\n  c(\"Component 1\", \"Component 2\"),\n  mo_data = mo_set_complete,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  )\n)\n\n\n\n\nThis function can also be used to compare the features weight of two latent dimensions from two different integration methods. This is done by passing to the function a list of length 2 containing the output of two different methods. The name of the latent dimensions to compare are provided as a named list, where each name corresponds to either the name of the method (if the input list is not named) or the name of the element in the input list. We will again compare MOFA factor 1 and DIABLO component 1:\n\nplot_features_weight_pair(\n  output_list[3:4],\n  list(\"MOFA\" = \"Factor 1\", \"DIABLO\" = \"Component 1\"),\n  mo_data = mo_set_complete,\n  features_metric = \"importance\",\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  )\n)\n\n\n\n\nWe can see that while MOFA and DIABLO identify the same metabolites as being the most important to separate healthy and infected animals, the genomic markers and genes that are given the highest importance score by MOFA are not selected with DIABLO.\nBy default, the function plots the features signed importance (i.e. importance score to which the sign of their weight was added), but in this case it makes sense to look at their (non-signed) importance score, which we have done by setting the features_metric argument to 'importance'. Note that we can also compare their raw weight, by setting features_metric to 'weight'. If that is the case, keep in mind that the weights from different latent dimensions live on different scales, so the raw values are not directly comparable (but the features ranking and weight sign are). We can also focus on a subset of datasets by passing their name to the datasets argument:\n\nplot_features_weight_pair(\n  output_list[3:4],\n  list(\"MOFA\" = \"Factor 1\", \"DIABLO\" = \"Component 1\"),\n  features_metric = \"weight\",\n  datasets = c(\"rnaseq\", \"metabolome\"),\n  mo_data = mo_set_complete,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  )\n)\n\n\n\n\nBy default, the plot_features_weight_pair() function uses the geometric consensus importance metric (more details in the next section) to highlight the 5 features identified as most important by both methods. Both the number of features highlighted and the metric used can be controlled, through the top_n and metric arguments, respectively. In the following section, we will expand on the concept of consensus importance and the different metrics available."
  },
  {
    "objectID": "comparison.html#sec-comparison-consensus",
    "href": "comparison.html#sec-comparison-consensus",
    "title": "14  Comparing the integration results",
    "section": "\n14.9 Feature consensus importance",
    "text": "14.9 Feature consensus importance\n\n14.9.1 Possible metrics\nWhen comparing the results of several integration methods, we might find that several methods uncover similar trends in the datasets, through the latent dimensions they construct. For these latent dimensions, it is interesting to assess which features are consistently selected by the different methods as driving these trends. We can do so by computing the consensus importance score of the features, which summarises the importance given to the features by the different integration methods. Different metrics can be used to compute the consensus importance score. With \\(s_j^i\\) denoting the importance score of feature \\(j\\) from method \\(i\\), \\(i = 1 \\dots n_i\\) (more specifically, from one latent dimension constructed by the integration method), the following metrics are implemented in the package:\n\nGeometric mean (geometric): calculated as \\(CI_j^G = \\exp\\left(\\frac{1}{n_i} \\sum\\limits_i \\log(s_j^i)\\right)\\)\nHarmonic mean (harmonic): calculated as \\(CI_j^H = \\frac{1}{\\frac{1}{n_i}\\sum\\limits_i\\frac{1}{s_j^i}}\\)\nL2 norm (l2): calculated as \\(CI_j^{L2} = \\sqrt{\\sum\\limits_i (s_j^i)^2}\\)\nAverage (average): calculated as \\(CI_j^A = \\frac{1}{n_i} \\sum\\limits_i s_j^i\\)\nProduct (product): calculated as \\(CI_j^P = \\prod\\limits_i s_j^i\\)\nMinimum (min): calculated as \\(CI_j^{min} = \\min\\limits_i(s_j^i)\\)\nMaximum (max): calculated as \\(CI_j^{max} = \\max\\limits_i(s_j^i)\\)\n\nThe difference between these metrics can be visualised in the simple case where features are assigned two different importance scores, e.g. by two different integration methods:\n\nshow_consensus_metrics()\n\n\n\n\nIn the plots, the consensus importance values have been normalised so that the highest value is 1. As we can see, metrics such as the geometric mean, harmonic mean, product or minimum will give higher consensus scores to features that are consistently assigned a high importance score across all methods, while features that have high importance score with one method but low score with the other will get a lower consensus score. Conversely, metrics such as the L2-norm or maximum prioritise features that are given a high importance score by at least one method, regardless of their importance score with other methods.\n\n14.9.2 Computing features’ consensus importance score\nThe function compute_consensus_importance() takes as input a list of output objects from different integration methods, as well as a named list indicating which latent dimension from each output object should be considered. By default, the geometric mean is used, but this can be changed through the metric argument.\n\nconsensus_df <- compute_consensus_importance(\n  output_list[3:4],\n  list(\"MOFA\" = \"Factor 1\", \"DIABLO\" = \"Component 1\")\n)\n\nconsensus_df\n#> # A tibble: 2,049 × 3\n#>    dataset feature_id         importance\n#>    <fct>   <chr>                   <dbl>\n#>  1 snps    ARS-BFGL-NGS-27468      1    \n#>  2 snps    BovineHD2300010006      0.908\n#>  3 snps    BovineHD0300000351      0.650\n#>  4 snps    BovineHD0900026231      0.555\n#>  5 snps    BovineHD0600028258      0.471\n#>  6 snps    BovineHD1100030384      0.416\n#>  7 snps    BTA-118330-no-rs        0.414\n#>  8 snps    BovineHD1800016801      0.409\n#>  9 snps    ARS-BFGL-NGS-84112      0.341\n#> 10 snps    BovineHD1900011146      0.331\n#> # ℹ 2,039 more rows\n\nTo help compare the data-frame with the plots created in the previous section, we will add the features label to the consensus importance data-frame.\n\nfeatures_labels_df <- get_features_labels(\n  mo_set_complete,\n  list(\"rnaseq\" = \"Name\",\n       \"metabolome\" = \"name\")\n)\n\nconsensus_df <- consensus_df |> \n  left_join(features_labels_df, by = c(\"dataset\", \"feature_id\"))\n\nconsensus_df |> \n  group_by(dataset) |> \n  slice_max(importance, n = 5)\n#> # A tibble: 15 × 4\n#> # Groups:   dataset [3]\n#>    dataset    feature_id         importance label                \n#>    <chr>      <chr>                   <dbl> <chr>                \n#>  1 metabolome HMDB00094               1     Citric acid          \n#>  2 metabolome HMDB00042               0.508 Acetic acid          \n#>  3 metabolome HMDB00169               0.448 D-Mannose            \n#>  4 metabolome HMDB00148               0.375 L-Glutamic acid      \n#>  5 metabolome HMDB00357               0.350 3-Hydroxybutyric acid\n#>  6 rnaseq     ENSBTAG00000022715      1     ENSBTAG00000022715   \n#>  7 rnaseq     ENSBTAG00000050618      0.877 ENSBTAG00000050618   \n#>  8 rnaseq     ENSBTAG00000051722      0.701 ENSBTAG00000051722   \n#>  9 rnaseq     ENSBTAG00000049808      0.698 IL3RA                \n#> 10 rnaseq     ENSBTAG00000050206      0.687 ENSBTAG00000050206   \n#> 11 snps       ARS-BFGL-NGS-27468      1     ARS-BFGL-NGS-27468   \n#> 12 snps       BovineHD2300010006      0.908 BovineHD2300010006   \n#> 13 snps       BovineHD0300000351      0.650 BovineHD0300000351   \n#> 14 snps       BovineHD0900026231      0.555 BovineHD0900026231   \n#> 15 snps       BovineHD0600028258      0.471 BovineHD0600028258\n\nWe can see that, using the geometric mean, the feature from the metabolomics dataset that is given the highest consensus importance is citric acid. Note that the metric chosen matters less when the latent dimensions compared are in strong agreement, as it is the case here:\n\ncompute_consensus_importance(\n  output_list[3:4],\n  list(\"MOFA\" = \"Factor 1\", \"DIABLO\" = \"Component 1\"),\n  metric = \"average\"\n) |> \n  left_join(features_labels_df, by = c(\"dataset\", \"feature_id\")) |> \n  group_by(dataset) |> \n  slice_max(importance, n = 5)\n#> # A tibble: 15 × 4\n#> # Groups:   dataset [3]\n#>    dataset    feature_id             importance label                 \n#>    <chr>      <chr>                       <dbl> <chr>                 \n#>  1 metabolome HMDB00094                   1     Citric acid           \n#>  2 metabolome HMDB00042                   0.508 Acetic acid           \n#>  3 metabolome HMDB00169                   0.448 D-Mannose             \n#>  4 metabolome HMDB00357                   0.377 3-Hydroxybutyric acid \n#>  5 metabolome HMDB00148                   0.375 L-Glutamic acid       \n#>  6 rnaseq     ENSBTAG00000022715          1     ENSBTAG00000022715    \n#>  7 rnaseq     ENSBTAG00000050618          0.872 ENSBTAG00000050618    \n#>  8 rnaseq     ENSBTAG00000051722          0.711 ENSBTAG00000051722    \n#>  9 rnaseq     ENSBTAG00000049808          0.699 IL3RA                 \n#> 10 rnaseq     ENSBTAG00000050206          0.685 ENSBTAG00000050206    \n#> 11 snps       ARS-BFGL-NGS-27468          1     ARS-BFGL-NGS-27468    \n#> 12 snps       BovineHD2300010006          0.883 BovineHD2300010006    \n#> 13 snps       BovineHD0100032240          0.645 BovineHD0100032240    \n#> 14 snps       Hapmap55381-rs29025399      0.645 Hapmap55381-rs29025399\n#> 15 snps       BovineHD0300000351          0.625 BovineHD0300000351\n\nIn the plot_features_weight_pair() function, we can specify which metric should be used for the consensus importance to highlight the top features. For example, we can illustrate the top features according to the average consensus metric:\n\nplot_features_weight_pair(\n  output_list[3:4],\n  list(\"MOFA\" = \"Factor 1\", \"DIABLO\" = \"Component 1\"),\n  metric = \"average\",\n  datasets = c(\"rnaseq\", \"metabolome\"),\n  mo_data = mo_set_complete,\n  label_cols = list(\n    \"rnaseq\" = \"Name\",\n    \"metabolome\" = \"name\"\n  )\n)"
  },
  {
    "objectID": "comparison.html#recap-targets-list",
    "href": "comparison.html#recap-targets-list",
    "title": "14  Comparing the integration results",
    "section": "\n14.10 Recap – targets list",
    "text": "14.10 Recap – targets list\nAlthough we didn’t create many new target for the plots in this chapter, we can turn some plots into targets.\n\nTargets list for comparing different integration methods’ output\n\n\nlist(\n  ## Creating a list of integration methods output objects\n  tar_target(\n    output_list,\n    list(spls_output, so2pls_output, mofa_output, diablo_output)\n  ),\n  \n  ## Heatmap for comparison of integration methods output\n  tar_target(\n    comparison_methods_heatmap_plot,\n    comparison_heatmap_corr(output_list)\n  ),\n  \n  ## Correlation plot for comparison of sPLS and sO2PLS results\n  tar_target(\n    mofa_so2pls_correlation_plot,\n    comparison_plot_correlation(output_list[2:1])\n  ),\n  \n  ## Comparison of samples score for MOFA factor 1 and DIABLO component 1\n  tar_target(\n    mofa_so2pls_samples_score_comparison_plot,\n    plot_samples_score_pair(\n      output_list[3:4],\n      list(\"MOFA\" = \"Factor 1\", \"DIABLO\" = \"Component 1\"),\n      mo_data = mo_set_complete,\n      colour_by = \"status\"\n    ) +\n      scale_colour_brewer(palette = \"Set1\")\n  ),\n  \n  ## Comparison of features weight for MOFA factor 1 and sO2PLS joint component 1\n  tar_target(\n    mofa_so2pls_features_weight_comparison_plot,\n    plot_features_weight_pair(\n      output_list[3:4],\n      list(\"MOFA\" = \"Factor 1\", \"DIABLO\" = \"Component 1\"),\n      mo_data = mo_set_complete,\n      label_cols = list(\n        \"rnaseq\" = \"Name\",\n        \"metabolome\" = \"name\"\n      )\n    )\n  ),\n  \n  ## Table of features' consensus importance for MOFA factor 1 and sO2PLS joint\n  ## component 1\n  tar_target(\n    mofa_so2pls_features_weight_consensus_importance,\n    compute_consensus_importance(\n      output_list[3:4],\n      list(\"MOFA\" = \"Factor 1\", \"DIABLO\" = \"Component 1\")\n    ) |> \n      left_join(\n        get_features_labels(\n          mo_set_complete,\n          list(\"rnaseq\" = \"Name\",\n               \"metabolome\" = \"name\")\n        ),\n        by = c(\"dataset\", \"feature_id\")\n      )\n  )\n)"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bouhaddani, Said el, Hae-Won Uh, Geurt Jongbloed, Caroline Hayward,\nLucija Klarić, Szymon M. Kiełbasa, and Jeanine Houwing-Duistermaat.\n2018. “Integrating Omics Datasets with the OmicsPLS\nPackage.” BMC Bioinformatics 19 (1): 371. https://doi.org/10.1186/s12859-018-2371-3.\n\n\nGu, Zhujie, Said el Bouhaddani, Jiayi Pei, Jeanine Houwing-Duistermaat,\nand Hae-Won Uh. 2021. “Statistical Integration of Two Omics\nDatasets Using GO2PLS.” BMC Bioinformatics\n22 (1): 131. https://doi.org/10.1186/s12859-021-03958-3.\n\n\nHernandez-Ferrer, Carles, Carlos Ruiz-Arenas, Alba Beltran-Gomila, and\nJuan R. González. 2017. “MultiDataSet: An r Package for\nEncapsulating Multiple Data Sets with Application to Omic Data\nIntegration.” BMC Bioinformatics 18 (1): 36. https://doi.org/10.1186/s12859-016-1455-1.\n\n\nLê Cao, Kim-Anh, Simon Boitard, and Philippe Besse. 2011. “Sparse\nPLS Discriminant Analysis: Biologically Relevant Feature Selection and\nGraphical Displays for Multiclass Problems.” BMC\nBioinformatics 12 (1): 253. https://doi.org/10.1186/1471-2105-12-253.\n\n\nLi, Jiyuan, Robert Mukiibi, Janelle Jiminez, Zhiquan Wang, Everestus C.\nAkanno, Edouard Timsit, and Graham S. Plastow. 2022. “Applying\nMulti-Omics Data to Study the Genetic Background of Bovine Respiratory\nDisease Infection in Feedlot Crossbred Cattle.” Frontiers in\nGenetics 13. https://www.frontiersin.org/articles/10.3389/fgene.2022.1046192.\n\n\nLiquet, Benoit, Kim-Anh Lê Cao, Hakim Hocini, and Rodolphe Thiébaut.\n2012. “A Novel Approach for Biomarker Selection and the\nIntegration of Repeated Measures Experiments from Two Assays.”\nBMC Bioinformatics 13 (1): 325. https://doi.org/10.1186/1471-2105-13-325.\n\n\nLuo, Weijun, Michael S. Friedman, Kerby Shedden, Kurt D. Hankenson, and\nPeter J. Woolf. 2009. “GAGE: Generally Applicable\nGene Set Enrichment for Pathway Analysis.” BMC\nBioinformatics 10 (1): 161. https://doi.org/10.1186/1471-2105-10-161.\n\n\nTimmons, James A., Krzysztof J. Szkop, and Iain J. Gallagher. 2015.\n“Multiple Sources of Bias Confound Functional Enrichment Analysis\nof Global -Omics Data.” Genome Biology 16 (1): 186. https://doi.org/10.1186/s13059-015-0761-7.\n\n\nZhao, Kangmei, and Seung Yon Rhee. 2023. “Interpreting Omics Data\nwith Pathway Enrichment Analysis.” Trends in Genetics 39\n(4): 308–19. https://doi.org/10.1016/j.tig.2023.01.003."
  }
]